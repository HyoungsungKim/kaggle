{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.8.1-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python38164bit66f7a8720ea44564891eb6b9b39e6c03",
   "display_name": "Python 3.8.1 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "import collections\n",
    "import time\n",
    "\n",
    "from random import choice\n",
    "from kaggle_environments import evaluate, make, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Experience = collections.namedtuple('Experience', field_names=['observation', 'action', 'reward', 'done', 'new_observation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExperienceBuffer:\n",
    "    def __init__(self, capacity):\n",
    "        self.buffer = collections.deque(maxlen=capacity)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.buffer)\n",
    "\n",
    "    def append(self, experience):\n",
    "        self.buffer.append(experience)\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        # * Get a number of batch_size experience in a range of len(self.buffer)\n",
    "        # * It does not replace\n",
    "        indices = np.random.choice(len(self.buffer), batch_size, replace=False)\n",
    "\n",
    "        observation, actions, rewards, dones, next_observation = zip(*[self.buffer[idx] for idx in indices])\n",
    "        return np.array(observation), np.array(actions), np.array(rewards, dtype=np.float32), np.array(dones, dtype=np.uint8), np.array(next_observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Flatten, self).__init__()\n",
    "\n",
    "    def forward(self, shape):\n",
    "        return shape.view(shape.size()[0], -1)\n",
    "\n",
    "\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, input_shape, n_actions):\n",
    "        super(DQN, self).__init__()\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(input_shape[0], 32, kernel_size=3, padding = 1, stride=4),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=4, padding = 1, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding = 1, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "\n",
    "        conv_out_size = self._get_conv_out(input_shape)\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(conv_out_size, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, n_actions)\n",
    "        )\n",
    "\n",
    "    def _get_conv_out(self, input_shape):\n",
    "        # * To make 3D shape, we have to put 1 in torch.zeros\n",
    "        # * torch.zeros(1, 1, 52, 52)\n",
    "        # * -> troch.zeros(batch_dimension, *shape)\n",
    "        out = self.conv(torch.zeros(1, *input_shape))\n",
    "        return int(np.prod(out.size()))\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv_out = self.conv(x)\n",
    "        fc_out = self.fc(conv_out)\n",
    "        return fc_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "DQN(\n  (conv): Sequential(\n    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(4, 4), padding=(1, 1))\n    (1): ReLU()\n    (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n    (3): ReLU()\n    (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (5): ReLU()\n    (6): Flatten()\n  )\n  (fc): Sequential(\n    (0): Linear(in_features=2304, out_features=512, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=512, out_features=10, bias=True)\n  )\n)\n"
    },
    {
     "data": {
      "text/plain": "tensor([[-0.0490, -0.0318, -0.0217,  0.0270, -0.0230,  0.0005, -0.0169,  0.0252,\n          0.0056, -0.0456]], grad_fn=<AddmmBackward>)"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = torch.rand(1, 1, 52, 52)\n",
    "dqn = DQN(image[0].shape, 10)\n",
    "print(dqn)\n",
    "dqn(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /kaggle_environments/envs/connectx.py\n",
    "def is_win(board, column, mark, config, has_played=True):\n",
    "    columns = config.columns\n",
    "    rows = config.rows\n",
    "    inarow = config.inarow - 1\n",
    "    row = (\n",
    "        min([r for r in range(rows) if board[column + (r * columns)] == mark])\n",
    "        if has_played\n",
    "        else max([r for r in range(rows) if board[column + (r * columns)] == 0])\n",
    "    )\n",
    "\n",
    "    def count(offset_row, offset_column):\n",
    "        for i in range(1, inarow + 1):\n",
    "            r = row + offset_row * i\n",
    "            c = column + offset_column * i\n",
    "            if (\n",
    "                r < 0\n",
    "                or r >= rows\n",
    "                or c < 0\n",
    "                or c >= columns\n",
    "                or board[c + (r * columns)] != mark\n",
    "            ):\n",
    "                return i - 1\n",
    "        return inarow\n",
    "\n",
    "    return (\n",
    "        count(1, 0) >= inarow  # vertical.\n",
    "        or (count(0, 1) + count(0, -1)) >= inarow  # horizontal.\n",
    "        or (count(-1, -1) + count(1, 1)) >= inarow  # top left diagonal.\n",
    "        or (count(-1, 1) + count(1, -1)) >= inarow  # top right diagonal.\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, env, exp_buffer):\n",
    "        configuration = env.configuration\n",
    "        self.env = env\n",
    "        self.columns = configuration['columns']\n",
    "        self.rows = configuration['rows']        \n",
    "        self.exp_buffer = exp_buffer\n",
    "        self._reset()\n",
    "\n",
    "    def _reset(self):      \n",
    "        mode_selector = np.random.random()\n",
    "        if  mode_selector < 0.25:        \n",
    "            self.trainer = self.env.train([None, \"random\"])\n",
    "           # print(\"random mode\")            \n",
    "        elif mode_selector >= 0.25  and mode_selector < 0.5:\n",
    "            self.trainer = self.env.train([None, \"negamax\"])\n",
    "           # print(\"negamax mode\")\n",
    "        elif mode_selector >= 0.5  and mode_selector < 0.75:\n",
    "            self.trainer = self.env.train([\"random\", None])\n",
    "           # print(\"negamax mode\")\n",
    "        elif mode_selector >= 0.75:\n",
    "            self.trainer = self.env.train([\"negamax\", None])\n",
    "           # print(\"negamax mode\")            \n",
    "\n",
    "        env_observation = self.trainer.reset()\n",
    "        self.mark = env_observation['mark']\n",
    "        self.board = env_observation['board']\n",
    "        np_board = np.array(self.board)\n",
    "        np_board = np_board.reshape(1, self.rows, -1)\n",
    "        assert np_board.shape[2] == self.columns\n",
    "\n",
    "        self.env.reset()\n",
    "        self.observation = np_board\n",
    "        self.total_reward = 0.0       \n",
    "\n",
    "    def _select_random_action(self):        \n",
    "        while True:\n",
    "            action = choice([c for c in range (self.columns) if self.board[c] == 0]) \n",
    "            if self.board[action] == 0:\n",
    "                return action\n",
    "\n",
    "    def _select_network_action(self, q_vals_v):\n",
    "        actions = torch.argsort(q_vals_v, descending=True, dim=1)\n",
    "        actions = actions.view(-1)\n",
    "\n",
    "        for action in actions:            \n",
    "            if self.board[action] == 0:                \n",
    "                return action.item()\n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def play_step(self, net, epsilon=0.0, device=\"cpu\"):\n",
    "        done_reward = None\n",
    "\n",
    "        if np.random.random() < epsilon:\n",
    "            action = self._select_random_action()\n",
    "        else:            \n",
    "            observation_v = torch.from_numpy(self.observation).float().to(device)\n",
    "            # Unsqueeze for batch size\n",
    "            # [batch_size, channel, row, column]\n",
    "            q_vals_v = net(observation_v.unsqueeze(0))\n",
    "            action = self._select_network_action(q_vals_v)   \n",
    "       \n",
    "        new_observation, reward, done, _ = self.trainer.step(action)        \n",
    "        \n",
    "        # For debuging\n",
    "        if reward == None:\n",
    "            print(\"INVALID\")\n",
    "            assert False\n",
    "                        \n",
    "        if done == False:\n",
    "            reward = 1                     \n",
    "   \n",
    "        self.total_reward += reward\n",
    "        self.board = new_observation['board']\n",
    "        if done == True and is_win(self.board, action, self.mark, self.env.configuration, has_played=True) == False:\n",
    "            reward = -30\n",
    "            #print(\"lose!\")\n",
    "\n",
    "        # Do not need to consider lose case. If agent can get high reward when it doen win        \n",
    "        if done == True and is_win(self.board, action, self.mark, self.env.configuration, has_played=True):\n",
    "            reward = 50\n",
    "            #print(\"WIN!\")\n",
    "\n",
    "        new_observation = np.array(self.board)\n",
    "        new_observation = new_observation.reshape(1, self.rows, -1)\n",
    "        assert new_observation.shape[2] == self.columns\n",
    "        \n",
    "        exp = Experience(self.observation, action, reward, done, new_observation)\n",
    "\n",
    "        self.exp_buffer.append(exp)\n",
    "        self.observation = new_observation\n",
    "\n",
    "        if done:\n",
    "            done_reward = self.total_reward\n",
    "            self._reset()     \n",
    "\n",
    "        return done_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "+---+---+---+---+---+---+---+\n| 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n+---+---+---+---+---+---+---+\n| 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n+---+---+---+---+---+---+---+\n| 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n+---+---+---+---+---+---+---+\n| 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n+---+---+---+---+---+---+---+\n| 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n+---+---+---+---+---+---+---+\n| 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n+---+---+---+---+---+---+---+\n\n"
    }
   ],
   "source": [
    "test_env = make(\"connectx\", debug=True)\n",
    "test_env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = test_env.configuration['columns']\n",
    "rows = test_env.configuration['rows']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_buffer = ExperienceBuffer(30)\n",
    "agent = Agent(test_env, test_buffer)\n",
    "epsilon = 1\n",
    "input_shape = [1, rows, columns]\n",
    "n_actions = columns\n",
    "net = DQN(input_shape, n_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "+---+---+---+---+---+---+---+\n| 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n+---+---+---+---+---+---+---+\n| 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n+---+---+---+---+---+---+---+\n| 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n+---+---+---+---+---+---+---+\n| 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n+---+---+---+---+---+---+---+\n| 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n+---+---+---+---+---+---+---+\n| 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n+---+---+---+---+---+---+---+\n\n"
    }
   ],
   "source": [
    "test_env.render()\n",
    "agent.play_step(net, epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "+---+---+---+---+---+---+---+\n| 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n+---+---+---+---+---+---+---+\n| 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n+---+---+---+---+---+---+---+\n| 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n+---+---+---+---+---+---+---+\n| 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n+---+---+---+---+---+---+---+\n| 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n+---+---+---+---+---+---+---+\n| 0 | 0 | 0 | 2 | 1 | 0 | 0 |\n+---+---+---+---+---+---+---+\n\n"
    }
   ],
   "source": [
    "test_env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(500):    \n",
    "    agent.play_step(net, epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation, actions, rewards, dones, next_observation = test_buffer.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[[[2, 1, 0, 0, 1, 0, 2],\n         [1, 2, 2, 0, 1, 0, 1],\n         [2, 1, 2, 0, 1, 0, 2],\n         [2, 2, 1, 0, 2, 0, 2],\n         [1, 1, 2, 0, 2, 1, 1],\n         [1, 2, 1, 1, 2, 2, 1]]],\n\n\n       [[[2, 1, 0, 0, 0, 0, 0],\n         [1, 2, 0, 0, 1, 0, 0],\n         [2, 1, 2, 0, 1, 0, 0],\n         [2, 2, 1, 0, 2, 0, 2],\n         [1, 1, 2, 0, 2, 0, 1],\n         [1, 2, 1, 0, 2, 0, 1]]],\n\n\n       [[[0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0]]],\n\n\n       [[[0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0]]],\n\n\n       [[[0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0],\n         [2, 0, 0, 0, 0, 0, 0],\n         [1, 0, 0, 2, 0, 0, 0],\n         [1, 1, 2, 1, 2, 2, 1]]],\n\n\n       [[[2, 1, 0, 0, 1, 0, 0],\n         [1, 2, 0, 0, 1, 0, 0],\n         [2, 1, 2, 0, 1, 0, 0],\n         [2, 2, 1, 0, 2, 0, 2],\n         [1, 1, 2, 0, 2, 0, 1],\n         [1, 2, 1, 0, 2, 2, 1]]],\n\n\n       [[[0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 2, 0, 0, 0],\n         [0, 0, 0, 1, 0, 0, 0],\n         [1, 0, 0, 2, 0, 0, 0]]],\n\n\n       [[[0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0],\n         [2, 0, 0, 0, 0, 0, 0],\n         [1, 0, 1, 2, 0, 2, 0],\n         [1, 1, 2, 1, 2, 2, 1]]],\n\n\n       [[[0, 1, 0, 0, 0, 0, 0],\n         [0, 2, 0, 0, 0, 0, 0],\n         [0, 1, 0, 0, 0, 0, 0],\n         [2, 2, 0, 0, 2, 0, 0],\n         [1, 1, 2, 0, 2, 0, 1],\n         [1, 2, 1, 0, 2, 0, 1]]],\n\n\n       [[[0, 1, 0, 0, 0, 0, 0],\n         [0, 2, 0, 0, 0, 0, 0],\n         [2, 1, 0, 0, 0, 0, 0],\n         [2, 2, 1, 0, 2, 0, 0],\n         [1, 1, 2, 0, 2, 0, 1],\n         [1, 2, 1, 0, 2, 0, 1]]]])"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([2, 4, 0, 6, 2, 5, 6, 3, 2, 4])"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=uint8)"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[[[2, 1, 1, 0, 1, 0, 2],\n         [1, 2, 2, 0, 1, 0, 1],\n         [2, 1, 2, 0, 1, 0, 2],\n         [2, 2, 1, 0, 2, 2, 2],\n         [1, 1, 2, 0, 2, 1, 1],\n         [1, 2, 1, 1, 2, 2, 1]]],\n\n\n       [[[2, 1, 0, 0, 1, 0, 0],\n         [1, 2, 0, 0, 1, 0, 0],\n         [2, 1, 2, 0, 1, 0, 0],\n         [2, 2, 1, 0, 2, 0, 2],\n         [1, 1, 2, 0, 2, 0, 1],\n         [1, 2, 1, 0, 2, 2, 1]]],\n\n\n       [[[0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0],\n         [1, 0, 0, 0, 2, 0, 0]]],\n\n\n       [[[0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 2, 0, 1]]],\n\n\n       [[[0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0],\n         [2, 0, 0, 0, 0, 0, 0],\n         [1, 0, 1, 2, 0, 2, 0],\n         [1, 1, 2, 1, 2, 2, 1]]],\n\n\n       [[[2, 1, 0, 0, 1, 0, 0],\n         [1, 2, 0, 0, 1, 0, 0],\n         [2, 1, 2, 0, 1, 0, 2],\n         [2, 2, 1, 0, 2, 0, 2],\n         [1, 1, 2, 0, 2, 1, 1],\n         [1, 2, 1, 0, 2, 2, 1]]],\n\n\n       [[[0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 2, 0, 0, 0],\n         [2, 0, 0, 1, 0, 0, 0],\n         [1, 0, 0, 2, 0, 0, 1]]],\n\n\n       [[[0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 2, 0, 0, 0],\n         [2, 0, 0, 1, 0, 0, 0],\n         [1, 0, 1, 2, 0, 2, 0],\n         [1, 1, 2, 1, 2, 2, 1]]],\n\n\n       [[[0, 1, 0, 0, 0, 0, 0],\n         [0, 2, 0, 0, 0, 0, 0],\n         [2, 1, 0, 0, 0, 0, 0],\n         [2, 2, 1, 0, 2, 0, 0],\n         [1, 1, 2, 0, 2, 0, 1],\n         [1, 2, 1, 0, 2, 0, 1]]],\n\n\n       [[[0, 1, 0, 0, 0, 0, 0],\n         [0, 2, 0, 0, 0, 0, 0],\n         [2, 1, 2, 0, 1, 0, 0],\n         [2, 2, 1, 0, 2, 0, 0],\n         [1, 1, 2, 0, 2, 0, 1],\n         [1, 2, 1, 0, 2, 0, 1]]]])"
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([  1.,   1.,   1.,   1., -10.,   1.,   1.,   1.,   1.,   1.],\n      dtype=float32)"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'agent' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-86d97942e9ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplay_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'agent' is not defined"
     ]
    }
   ],
   "source": [
    "agent.play_step(net, epsilon)\n",
    "test_env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss(batch, net, tgt_net, device='cpu'):\n",
    "    observation, actions, rewards, dones, next_observation = batch\n",
    "\n",
    "    observation_v = torch.from_numpy(observation).float().to(device)\n",
    "    next_observation_v = torch.from_numpy(next_observation).float().to(device)\n",
    "    action_v = torch.from_numpy(actions).to(device)\n",
    "    rewards_v = torch.from_numpy(rewards).to(device)\n",
    "    done_mask = torch.from_numpy(dones).to(device)\n",
    "\n",
    "    state_action_value = net(observation_v).gather(1, action_v.unsqueeze(-1)).squeeze(-1)\n",
    "    with torch.no_grad():\n",
    "        next_observation_values = tgt_net(next_observation_v).max(1)[0]\n",
    "        next_observation_values[done_mask] = 0.0\n",
    "        next_observation_values = next_observation_values.detach()\n",
    "\n",
    "    expected_state_action_values = next_observation_values * GAMMA + rewards_v\n",
    "\n",
    "    loss = nn.MSELoss()\n",
    "    return loss(state_action_value, expected_state_action_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAMMA = 0.99\n",
    "BATCH_SIZE = 8192\n",
    "REPLAY_SIZE = 5000000\n",
    "LEARNING_RATE = 1e-4\n",
    "SYNC_TARGET_FRAMES = 5000\n",
    "REPLAY_START_SIZE = 10000\n",
    "\n",
    "EPSILON_DECAY_LAST_FRAME = 100000\n",
    "EPSILON_START = 1.0\n",
    "EPSILON_FINAL = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Run using cuda\n"
    }
   ],
   "source": [
    "env = make(\"connectx\", debug=True)\n",
    "rows, columns = env.configuration['rows'], env.configuration['columns']\n",
    "input_shape = [1, rows, columns]\n",
    "n_actions = columns\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available else 'cpu')\n",
    "print(f\"Run using {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = DQN(input_shape, n_actions).to(device)    \n",
    "tgt_net = DQN(input_shape, n_actions).to(device)\n",
    "\n",
    "buffer = ExperienceBuffer(REPLAY_SIZE)\n",
    "agent = Agent(env, buffer)\n",
    "epsilon = EPSILON_START\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=LEARNING_RATE)\n",
    "total_rewards = []\n",
    "frame_idx = 0\n",
    "ts_frame = 0\n",
    "ts = time.time()\n",
    "best_m_reward = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_for_plot = []\n",
    "mean_reward_for_plot = []\n",
    "loss_for_plot = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "s 0.01, speed 6.93 f/s\n182352 : done 15659 games, reward 13.500, eps 0.01, speed 6.21 f/s\n182372 : done 15660 games, reward 13.500, eps 0.01, speed 5.29 f/s\n182378 : done 15661 games, reward 13.200, eps 0.01, speed 6.89 f/s\n182398 : done 15662 games, reward 14.300, eps 0.01, speed 5.25 f/s\n182403 : done 15663 games, reward 13.300, eps 0.01, speed 7.47 f/s\n182415 : done 15664 games, reward 12.400, eps 0.01, speed 6.93 f/s\n182435 : done 15665 games, reward 13.200, eps 0.01, speed 5.40 f/s\n182455 : done 15666 games, reward 14.200, eps 0.01, speed 5.40 f/s\n182463 : done 15667 games, reward 12.900, eps 0.01, speed 6.46 f/s\n182470 : done 15668 games, reward 12.100, eps 0.01, speed 6.91 f/s\n182477 : done 15669 games, reward 12.200, eps 0.01, speed 5.37 f/s\n182488 : done 15670 games, reward 11.200, eps 0.01, speed 4.64 f/s\n182496 : done 15671 games, reward 11.400, eps 0.01, speed 7.51 f/s\n182510 : done 15672 games, reward 10.800, eps 0.01, speed 6.14 f/s\n182521 : done 15673 games, reward 11.300, eps 0.01, speed 4.29 f/s\n182532 : done 15674 games, reward 11.200, eps 0.01, speed 4.87 f/s\n182546 : done 15675 games, reward 10.600, eps 0.01, speed 7.27 f/s\n182559 : done 15676 games, reward 9.900, eps 0.01, speed 7.46 f/s\n182579 : done 15677 games, reward 11.200, eps 0.01, speed 5.68 f/s\n182588 : done 15678 games, reward 11.400, eps 0.01, speed 7.10 f/s\n182608 : done 15679 games, reward 12.700, eps 0.01, speed 5.43 f/s\n182623 : done 15680 games, reward 13.100, eps 0.01, speed 4.49 f/s\n182634 : done 15681 games, reward 13.400, eps 0.01, speed 4.02 f/s\n182646 : done 15682 games, reward 13.100, eps 0.01, speed 4.28 f/s\n182661 : done 15683 games, reward 13.500, eps 0.01, speed 5.42 f/s\n182681 : done 15684 games, reward 14.500, eps 0.01, speed 5.37 f/s\n182701 : done 15685 games, reward 15.100, eps 0.01, speed 5.09 f/s\n182712 : done 15686 games, reward 14.800, eps 0.01, speed 4.86 f/s\n182732 : done 15687 games, reward 14.800, eps 0.01, speed 5.26 f/s\n182741 : done 15688 games, reward 14.800, eps 0.01, speed 6.82 f/s\n182750 : done 15689 games, reward 13.600, eps 0.01, speed 7.75 f/s\n182770 : done 15690 games, reward 14.200, eps 0.01, speed 5.10 f/s\n182781 : done 15691 games, reward 14.200, eps 0.01, speed 4.27 f/s\n182792 : done 15692 games, reward 14.100, eps 0.01, speed 4.51 f/s\n182799 : done 15693 games, reward 13.300, eps 0.01, speed 8.03 f/s\n182819 : done 15694 games, reward 13.300, eps 0.01, speed 5.37 f/s\n182837 : done 15695 games, reward 13.000, eps 0.01, speed 7.04 f/s\n182844 : done 15696 games, reward 12.700, eps 0.01, speed 6.85 f/s\n182851 : done 15697 games, reward 11.400, eps 0.01, speed 6.60 f/s\n182862 : done 15698 games, reward 11.500, eps 0.01, speed 6.92 f/s\n182871 : done 15699 games, reward 11.600, eps 0.01, speed 7.62 f/s\n182891 : done 15700 games, reward 11.500, eps 0.01, speed 5.00 f/s\n182902 : done 15701 games, reward 11.500, eps 0.01, speed 4.48 f/s\n182922 : done 15702 games, reward 12.500, eps 0.01, speed 4.98 f/s\n182933 : done 15703 games, reward 12.900, eps 0.01, speed 4.15 f/s\n182944 : done 15704 games, reward 11.900, eps 0.01, speed 4.53 f/s\n182948 : done 15705 games, reward 10.600, eps 0.01, speed 5.90 f/s\n182968 : done 15706 games, reward 11.900, eps 0.01, speed 5.51 f/s\n182988 : done 15707 games, reward 13.200, eps 0.01, speed 5.31 f/s\n182995 : done 15708 games, reward 12.800, eps 0.01, speed 7.45 f/s\n183015 : done 15709 games, reward 13.900, eps 0.01, speed 5.35 f/s\n183035 : done 15710 games, reward 14.000, eps 0.01, speed 5.40 f/s\n183041 : done 15711 games, reward 13.500, eps 0.01, speed 5.01 f/s\n183052 : done 15712 games, reward 12.500, eps 0.01, speed 4.44 f/s\n183063 : done 15713 games, reward 12.500, eps 0.01, speed 4.72 f/s\n183083 : done 15714 games, reward 13.500, eps 0.01, speed 5.68 f/s\n183087 : done 15715 games, reward 13.400, eps 0.01, speed 7.45 f/s\n183100 : done 15716 games, reward 12.600, eps 0.01, speed 6.96 f/s\n183106 : done 15717 games, reward 11.100, eps 0.01, speed 7.29 f/s\n183120 : done 15718 games, reward 11.800, eps 0.01, speed 7.50 f/s\n183132 : done 15719 games, reward 11.000, eps 0.01, speed 7.31 f/s\n183148 : done 15720 games, reward 10.500, eps 0.01, speed 4.95 f/s\n183160 : done 15721 games, reward 11.100, eps 0.01, speed 7.89 f/s\n183168 : done 15722 games, reward 10.800, eps 0.01, speed 6.05 f/s\n183179 : done 15723 games, reward 10.800, eps 0.01, speed 4.54 f/s\n183199 : done 15724 games, reward 10.800, eps 0.01, speed 4.84 f/s\n183210 : done 15725 games, reward 11.500, eps 0.01, speed 4.72 f/s\n183230 : done 15726 games, reward 12.200, eps 0.01, speed 5.20 f/s\n183241 : done 15727 games, reward 12.700, eps 0.01, speed 4.81 f/s\n183253 : done 15728 games, reward 12.500, eps 0.01, speed 7.25 f/s\n183262 : done 15729 games, reward 12.200, eps 0.01, speed 6.90 f/s\n183278 : done 15730 games, reward 12.300, eps 0.01, speed 7.52 f/s\n183290 : done 15731 games, reward 12.400, eps 0.01, speed 7.68 f/s\n183310 : done 15732 games, reward 13.700, eps 0.01, speed 5.24 f/s\n183319 : done 15733 games, reward 13.500, eps 0.01, speed 7.85 f/s\n183339 : done 15734 games, reward 13.500, eps 0.01, speed 5.33 f/s\n183356 : done 15735 games, reward 14.200, eps 0.01, speed 7.38 f/s\n183376 : done 15736 games, reward 14.300, eps 0.01, speed 5.06 f/s\n183387 : done 15737 games, reward 14.300, eps 0.01, speed 4.09 f/s\n183398 : done 15738 games, reward 14.200, eps 0.01, speed 4.03 f/s\n183409 : done 15739 games, reward 14.300, eps 0.01, speed 4.82 f/s\n183427 : done 15740 games, reward 14.400, eps 0.01, speed 7.38 f/s\n183433 : done 15741 games, reward 13.800, eps 0.01, speed 4.92 f/s\n183444 : done 15742 games, reward 12.800, eps 0.01, speed 4.90 f/s\n183461 : done 15743 games, reward 13.700, eps 0.01, speed 6.43 f/s\n183474 : done 15744 games, reward 12.900, eps 0.01, speed 5.04 f/s\n183488 : done 15745 games, reward 12.600, eps 0.01, speed 7.38 f/s\n183496 : done 15746 games, reward 11.400, eps 0.01, speed 5.95 f/s\n183507 : done 15747 games, reward 11.400, eps 0.01, speed 5.02 f/s\n183515 : done 15748 games, reward 11.200, eps 0.01, speed 8.25 f/s\n183535 : done 15749 games, reward 12.200, eps 0.01, speed 5.50 f/s\n183545 : done 15750 games, reward 11.400, eps 0.01, speed 5.42 f/s\n183556 : done 15751 games, reward 11.800, eps 0.01, speed 5.34 f/s\n183576 : done 15752 games, reward 12.800, eps 0.01, speed 5.36 f/s\n183581 : done 15753 games, reward 11.600, eps 0.01, speed 7.83 f/s\n183593 : done 15754 games, reward 11.500, eps 0.01, speed 7.54 f/s\n183613 : done 15755 games, reward 12.100, eps 0.01, speed 4.75 f/s\n183624 : done 15756 games, reward 12.300, eps 0.01, speed 5.02 f/s\n183636 : done 15757 games, reward 12.400, eps 0.01, speed 6.74 f/s\n183656 : done 15758 games, reward 13.600, eps 0.01, speed 5.41 f/s\n183665 : done 15759 games, reward 12.500, eps 0.01, speed 7.39 f/s\n183685 : done 15760 games, reward 13.600, eps 0.01, speed 4.95 f/s\n183696 : done 15761 games, reward 13.600, eps 0.01, speed 4.74 f/s\n183713 : done 15762 games, reward 13.200, eps 0.01, speed 7.38 f/s\n183728 : done 15763 games, reward 14.200, eps 0.01, speed 7.16 f/s\n183738 : done 15764 games, reward 14.100, eps 0.01, speed 5.99 f/s\n183749 : done 15765 games, reward 13.100, eps 0.01, speed 4.65 f/s\n183765 : done 15766 games, reward 13.700, eps 0.01, speed 7.03 f/s\n183770 : done 15767 games, reward 13.000, eps 0.01, speed 6.03 f/s\n183790 : done 15768 games, reward 13.000, eps 0.01, speed 5.19 f/s\n183801 : done 15769 games, reward 13.100, eps 0.01, speed 4.81 f/s\n183814 : done 15770 games, reward 12.400, eps 0.01, speed 6.28 f/s\n183823 : done 15771 games, reward 12.300, eps 0.01, speed 7.86 f/s\n183835 : done 15772 games, reward 11.900, eps 0.01, speed 7.04 f/s\n183844 : done 15773 games, reward 11.300, eps 0.01, speed 7.10 f/s\n183858 : done 15774 games, reward 11.600, eps 0.01, speed 6.83 f/s\n183877 : done 15775 games, reward 12.500, eps 0.01, speed 7.23 f/s\n183888 : done 15776 games, reward 12.000, eps 0.01, speed 6.89 f/s\n183905 : done 15777 games, reward 13.200, eps 0.01, speed 7.04 f/s\n183925 : done 15778 games, reward 13.200, eps 0.01, speed 5.24 f/s\n183931 : done 15779 games, reward 12.800, eps 0.01, speed 6.75 f/s\n183941 : done 15780 games, reward 12.400, eps 0.01, speed 5.81 f/s\n183952 : done 15781 games, reward 12.500, eps 0.01, speed 4.91 f/s\n183959 : done 15782 games, reward 11.900, eps 0.01, speed 6.75 f/s\n183979 : done 15783 games, reward 13.000, eps 0.01, speed 4.90 f/s\n183990 : done 15784 games, reward 12.700, eps 0.01, speed 4.16 f/s\n184001 : done 15785 games, reward 11.800, eps 0.01, speed 4.58 f/s\n184012 : done 15786 games, reward 11.700, eps 0.01, speed 5.98 f/s\n184023 : done 15787 games, reward 11.100, eps 0.01, speed 4.27 f/s\n184034 : done 15788 games, reward 10.100, eps 0.01, speed 4.72 f/s\n184054 : done 15789 games, reward 11.500, eps 0.01, speed 5.29 f/s\n184066 : done 15790 games, reward 11.700, eps 0.01, speed 7.01 f/s\n184086 : done 15791 games, reward 12.700, eps 0.01, speed 5.34 f/s\n184106 : done 15792 games, reward 14.100, eps 0.01, speed 4.85 f/s\n184117 : done 15793 games, reward 13.100, eps 0.01, speed 4.82 f/s\n184130 : done 15794 games, reward 13.300, eps 0.01, speed 6.29 f/s\n184141 : done 15795 games, reward 13.300, eps 0.01, speed 4.56 f/s\n184151 : done 15796 games, reward 13.300, eps 0.01, speed 7.78 f/s\n184171 : done 15797 games, reward 14.300, eps 0.01, speed 5.02 f/s\n184182 : done 15798 games, reward 14.300, eps 0.01, speed 4.50 f/s\n184192 : done 15799 games, reward 13.200, eps 0.01, speed 6.38 f/s\n184203 : done 15800 games, reward 13.100, eps 0.01, speed 4.63 f/s\n184210 : done 15801 games, reward 11.800, eps 0.01, speed 5.32 f/s\n184221 : done 15802 games, reward 10.800, eps 0.01, speed 4.64 f/s\n184228 : done 15803 games, reward 10.500, eps 0.01, speed 7.53 f/s\n184235 : done 15804 games, reward 10.000, eps 0.01, speed 7.13 f/s\n184255 : done 15805 games, reward 11.000, eps 0.01, speed 5.52 f/s\n184272 : done 15806 games, reward 11.700, eps 0.01, speed 6.04 f/s\n184283 : done 15807 games, reward 10.700, eps 0.01, speed 4.47 f/s\n184291 : done 15808 games, reward 10.500, eps 0.01, speed 7.63 f/s\n184303 : done 15809 games, reward 10.700, eps 0.01, speed 6.97 f/s\n184310 : done 15810 games, reward 10.300, eps 0.01, speed 6.54 f/s\n184321 : done 15811 games, reward 10.700, eps 0.01, speed 6.48 f/s\n184341 : done 15812 games, reward 11.700, eps 0.01, speed 5.22 f/s\n184352 : done 15813 games, reward 12.100, eps 0.01, speed 6.34 f/s\n184371 : done 15814 games, reward 13.200, eps 0.01, speed 5.33 f/s\n184376 : done 15815 games, reward 11.700, eps 0.01, speed 6.84 f/s\n184389 : done 15816 games, reward 11.300, eps 0.01, speed 6.66 f/s\n184400 : done 15817 games, reward 11.300, eps 0.01, speed 4.62 f/s\n184412 : done 15818 games, reward 11.700, eps 0.01, speed 7.01 f/s\n184426 : done 15819 games, reward 11.900, eps 0.01, speed 7.76 f/s\n184446 : done 15820 games, reward 13.300, eps 0.01, speed 5.52 f/s\n184457 : done 15821 games, reward 13.300, eps 0.01, speed 6.47 f/s\n184477 : done 15822 games, reward 13.300, eps 0.01, speed 5.32 f/s\n184497 : done 15823 games, reward 14.200, eps 0.01, speed 5.45 f/s\n184509 : done 15824 games, reward 13.600, eps 0.01, speed 7.04 f/s\n184529 : done 15825 games, reward 15.100, eps 0.01, speed 5.28 f/s\n184549 : done 15826 games, reward 15.800, eps 0.01, speed 5.25 f/s\n184557 : done 15827 games, reward 15.600, eps 0.01, speed 6.70 f/s\n184577 : done 15828 games, reward 16.400, eps 0.01, speed 5.30 f/s\n184591 : done 15829 games, reward 16.500, eps 0.01, speed 7.33 f/s\n184598 : done 15830 games, reward 15.100, eps 0.01, speed 6.91 f/s\n184618 : done 15831 games, reward 16.000, eps 0.01, speed 5.29 f/s\n184638 : done 15832 games, reward 16.000, eps 0.01, speed 5.45 f/s\n184658 : done 15833 games, reward 16.000, eps 0.01, speed 5.58 f/s\n184678 : done 15834 games, reward 16.800, eps 0.01, speed 5.35 f/s\n184687 : done 15835 games, reward 15.700, eps 0.01, speed 7.21 f/s\n184698 : done 15836 games, reward 14.800, eps 0.01, speed 7.11 f/s\n184718 : done 15837 games, reward 16.000, eps 0.01, speed 5.26 f/s\n184726 : done 15838 games, reward 14.800, eps 0.01, speed 7.32 f/s\n184746 : done 15839 games, reward 15.400, eps 0.01, speed 5.09 f/s\n184766 : done 15840 games, reward 16.800, eps 0.01, speed 4.96 f/s\n184777 : done 15841 games, reward 15.800, eps 0.01, speed 4.63 f/s\n184784 : done 15842 games, reward 14.400, eps 0.01, speed 7.72 f/s\n184796 : done 15843 games, reward 13.500, eps 0.01, speed 4.72 f/s\n184809 : done 15844 games, reward 12.700, eps 0.01, speed 7.04 f/s\n184829 : done 15845 games, reward 13.800, eps 0.01, speed 5.17 f/s\n184840 : done 15846 games, reward 13.700, eps 0.01, speed 4.11 f/s\n184851 : done 15847 games, reward 12.700, eps 0.01, speed 4.85 f/s\n184871 : done 15848 games, reward 13.900, eps 0.01, speed 5.66 f/s\n184891 : done 15849 games, reward 13.900, eps 0.01, speed 5.62 f/s\n184902 : done 15850 games, reward 13.000, eps 0.01, speed 6.24 f/s\n184913 : done 15851 games, reward 13.000, eps 0.01, speed 4.58 f/s\n184933 : done 15852 games, reward 14.400, eps 0.01, speed 5.37 f/s\n184953 : done 15853 games, reward 15.300, eps 0.01, speed 5.40 f/s\n184965 : done 15854 games, reward 15.200, eps 0.01, speed 7.58 f/s\n184985 : done 15855 games, reward 15.200, eps 0.01, speed 5.59 f/s\n184990 : done 15856 games, reward 14.600, eps 0.01, speed 5.08 f/s\nSync\nAppend data\n185001 : done 15857 games, reward 14.600, eps 0.01, speed 4.78 f/s\n185015 : done 15858 games, reward 14.000, eps 0.01, speed 7.10 f/s\n185020 : done 15859 games, reward 12.400, eps 0.01, speed 4.34 f/s\n185036 : done 15860 games, reward 12.800, eps 0.01, speed 5.10 f/s\n185056 : done 15861 games, reward 13.800, eps 0.01, speed 5.28 f/s\n185070 : done 15862 games, reward 13.200, eps 0.01, speed 6.79 f/s\n185078 : done 15863 games, reward 12.000, eps 0.01, speed 5.94 f/s\n185089 : done 15864 games, reward 11.900, eps 0.01, speed 4.52 f/s\n185097 : done 15865 games, reward 10.600, eps 0.01, speed 7.75 f/s\n185105 : done 15866 games, reward 11.000, eps 0.01, speed 6.86 f/s\n185109 : done 15867 games, reward 10.300, eps 0.01, speed 7.76 f/s\n185129 : done 15868 games, reward 10.900, eps 0.01, speed 5.49 f/s\n185149 : done 15869 games, reward 12.500, eps 0.01, speed 4.90 f/s\n185160 : done 15870 games, reward 12.000, eps 0.01, speed 4.58 f/s\n185166 : done 15871 games, reward 10.600, eps 0.01, speed 7.70 f/s\n185186 : done 15872 games, reward 11.200, eps 0.01, speed 5.15 f/s\n185192 : done 15873 games, reward 11.000, eps 0.01, speed 5.77 f/s\n185212 : done 15874 games, reward 12.000, eps 0.01, speed 5.20 f/s\n185228 : done 15875 games, reward 12.800, eps 0.01, speed 6.23 f/s\n185239 : done 15876 games, reward 13.000, eps 0.01, speed 4.37 f/s\n185250 : done 15877 games, reward 13.700, eps 0.01, speed 4.47 f/s\n185261 : done 15878 games, reward 12.800, eps 0.01, speed 7.21 f/s\n185266 : done 15879 games, reward 11.200, eps 0.01, speed 6.04 f/s\n185281 : done 15880 games, reward 11.600, eps 0.01, speed 5.09 f/s\n185285 : done 15881 games, reward 11.300, eps 0.01, speed 6.19 f/s\n185305 : done 15882 games, reward 11.300, eps 0.01, speed 5.06 f/s\n185321 : done 15883 games, reward 12.300, eps 0.01, speed 6.47 f/s\n185332 : done 15884 games, reward 11.300, eps 0.01, speed 4.12 f/s\n185343 : done 15885 games, reward 10.800, eps 0.01, speed 4.57 f/s\n185347 : done 15886 games, reward 10.100, eps 0.01, speed 7.14 f/s\n185357 : done 15887 games, reward 10.100, eps 0.01, speed 6.79 f/s\n185366 : done 15888 games, reward 9.800, eps 0.01, speed 7.75 f/s\n185384 : done 15889 games, reward 11.100, eps 0.01, speed 6.37 f/s\n185400 : done 15890 games, reward 11.200, eps 0.01, speed 7.58 f/s\n185420 : done 15891 games, reward 12.900, eps 0.01, speed 5.16 f/s\n185429 : done 15892 games, reward 11.700, eps 0.01, speed 7.31 f/s\n185436 : done 15893 games, reward 10.700, eps 0.01, speed 6.43 f/s\n185450 : done 15894 games, reward 11.100, eps 0.01, speed 7.73 f/s\n185462 : done 15895 games, reward 11.300, eps 0.01, speed 6.92 f/s\n185471 : done 15896 games, reward 11.900, eps 0.01, speed 6.75 f/s\n185485 : done 15897 games, reward 12.200, eps 0.01, speed 7.55 f/s\n185490 : done 15898 games, reward 11.800, eps 0.01, speed 6.87 f/s\n185500 : done 15899 games, reward 11.000, eps 0.01, speed 6.05 f/s\n185511 : done 15900 games, reward 10.500, eps 0.01, speed 4.29 f/s\n185522 : done 15901 games, reward 9.500, eps 0.01, speed 4.35 f/s\n185533 : done 15902 games, reward 9.700, eps 0.01, speed 4.63 f/s\n185546 : done 15903 games, reward 10.400, eps 0.01, speed 6.76 f/s\n185557 : done 15904 games, reward 10.000, eps 0.01, speed 7.24 f/s\n185565 : done 15905 games, reward 9.600, eps 0.01, speed 7.32 f/s\n185585 : done 15906 games, reward 10.700, eps 0.01, speed 4.88 f/s\n185596 : done 15907 games, reward 10.400, eps 0.01, speed 5.08 f/s\n185616 : done 15908 games, reward 12.000, eps 0.01, speed 5.21 f/s\n185630 : done 15909 games, reward 12.500, eps 0.01, speed 6.85 f/s\n185636 : done 15910 games, reward 12.100, eps 0.01, speed 5.00 f/s\n185647 : done 15911 games, reward 12.100, eps 0.01, speed 4.12 f/s\n185658 : done 15912 games, reward 12.100, eps 0.01, speed 4.49 f/s\n185671 : done 15913 games, reward 12.100, eps 0.01, speed 7.16 f/s\n185680 : done 15914 games, reward 12.000, eps 0.01, speed 6.84 f/s\n185688 : done 15915 games, reward 12.000, eps 0.01, speed 5.95 f/s\n185708 : done 15916 games, reward 12.000, eps 0.01, speed 5.60 f/s\n185718 : done 15917 games, reward 11.900, eps 0.01, speed 7.28 f/s\n185731 : done 15918 games, reward 11.200, eps 0.01, speed 6.30 f/s\n185740 : done 15919 games, reward 10.700, eps 0.01, speed 8.24 f/s\n185760 : done 15920 games, reward 12.100, eps 0.01, speed 5.08 f/s\n185771 : done 15921 games, reward 12.100, eps 0.01, speed 4.70 f/s\n185784 : done 15922 games, reward 12.300, eps 0.01, speed 6.09 f/s\n185795 : done 15923 games, reward 12.000, eps 0.01, speed 4.58 f/s\n185812 : done 15924 games, reward 12.700, eps 0.01, speed 6.45 f/s\n185823 : done 15925 games, reward 12.900, eps 0.01, speed 4.60 f/s\n185843 : done 15926 games, reward 12.900, eps 0.01, speed 5.44 f/s\n185856 : done 15927 games, reward 13.200, eps 0.01, speed 7.59 f/s\n185871 : done 15928 games, reward 13.400, eps 0.01, speed 6.48 f/s\n185885 : done 15929 games, reward 13.900, eps 0.01, speed 6.14 f/s\n185896 : done 15930 games, reward 12.900, eps 0.01, speed 4.77 f/s\n185902 : done 15931 games, reward 12.400, eps 0.01, speed 6.88 f/s\n185912 : done 15932 games, reward 12.200, eps 0.01, speed 5.60 f/s\n185923 : done 15933 games, reward 12.200, eps 0.01, speed 4.22 f/s\n185934 : done 15934 games, reward 11.600, eps 0.01, speed 3.94 f/s\n185945 : done 15935 games, reward 11.600, eps 0.01, speed 4.26 f/s\n185956 : done 15936 games, reward 10.600, eps 0.01, speed 4.72 f/s\n185976 : done 15937 games, reward 11.400, eps 0.01, speed 5.67 f/s\n185985 : done 15938 games, reward 10.800, eps 0.01, speed 7.33 f/s\n185990 : done 15939 games, reward 9.800, eps 0.01, speed 6.43 f/s\n186009 : done 15940 games, reward 10.600, eps 0.01, speed 5.45 f/s\n186019 : done 15941 games, reward 11.000, eps 0.01, speed 6.46 f/s\n186029 : done 15942 games, reward 11.000, eps 0.01, speed 5.94 f/s\n186040 : done 15943 games, reward 11.000, eps 0.01, speed 4.66 f/s\n186060 : done 15944 games, reward 12.000, eps 0.01, speed 4.95 f/s\n186074 : done 15945 games, reward 12.300, eps 0.01, speed 5.19 f/s\n186094 : done 15946 games, reward 13.300, eps 0.01, speed 4.75 f/s\n186105 : done 15947 games, reward 12.300, eps 0.01, speed 4.10 f/s\n186116 : done 15948 games, reward 12.400, eps 0.01, speed 4.49 f/s\n186129 : done 15949 games, reward 13.200, eps 0.01, speed 5.03 f/s\n186141 : done 15950 games, reward 12.600, eps 0.01, speed 7.17 f/s\n186161 : done 15951 games, reward 13.700, eps 0.01, speed 5.20 f/s\n186181 : done 15952 games, reward 14.700, eps 0.01, speed 5.07 f/s\n186192 : done 15953 games, reward 14.700, eps 0.01, speed 4.77 f/s\n186208 : done 15954 games, reward 14.200, eps 0.01, speed 7.21 f/s\n186214 : done 15955 games, reward 13.500, eps 0.01, speed 6.31 f/s\n186234 : done 15956 games, reward 13.500, eps 0.01, speed 5.14 f/s\n"
    }
   ],
   "source": [
    "while True:\n",
    "    frame_idx += 1\n",
    "    epsilon = max(EPSILON_FINAL, EPSILON_START - frame_idx / EPSILON_DECAY_LAST_FRAME)   \n",
    "    reward = agent.play_step(net, epsilon, device=device)\n",
    "    if reward is not None:\n",
    "        total_rewards.append(reward)\n",
    "        speed = (frame_idx - ts_frame) / (time.time() - ts)\n",
    "        ts_frame = frame_idx\n",
    "        ts = time.time()\n",
    "        m_reward = np.mean(total_rewards[-10:])\n",
    "        print(\"%d : done %d games, reward %.3f, eps %.2f, speed %.2f f/s\" % (frame_idx, len(total_rewards), m_reward, epsilon, speed))\n",
    "\n",
    "        if best_m_reward is None or best_m_reward < m_reward :\n",
    "            if frame_idx < SYNC_TARGET_FRAMES:\n",
    "                continue\n",
    "            torch.save(net.state_dict(), \"best_%.0f.pth\" % m_reward)\n",
    "            if best_m_reward is not None:\n",
    "                print(\"Best reward updated %.3f -> %.3f\" % (best_m_reward, m_reward))\n",
    "            best_m_reward = m_reward\n",
    "\n",
    "    if len(buffer) < REPLAY_START_SIZE:\n",
    "        continue\n",
    "  \n",
    "    if frame_idx % SYNC_TARGET_FRAMES == 0:\n",
    "        tgt_net.load_state_dict(net.state_dict())\n",
    "        print(\"Sync\")\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    batch = buffer.sample(BATCH_SIZE)\n",
    "    loss_t = calc_loss(batch, net, tgt_net, device=device)\n",
    "    loss_t.backward()\n",
    "    optimizer.step() \n",
    "\n",
    "    if frame_idx is not 0 and frame_idx % SYNC_TARGET_FRAMES == 0:\n",
    "        reward_for_plot.append(reward)\n",
    "        mean_reward_for_plot.append(m_reward)\n",
    "        loss_for_plot.append(loss_t)\n",
    "        print(\"Append data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), \"best.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_env = make(\"connectx\")\n",
    "valid_env.reset()\n",
    "valid_trainer = valid_env.train([None, \"negamax\"])\n",
    "valid_observation = valid_trainer.reset()\n",
    "path = \"./weights/best_18.pth\"\n",
    "path2 = \"./win_best_17.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_network_action(q_vals_v, observation):\n",
    "    actions = torch.argsort(q_vals_v, descending=True, dim=1)\n",
    "    actions = actions.view(-1)\n",
    "\n",
    "    for action in actions:            \n",
    "        action = action.item()\n",
    "        if observation.board[action] == 0:                \n",
    "            return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_agent(observation, configuration):\n",
    "    rows, columns = configuration['rows'], configuration['columns']\n",
    "    input_shape = [1, rows, columns]\n",
    "    n_actions = columns\n",
    "\n",
    "    board = observation['board']\n",
    "    np_board = np.array(board)\n",
    "    np_board = np_board.reshape(1, rows, -1)\n",
    "    assert np_board.shape[2] == columns\n",
    "    \n",
    "    net = DQN(input_shape, n_actions)\n",
    "    net.load_state_dict(torch.load(path))\n",
    "    net.eval()\n",
    "\n",
    "    observation_v = torch.from_numpy(np_board).float()\n",
    "    q_vals_v = net(observation_v.unsqueeze(0))\n",
    "    action = select_network_action(q_vals_v, observation)\n",
    "\n",
    "    return int(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "action = my_agent(valid_observation, valid_env.configuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<iframe srcdoc=\"<!--\n  Copyright 2020 Kaggle Inc\n\n  Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);\n  you may not use this file except in compliance with the License.\n  You may obtain a copy of the License at\n\n      http://www.apache.org/licenses/LICENSE-2.0\n\n  Unless required by applicable law or agreed to in writing, software\n  distributed under the License is distributed on an &quot;AS IS&quot; BASIS,\n  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n  See the License for the specific language governing permissions and\n  limitations under the License.\n-->\n<!DOCTYPE html>\n<html lang=&quot;en&quot;>\n  <head>\n    <title>Kaggle Simulation Player</title>\n    <meta name=&quot;viewport&quot; content=&quot;width=device-width,initial-scale=1&quot; />\n    <link\n      rel=&quot;stylesheet&quot;\n      href=&quot;https://cdnjs.cloudflare.com/ajax/libs/meyer-reset/2.0/reset.css&quot;\n      crossorigin=&quot;anonymous&quot;\n    />\n    <style type=&quot;text/css&quot;>\n      html,\n      body {\n        height: 100%;\n        font-family: sans-serif;\n      }\n      canvas {\n        /* image-rendering: -moz-crisp-edges;\n        image-rendering: -webkit-crisp-edges;\n        image-rendering: pixelated;\n        image-rendering: crisp-edges; */\n      }\n    </style>\n    <script src=&quot;https://unpkg.com/preact@10.0.1/dist/preact.umd.js&quot;></script>\n    <script src=&quot;https://unpkg.com/preact@10.0.1/hooks/dist/hooks.umd.js&quot;></script>\n    <script src=&quot;https://unpkg.com/htm@2.2.1/dist/htm.umd.js&quot;></script>\n    <script>\n      // Polyfill for Styled Components\n      window.React = {\n        ...preact,\n        createElement: preact.h,\n        PropTypes: { func: {} },\n      };\n    </script>\n    <script src=&quot;https://unpkg.com/styled-components@3.5.0-0/dist/styled-components.min.js&quot;></script>\n  </head>\n  <body>\n    <script>\n      \nwindow.kaggle = {\n  &quot;debug&quot;: false,\n  &quot;autoplay&quot;: true,\n  &quot;step&quot;: 0,\n  &quot;controls&quot;: true,\n  &quot;environment&quot;: {\n    &quot;id&quot;: &quot;b521cc20-5bf4-11ea-b551-38d547ad5d4a&quot;,\n    &quot;name&quot;: &quot;connectx&quot;,\n    &quot;title&quot;: &quot;ConnectX&quot;,\n    &quot;description&quot;: &quot;Classic Connect in a row but configurable.&quot;,\n    &quot;version&quot;: &quot;1.0.0&quot;,\n    &quot;configuration&quot;: {\n      &quot;timeout&quot;: 5,\n      &quot;columns&quot;: 7,\n      &quot;rows&quot;: 6,\n      &quot;inarow&quot;: 4,\n      &quot;steps&quot;: 1000\n    },\n    &quot;specification&quot;: {\n      &quot;action&quot;: {\n        &quot;description&quot;: &quot;Column to drop a checker onto the board.&quot;,\n        &quot;type&quot;: &quot;integer&quot;,\n        &quot;minimum&quot;: 0,\n        &quot;default&quot;: 0\n      },\n      &quot;agents&quot;: [\n        2\n      ],\n      &quot;configuration&quot;: {\n        &quot;timeout&quot;: {\n          &quot;description&quot;: &quot;Seconds an agent can run before timing out.&quot;,\n          &quot;type&quot;: &quot;integer&quot;,\n          &quot;minimum&quot;: 1,\n          &quot;default&quot;: 5\n        },\n        &quot;columns&quot;: {\n          &quot;description&quot;: &quot;The number of columns on the board&quot;,\n          &quot;type&quot;: &quot;integer&quot;,\n          &quot;default&quot;: 7,\n          &quot;minimum&quot;: 1\n        },\n        &quot;rows&quot;: {\n          &quot;description&quot;: &quot;The number of rows on the board&quot;,\n          &quot;type&quot;: &quot;integer&quot;,\n          &quot;default&quot;: 6,\n          &quot;minimum&quot;: 1\n        },\n        &quot;inarow&quot;: {\n          &quot;description&quot;: &quot;The number of checkers in a row required to win.&quot;,\n          &quot;type&quot;: &quot;integer&quot;,\n          &quot;default&quot;: 4,\n          &quot;minimum&quot;: 1\n        },\n        &quot;steps&quot;: {\n          &quot;description&quot;: &quot;Maximum number of steps the environment can run.&quot;,\n          &quot;type&quot;: &quot;integer&quot;,\n          &quot;minimum&quot;: 1,\n          &quot;default&quot;: 1000\n        }\n      },\n      &quot;info&quot;: {},\n      &quot;observation&quot;: {\n        &quot;board&quot;: {\n          &quot;description&quot;: &quot;Serialized grid (rows x columns). 0 = Empty, 1 = P1, 2 = P2&quot;,\n          &quot;type&quot;: &quot;array&quot;,\n          &quot;default&quot;: []\n        },\n        &quot;mark&quot;: {\n          &quot;default&quot;: 0,\n          &quot;description&quot;: &quot;Which checkers are the agents.&quot;,\n          &quot;enum&quot;: [\n            1,\n            2\n          ]\n        }\n      },\n      &quot;reward&quot;: {\n        &quot;description&quot;: &quot;0 = Lost, 0.5 = Draw, 1 = Won&quot;,\n        &quot;enum&quot;: [\n          0,\n          0.5,\n          1\n        ],\n        &quot;default&quot;: 0.5,\n        &quot;type&quot;: [\n          &quot;number&quot;,\n          &quot;null&quot;\n        ]\n      },\n      &quot;reset&quot;: {\n        &quot;status&quot;: [\n          &quot;ACTIVE&quot;,\n          &quot;INACTIVE&quot;\n        ],\n        &quot;observation&quot;: [\n          {\n            &quot;mark&quot;: 1\n          },\n          {\n            &quot;mark&quot;: 2\n          }\n        ]\n      }\n    },\n    &quot;steps&quot;: [\n      [\n        {\n          &quot;action&quot;: 0,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0\n            ],\n            &quot;mark&quot;: 1\n          },\n          &quot;status&quot;: &quot;ACTIVE&quot;\n        },\n        {\n          &quot;action&quot;: 0,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0\n            ],\n            &quot;mark&quot;: 2\n          },\n          &quot;status&quot;: &quot;INACTIVE&quot;\n        }\n      ],\n      [\n        {\n          &quot;action&quot;: 6,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              1\n            ],\n            &quot;mark&quot;: 1\n          },\n          &quot;status&quot;: &quot;INACTIVE&quot;\n        },\n        {\n          &quot;action&quot;: 0,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              1\n            ],\n            &quot;mark&quot;: 2\n          },\n          &quot;status&quot;: &quot;ACTIVE&quot;\n        }\n      ],\n      [\n        {\n          &quot;action&quot;: 0,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              2,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              1\n            ],\n            &quot;mark&quot;: 1\n          },\n          &quot;status&quot;: &quot;ACTIVE&quot;\n        },\n        {\n          &quot;action&quot;: 6,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              2,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              1\n            ],\n            &quot;mark&quot;: 2\n          },\n          &quot;status&quot;: &quot;INACTIVE&quot;\n        }\n      ],\n      [\n        {\n          &quot;action&quot;: 6,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              1,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              2,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              1\n            ],\n            &quot;mark&quot;: 1\n          },\n          &quot;status&quot;: &quot;INACTIVE&quot;\n        },\n        {\n          &quot;action&quot;: 0,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              1,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              2,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              1\n            ],\n            &quot;mark&quot;: 2\n          },\n          &quot;status&quot;: &quot;ACTIVE&quot;\n        }\n      ],\n      [\n        {\n          &quot;action&quot;: 0,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              1,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              2,\n              0,\n              2,\n              0,\n              0,\n              0,\n              0,\n              1\n            ],\n            &quot;mark&quot;: 1\n          },\n          &quot;status&quot;: &quot;ACTIVE&quot;\n        },\n        {\n          &quot;action&quot;: 1,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              1,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              2,\n              0,\n              2,\n              0,\n              0,\n              0,\n              0,\n              1\n            ],\n            &quot;mark&quot;: 2\n          },\n          &quot;status&quot;: &quot;INACTIVE&quot;\n        }\n      ],\n      [\n        {\n          &quot;action&quot;: 0,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              1,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              2,\n              1,\n              2,\n              0,\n              0,\n              0,\n              0,\n              1\n            ],\n            &quot;mark&quot;: 1\n          },\n          &quot;status&quot;: &quot;INACTIVE&quot;\n        },\n        {\n          &quot;action&quot;: 0,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              1,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              2,\n              1,\n              2,\n              0,\n              0,\n              0,\n              0,\n              1\n            ],\n            &quot;mark&quot;: 2\n          },\n          &quot;status&quot;: &quot;ACTIVE&quot;\n        }\n      ],\n      [\n        {\n          &quot;action&quot;: 0,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              1,\n              0,\n              2,\n              0,\n              0,\n              0,\n              0,\n              2,\n              1,\n              2,\n              0,\n              0,\n              0,\n              0,\n              1\n            ],\n            &quot;mark&quot;: 1\n          },\n          &quot;status&quot;: &quot;ACTIVE&quot;\n        },\n        {\n          &quot;action&quot;: 1,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              1,\n              0,\n              2,\n              0,\n              0,\n              0,\n              0,\n              2,\n              1,\n              2,\n              0,\n              0,\n              0,\n              0,\n              1\n            ],\n            &quot;mark&quot;: 2\n          },\n          &quot;status&quot;: &quot;INACTIVE&quot;\n        }\n      ],\n      [\n        {\n          &quot;action&quot;: 3,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              1,\n              0,\n              2,\n              0,\n              0,\n              0,\n              0,\n              2,\n              1,\n              2,\n              0,\n              1,\n              0,\n              0,\n              1\n            ],\n            &quot;mark&quot;: 1\n          },\n          &quot;status&quot;: &quot;INACTIVE&quot;\n        },\n        {\n          &quot;action&quot;: 0,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              1,\n              0,\n              2,\n              0,\n              0,\n              0,\n              0,\n              2,\n              1,\n              2,\n              0,\n              1,\n              0,\n              0,\n              1\n            ],\n            &quot;mark&quot;: 2\n          },\n          &quot;status&quot;: &quot;ACTIVE&quot;\n        }\n      ],\n      [\n        {\n          &quot;action&quot;: 0,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              1,\n              0,\n              2,\n              0,\n              0,\n              0,\n              0,\n              2,\n              1,\n              2,\n              0,\n              1,\n              0,\n              2,\n              1\n            ],\n            &quot;mark&quot;: 1\n          },\n          &quot;status&quot;: &quot;ACTIVE&quot;\n        },\n        {\n          &quot;action&quot;: 5,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              1,\n              0,\n              2,\n              0,\n              0,\n              0,\n              0,\n              2,\n              1,\n              2,\n              0,\n              1,\n              0,\n              2,\n              1\n            ],\n            &quot;mark&quot;: 2\n          },\n          &quot;status&quot;: &quot;INACTIVE&quot;\n        }\n      ],\n      [\n        {\n          &quot;action&quot;: 2,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              1,\n              0,\n              2,\n              0,\n              0,\n              0,\n              0,\n              2,\n              1,\n              2,\n              1,\n              1,\n              0,\n              2,\n              1\n            ],\n            &quot;mark&quot;: 1\n          },\n          &quot;status&quot;: &quot;INACTIVE&quot;\n        },\n        {\n          &quot;action&quot;: 0,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              1,\n              0,\n              2,\n              0,\n              0,\n              0,\n              0,\n              2,\n              1,\n              2,\n              1,\n              1,\n              0,\n              2,\n              1\n            ],\n            &quot;mark&quot;: 2\n          },\n          &quot;status&quot;: &quot;ACTIVE&quot;\n        }\n      ],\n      [\n        {\n          &quot;action&quot;: 0,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              1,\n              0,\n              2,\n              0,\n              0,\n              0,\n              2,\n              2,\n              1,\n              2,\n              1,\n              1,\n              0,\n              2,\n              1\n            ],\n            &quot;mark&quot;: 1\n          },\n          &quot;status&quot;: &quot;ACTIVE&quot;\n        },\n        {\n          &quot;action&quot;: 5,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              1,\n              0,\n              2,\n              0,\n              0,\n              0,\n              2,\n              2,\n              1,\n              2,\n              1,\n              1,\n              0,\n              2,\n              1\n            ],\n            &quot;mark&quot;: 2\n          },\n          &quot;status&quot;: &quot;INACTIVE&quot;\n        }\n      ],\n      [\n        {\n          &quot;action&quot;: 5,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              1,\n              1,\n              0,\n              2,\n              0,\n              0,\n              0,\n              2,\n              2,\n              1,\n              2,\n              1,\n              1,\n              0,\n              2,\n              1\n            ],\n            &quot;mark&quot;: 1\n          },\n          &quot;status&quot;: &quot;INACTIVE&quot;\n        },\n        {\n          &quot;action&quot;: 0,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              1,\n              1,\n              0,\n              2,\n              0,\n              0,\n              0,\n              2,\n              2,\n              1,\n              2,\n              1,\n              1,\n              0,\n              2,\n              1\n            ],\n            &quot;mark&quot;: 2\n          },\n          &quot;status&quot;: &quot;ACTIVE&quot;\n        }\n      ],\n      [\n        {\n          &quot;action&quot;: 0,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              2,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              1,\n              1,\n              0,\n              2,\n              0,\n              0,\n              0,\n              2,\n              2,\n              1,\n              2,\n              1,\n              1,\n              0,\n              2,\n              1\n            ],\n            &quot;mark&quot;: 1\n          },\n          &quot;status&quot;: &quot;ACTIVE&quot;\n        },\n        {\n          &quot;action&quot;: 5,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              2,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              1,\n              1,\n              0,\n              2,\n              0,\n              0,\n              0,\n              2,\n              2,\n              1,\n              2,\n              1,\n              1,\n              0,\n              2,\n              1\n            ],\n            &quot;mark&quot;: 2\n          },\n          &quot;status&quot;: &quot;INACTIVE&quot;\n        }\n      ],\n      [\n        {\n          &quot;action&quot;: 5,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              1,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              2,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              1,\n              1,\n              0,\n              2,\n              0,\n              0,\n              0,\n              2,\n              2,\n              1,\n              2,\n              1,\n              1,\n              0,\n              2,\n              1\n            ],\n            &quot;mark&quot;: 1\n          },\n          &quot;status&quot;: &quot;INACTIVE&quot;\n        },\n        {\n          &quot;action&quot;: 0,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              1,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              2,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              1,\n              1,\n              0,\n              2,\n              0,\n              0,\n              0,\n              2,\n              2,\n              1,\n              2,\n              1,\n              1,\n              0,\n              2,\n              1\n            ],\n            &quot;mark&quot;: 2\n          },\n          &quot;status&quot;: &quot;ACTIVE&quot;\n        }\n      ],\n      [\n        {\n          &quot;action&quot;: 0,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              1,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              2,\n              0,\n              0,\n              2,\n              0,\n              0,\n              0,\n              1,\n              1,\n              0,\n              2,\n              0,\n              0,\n              0,\n              2,\n              2,\n              1,\n              2,\n              1,\n              1,\n              0,\n              2,\n              1\n            ],\n            &quot;mark&quot;: 1\n          },\n          &quot;status&quot;: &quot;ACTIVE&quot;\n        },\n        {\n          &quot;action&quot;: 1,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              1,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              2,\n              0,\n              0,\n              2,\n              0,\n              0,\n              0,\n              1,\n              1,\n              0,\n              2,\n              0,\n              0,\n              0,\n              2,\n              2,\n              1,\n              2,\n              1,\n              1,\n              0,\n              2,\n              1\n            ],\n            &quot;mark&quot;: 2\n          },\n          &quot;status&quot;: &quot;INACTIVE&quot;\n        }\n      ],\n      [\n        {\n          &quot;action&quot;: 1,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              1,\n              0,\n              0,\n              1,\n              0,\n              0,\n              0,\n              2,\n              0,\n              0,\n              2,\n              0,\n              0,\n              0,\n              1,\n              1,\n              0,\n              2,\n              0,\n              0,\n              0,\n              2,\n              2,\n              1,\n              2,\n              1,\n              1,\n              0,\n              2,\n              1\n            ],\n            &quot;mark&quot;: 1\n          },\n          &quot;status&quot;: &quot;INACTIVE&quot;\n        },\n        {\n          &quot;action&quot;: 0,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              1,\n              0,\n              0,\n              1,\n              0,\n              0,\n              0,\n              2,\n              0,\n              0,\n              2,\n              0,\n              0,\n              0,\n              1,\n              1,\n              0,\n              2,\n              0,\n              0,\n              0,\n              2,\n              2,\n              1,\n              2,\n              1,\n              1,\n              0,\n              2,\n              1\n            ],\n            &quot;mark&quot;: 2\n          },\n          &quot;status&quot;: &quot;ACTIVE&quot;\n        }\n      ],\n      [\n        {\n          &quot;action&quot;: 0,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              2,\n              0,\n              0,\n              0,\n              1,\n              0,\n              0,\n              1,\n              0,\n              0,\n              0,\n              2,\n              0,\n              0,\n              2,\n              0,\n              0,\n              0,\n              1,\n              1,\n              0,\n              2,\n              0,\n              0,\n              0,\n              2,\n              2,\n              1,\n              2,\n              1,\n              1,\n              0,\n              2,\n              1\n            ],\n            &quot;mark&quot;: 1\n          },\n          &quot;status&quot;: &quot;ACTIVE&quot;\n        },\n        {\n          &quot;action&quot;: 1,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              2,\n              0,\n              0,\n              0,\n              1,\n              0,\n              0,\n              1,\n              0,\n              0,\n              0,\n              2,\n              0,\n              0,\n              2,\n              0,\n              0,\n              0,\n              1,\n              1,\n              0,\n              2,\n              0,\n              0,\n              0,\n              2,\n              2,\n              1,\n              2,\n              1,\n              1,\n              0,\n              2,\n              1\n            ],\n            &quot;mark&quot;: 2\n          },\n          &quot;status&quot;: &quot;INACTIVE&quot;\n        }\n      ],\n      [\n        {\n          &quot;action&quot;: 4,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              2,\n              0,\n              0,\n              0,\n              1,\n              0,\n              0,\n              1,\n              0,\n              0,\n              0,\n              2,\n              0,\n              0,\n              2,\n              0,\n              0,\n              0,\n              1,\n              1,\n              0,\n              2,\n              0,\n              0,\n              0,\n              2,\n              2,\n              1,\n              2,\n              1,\n              1,\n              1,\n              2,\n              1\n            ],\n            &quot;mark&quot;: 1\n          },\n          &quot;status&quot;: &quot;INACTIVE&quot;\n        },\n        {\n          &quot;action&quot;: 0,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              2,\n              0,\n              0,\n              0,\n              1,\n              0,\n              0,\n              1,\n              0,\n              0,\n              0,\n              2,\n              0,\n              0,\n              2,\n              0,\n              0,\n              0,\n              1,\n              1,\n              0,\n              2,\n              0,\n              0,\n              0,\n              2,\n              2,\n              1,\n              2,\n              1,\n              1,\n              1,\n              2,\n              1\n            ],\n            &quot;mark&quot;: 2\n          },\n          &quot;status&quot;: &quot;ACTIVE&quot;\n        }\n      ],\n      [\n        {\n          &quot;action&quot;: 0,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              2,\n              0,\n              0,\n              0,\n              1,\n              0,\n              0,\n              1,\n              0,\n              0,\n              0,\n              2,\n              0,\n              0,\n              2,\n              0,\n              0,\n              0,\n              1,\n              1,\n              2,\n              2,\n              0,\n              0,\n              0,\n              2,\n              2,\n              1,\n              2,\n              1,\n              1,\n              1,\n              2,\n              1\n            ],\n            &quot;mark&quot;: 1\n          },\n          &quot;status&quot;: &quot;ACTIVE&quot;\n        },\n        {\n          &quot;action&quot;: 0,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              2,\n              0,\n              0,\n              0,\n              1,\n              0,\n              0,\n              1,\n              0,\n              0,\n              0,\n              2,\n              0,\n              0,\n              2,\n              0,\n              0,\n              0,\n              1,\n              1,\n              2,\n              2,\n              0,\n              0,\n              0,\n              2,\n              2,\n              1,\n              2,\n              1,\n              1,\n              1,\n              2,\n              1\n            ],\n            &quot;mark&quot;: 2\n          },\n          &quot;status&quot;: &quot;INACTIVE&quot;\n        }\n      ],\n      [\n        {\n          &quot;action&quot;: 0,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              2,\n              0,\n              0,\n              0,\n              1,\n              0,\n              0,\n              1,\n              0,\n              0,\n              0,\n              2,\n              0,\n              1,\n              2,\n              0,\n              0,\n              0,\n              1,\n              1,\n              2,\n              2,\n              0,\n              0,\n              0,\n              2,\n              2,\n              1,\n              2,\n              1,\n              1,\n              1,\n              2,\n              1\n            ],\n            &quot;mark&quot;: 1\n          },\n          &quot;status&quot;: &quot;INACTIVE&quot;\n        },\n        {\n          &quot;action&quot;: 0,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              2,\n              0,\n              0,\n              0,\n              1,\n              0,\n              0,\n              1,\n              0,\n              0,\n              0,\n              2,\n              0,\n              1,\n              2,\n              0,\n              0,\n              0,\n              1,\n              1,\n              2,\n              2,\n              0,\n              0,\n              0,\n              2,\n              2,\n              1,\n              2,\n              1,\n              1,\n              1,\n              2,\n              1\n            ],\n            &quot;mark&quot;: 2\n          },\n          &quot;status&quot;: &quot;ACTIVE&quot;\n        }\n      ],\n      [\n        {\n          &quot;action&quot;: 0,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              2,\n              0,\n              0,\n              0,\n              1,\n              0,\n              0,\n              1,\n              0,\n              0,\n              0,\n              2,\n              2,\n              1,\n              2,\n              0,\n              0,\n              0,\n              1,\n              1,\n              2,\n              2,\n              0,\n              0,\n              0,\n              2,\n              2,\n              1,\n              2,\n              1,\n              1,\n              1,\n              2,\n              1\n            ],\n            &quot;mark&quot;: 1\n          },\n          &quot;status&quot;: &quot;ACTIVE&quot;\n        },\n        {\n          &quot;action&quot;: 6,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              2,\n              0,\n              0,\n              0,\n              1,\n              0,\n              0,\n              1,\n              0,\n              0,\n              0,\n              2,\n              2,\n              1,\n              2,\n              0,\n              0,\n              0,\n              1,\n              1,\n              2,\n              2,\n              0,\n              0,\n              0,\n              2,\n              2,\n              1,\n              2,\n              1,\n              1,\n              1,\n              2,\n              1\n            ],\n            &quot;mark&quot;: 2\n          },\n          &quot;status&quot;: &quot;INACTIVE&quot;\n        }\n      ],\n      [\n        {\n          &quot;action&quot;: 4,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              2,\n              0,\n              0,\n              0,\n              1,\n              0,\n              0,\n              1,\n              0,\n              0,\n              0,\n              2,\n              2,\n              1,\n              2,\n              0,\n              0,\n              0,\n              1,\n              1,\n              2,\n              2,\n              0,\n              0,\n              1,\n              2,\n              2,\n              1,\n              2,\n              1,\n              1,\n              1,\n              2,\n              1\n            ],\n            &quot;mark&quot;: 1\n          },\n          &quot;status&quot;: &quot;INACTIVE&quot;\n        },\n        {\n          &quot;action&quot;: 0,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              2,\n              0,\n              0,\n              0,\n              1,\n              0,\n              0,\n              1,\n              0,\n              0,\n              0,\n              2,\n              2,\n              1,\n              2,\n              0,\n              0,\n              0,\n              1,\n              1,\n              2,\n              2,\n              0,\n              0,\n              1,\n              2,\n              2,\n              1,\n              2,\n              1,\n              1,\n              1,\n              2,\n              1\n            ],\n            &quot;mark&quot;: 2\n          },\n          &quot;status&quot;: &quot;ACTIVE&quot;\n        }\n      ],\n      [\n        {\n          &quot;action&quot;: 0,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              2,\n              0,\n              0,\n              0,\n              1,\n              0,\n              0,\n              1,\n              0,\n              0,\n              0,\n              2,\n              2,\n              1,\n              2,\n              0,\n              0,\n              0,\n              1,\n              1,\n              2,\n              2,\n              0,\n              2,\n              1,\n              2,\n              2,\n              1,\n              2,\n              1,\n              1,\n              1,\n              2,\n              1\n            ],\n            &quot;mark&quot;: 1\n          },\n          &quot;status&quot;: &quot;ACTIVE&quot;\n        },\n        {\n          &quot;action&quot;: 3,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              2,\n              0,\n              0,\n              0,\n              1,\n              0,\n              0,\n              1,\n              0,\n              0,\n              0,\n              2,\n              2,\n              1,\n              2,\n              0,\n              0,\n              0,\n              1,\n              1,\n              2,\n              2,\n              0,\n              2,\n              1,\n              2,\n              2,\n              1,\n              2,\n              1,\n              1,\n              1,\n              2,\n              1\n            ],\n            &quot;mark&quot;: 2\n          },\n          &quot;status&quot;: &quot;INACTIVE&quot;\n        }\n      ],\n      [\n        {\n          &quot;action&quot;: 5,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              1,\n              0,\n              0,\n              2,\n              0,\n              0,\n              0,\n              1,\n              0,\n              0,\n              1,\n              0,\n              0,\n              0,\n              2,\n              2,\n              1,\n              2,\n              0,\n              0,\n              0,\n              1,\n              1,\n              2,\n              2,\n              0,\n              2,\n              1,\n              2,\n              2,\n              1,\n              2,\n              1,\n              1,\n              1,\n              2,\n              1\n            ],\n            &quot;mark&quot;: 1\n          },\n          &quot;status&quot;: &quot;INACTIVE&quot;\n        },\n        {\n          &quot;action&quot;: 0,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              1,\n              0,\n              0,\n              2,\n              0,\n              0,\n              0,\n              1,\n              0,\n              0,\n              1,\n              0,\n              0,\n              0,\n              2,\n              2,\n              1,\n              2,\n              0,\n              0,\n              0,\n              1,\n              1,\n              2,\n              2,\n              0,\n              2,\n              1,\n              2,\n              2,\n              1,\n              2,\n              1,\n              1,\n              1,\n              2,\n              1\n            ],\n            &quot;mark&quot;: 2\n          },\n          &quot;status&quot;: &quot;ACTIVE&quot;\n        }\n      ],\n      [\n        {\n          &quot;action&quot;: 0,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              1,\n              0,\n              0,\n              2,\n              0,\n              0,\n              0,\n              1,\n              0,\n              0,\n              1,\n              0,\n              0,\n              0,\n              2,\n              2,\n              1,\n              2,\n              0,\n              2,\n              0,\n              1,\n              1,\n              2,\n              2,\n              0,\n              2,\n              1,\n              2,\n              2,\n              1,\n              2,\n              1,\n              1,\n              1,\n              2,\n              1\n            ],\n            &quot;mark&quot;: 1\n          },\n          &quot;status&quot;: &quot;ACTIVE&quot;\n        },\n        {\n          &quot;action&quot;: 3,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              1,\n              0,\n              0,\n              2,\n              0,\n              0,\n              0,\n              1,\n              0,\n              0,\n              1,\n              0,\n              0,\n              0,\n              2,\n              2,\n              1,\n              2,\n              0,\n              2,\n              0,\n              1,\n              1,\n              2,\n              2,\n              0,\n              2,\n              1,\n              2,\n              2,\n              1,\n              2,\n              1,\n              1,\n              1,\n              2,\n              1\n            ],\n            &quot;mark&quot;: 2\n          },\n          &quot;status&quot;: &quot;INACTIVE&quot;\n        }\n      ],\n      [\n        {\n          &quot;action&quot;: 1,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              1,\n              0,\n              0,\n              0,\n              1,\n              0,\n              0,\n              2,\n              0,\n              0,\n              0,\n              1,\n              0,\n              0,\n              1,\n              0,\n              0,\n              0,\n              2,\n              2,\n              1,\n              2,\n              0,\n              2,\n              0,\n              1,\n              1,\n              2,\n              2,\n              0,\n              2,\n              1,\n              2,\n              2,\n              1,\n              2,\n              1,\n              1,\n              1,\n              2,\n              1\n            ],\n            &quot;mark&quot;: 1\n          },\n          &quot;status&quot;: &quot;INACTIVE&quot;\n        },\n        {\n          &quot;action&quot;: 0,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              1,\n              0,\n              0,\n              0,\n              1,\n              0,\n              0,\n              2,\n              0,\n              0,\n              0,\n              1,\n              0,\n              0,\n              1,\n              0,\n              0,\n              0,\n              2,\n              2,\n              1,\n              2,\n              0,\n              2,\n              0,\n              1,\n              1,\n              2,\n              2,\n              0,\n              2,\n              1,\n              2,\n              2,\n              1,\n              2,\n              1,\n              1,\n              1,\n              2,\n              1\n            ],\n            &quot;mark&quot;: 2\n          },\n          &quot;status&quot;: &quot;ACTIVE&quot;\n        }\n      ],\n      [\n        {\n          &quot;action&quot;: 0,\n          &quot;reward&quot;: 0,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              1,\n              0,\n              0,\n              0,\n              1,\n              0,\n              0,\n              2,\n              0,\n              0,\n              0,\n              1,\n              0,\n              0,\n              1,\n              0,\n              0,\n              0,\n              2,\n              2,\n              1,\n              2,\n              0,\n              2,\n              0,\n              1,\n              1,\n              2,\n              2,\n              2,\n              2,\n              1,\n              2,\n              2,\n              1,\n              2,\n              1,\n              1,\n              1,\n              2,\n              1\n            ],\n            &quot;mark&quot;: 1\n          },\n          &quot;status&quot;: &quot;DONE&quot;\n        },\n        {\n          &quot;action&quot;: 2,\n          &quot;reward&quot;: 1,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              1,\n              0,\n              0,\n              0,\n              1,\n              0,\n              0,\n              2,\n              0,\n              0,\n              0,\n              1,\n              0,\n              0,\n              1,\n              0,\n              0,\n              0,\n              2,\n              2,\n              1,\n              2,\n              0,\n              2,\n              0,\n              1,\n              1,\n              2,\n              2,\n              2,\n              2,\n              1,\n              2,\n              2,\n              1,\n              2,\n              1,\n              1,\n              1,\n              2,\n              1\n            ],\n            &quot;mark&quot;: 2\n          },\n          &quot;status&quot;: &quot;DONE&quot;\n        }\n      ]\n    ],\n    &quot;rewards&quot;: [\n      0,\n      1\n    ],\n    &quot;statuses&quot;: [\n      &quot;DONE&quot;,\n      &quot;DONE&quot;\n    ],\n    &quot;schema_version&quot;: 1\n  },\n  &quot;mode&quot;: &quot;ipython&quot;,\n  &quot;width&quot;: 500,\n  &quot;height&quot;: 450\n};\n\n\nwindow.kaggle.renderer = // Copyright 2020 Kaggle Inc\n//\n// Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//      http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an &quot;AS IS&quot; BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\nfunction renderer({\n  act,\n  agents,\n  environment,\n  frame,\n  height = 400,\n  interactive,\n  isInteractive,\n  parent,\n  step,\n  update,\n  width = 400,\n}) {\n  // Configuration.\n  const { rows, columns, inarow } = environment.configuration;\n\n  // Common Dimensions.\n  const unit = 8;\n  const minCanvasSize = Math.min(height, width);\n  const minOffset = minCanvasSize > 400 ? 30 : unit / 2;\n  const cellSize = Math.min(\n    (width - minOffset * 2) / columns,\n    (height - minOffset * 2) / rows\n  );\n  const cellInset = 0.8;\n  const pieceScale = cellSize / 100;\n  const xOffset = Math.max(0, (width - cellSize * columns) / 2);\n  const yOffset = Math.max(0, (height - cellSize * rows) / 2);\n\n  // Canvas Setup.\n  let canvas = parent.querySelector(&quot;canvas&quot;);\n  if (!canvas) {\n    canvas = document.createElement(&quot;canvas&quot;);\n    parent.appendChild(canvas);\n\n    if (interactive) {\n      canvas.addEventListener(&quot;click&quot;, evt => {\n        if (!isInteractive()) return;\n        const rect = evt.target.getBoundingClientRect();\n        const col = Math.floor((evt.clientX - rect.left - xOffset) / cellSize);\n        if (col >= 0 && col < columns) act(col);\n      });\n    }\n  }\n  canvas.style.cursor = isInteractive() ? &quot;pointer&quot; : &quot;default&quot;;\n\n  // Character Paths (based on 100x100 tiles).\n  const kPath = new Path2D(\n    `M78.3,96.5c-0.1,0.4-0.5,0.6-1.1,0.6H64.9c-0.7,0-1.4-0.3-1.9-1l-20.3-26L37,75.5v20.1 c0,0.9-0.5,1.4-1.4,1.4H26c-0.9,0-1.4-0.5-1.4-1.4V3.9c0-0.9,0.5-1.4,1.4-1.4h9.5C36.5,2.5,37,3,37,3.9v56.5l24.3-24.7 c0.6-0.6,1.3-1,1.9-1H76c0.6,0,0.9,0.2,1.1,0.7c0.2,0.6,0.1,1-0.1,1.2l-25.7,25L78,95.1C78.4,95.5,78.5,95.9,78.3,96.5z`\n  );\n  const goose1Path = new Path2D(\n    `M8.8,92.7c-4-18.5,4.7-37.2,20.7-46.2c0,0,2.7-1.4,3.4-1.9c2.2-1.6,3-2.1,3-5c0-5-2.1-7.2-2.1-7.2 c-3.9-3.3-6.3-8.2-6.3-13.7c0-10,8.1-18.1,18.1-18.1s18.1,8.1,18.1,18.1c0,6-1.5,32.7-2.3,38.8l-0.1,1`\n  );\n  const goose2Path = new Path2D(\n    `M27.4,19L8.2,27.6c0,0-7.3,2.9,2.6,5c6.1,1.3,24,5.9,24,5.9l1,0.3`\n  );\n  const goose3Path = new Path2D(\n    `M63.7,99.6C52.3,99.6,43,90.3,43,78.9s9.3-20.7,20.7-20.7c10.6,0,34.4,0.1,35.8,9`\n  );\n\n  // Canvas setup and reset.\n  let c = canvas.getContext(&quot;2d&quot;);\n  canvas.width = width;\n  canvas.height = height;\n  c.fillStyle = &quot;#000B2A&quot;;\n  c.fillRect(0, 0, canvas.width, canvas.height);\n\n  const getRowCol = cell => [Math.floor(cell / columns), cell % columns];\n\n  const getColor = (mark, opacity = 1) => {\n    if (mark === 1) return `rgba(0,255,255,${opacity})`;\n    if (mark === 2) return `rgba(255,255,255,${opacity})`;\n    return &quot;#fff&quot;;\n  };\n\n  const drawCellCircle = (cell, xFrame = 1, yFrame = 1, radiusOffset = 0) => {\n    const [row, col] = getRowCol(cell);\n    c.arc(\n      xOffset + xFrame * (col * cellSize + cellSize / 2),\n      yOffset + yFrame * (row * cellSize + cellSize / 2),\n      (cellInset * cellSize) / 2 - radiusOffset,\n      2 * Math.PI,\n      false\n    );\n  };\n\n  // Render the pieces.\n  const board = environment.steps[step][0].observation.board;\n\n  const drawPiece = mark => {\n    // Base Styles.\n    const opacity = minCanvasSize < 300 ? 0.6 - minCanvasSize / 1000 : 0.1;\n    c.fillStyle = getColor(mark, opacity);\n    c.strokeStyle = getColor(mark);\n    c.shadowColor = getColor(mark);\n    c.shadowBlur = 8 / cellInset;\n    c.lineWidth = 1 / cellInset;\n\n    // Outer circle.\n    c.save();\n    c.beginPath();\n    c.arc(50, 50, 50, 2 * Math.PI, false);\n    c.closePath();\n    c.lineWidth *= 4;\n    c.stroke();\n    c.fill();\n    c.restore();\n\n    // Inner circle.\n    c.beginPath();\n    c.arc(50, 50, 40, 2 * Math.PI, false);\n    c.closePath();\n    c.stroke();\n\n    // Kaggle &quot;K&quot;.\n    if (mark === 1) {\n      const scale = 0.54;\n      c.save();\n      c.translate(23, 23);\n      c.scale(scale, scale);\n      c.lineWidth /= scale;\n      c.shadowBlur /= scale;\n      c.stroke(kPath);\n      c.restore();\n    }\n\n    // Kaggle &quot;Goose&quot;.\n    if (mark === 2) {\n      const scale = 0.6;\n      c.save();\n      c.translate(24, 28);\n      c.scale(scale, scale);\n      c.lineWidth /= scale;\n      c.shadowBlur /= scale;\n      c.stroke(goose1Path);\n      c.stroke(goose2Path);\n      c.stroke(goose3Path);\n      c.beginPath();\n      c.arc(38.5, 18.6, 2.7, 0, Math.PI * 2, false);\n      c.closePath();\n      c.fill();\n      c.restore();\n    }\n  };\n\n  for (let i = 0; i < board.length; i++) {\n    const [row, col] = getRowCol(i);\n    if (board[i] === 0) continue;\n    // Easing In.\n    let yFrame = Math.min(\n      (columns * Math.pow(frame, 3)) / Math.floor(i / columns),\n      1\n    );\n\n    if (\n      step > 1 &&\n      environment.steps[step - 1][0].observation.board[i] === board[i]\n    ) {\n      yFrame = 1;\n    }\n\n    c.save();\n    c.translate(\n      xOffset + cellSize * col + (cellSize - cellSize * cellInset) / 2,\n      yOffset +\n        yFrame * (cellSize * row) +\n        (cellSize - cellSize * cellInset) / 2\n    );\n    c.scale(pieceScale * cellInset, pieceScale * cellInset);\n    drawPiece(board[i]);\n    c.restore();\n  }\n\n  // Background Gradient.\n  const bgRadius = (Math.min(rows, columns) * cellSize) / 2;\n  const bgStyle = c.createRadialGradient(\n    xOffset + (cellSize * columns) / 2,\n    yOffset + (cellSize * rows) / 2,\n    0,\n    xOffset + (cellSize * columns) / 2,\n    yOffset + (cellSize * rows) / 2,\n    bgRadius\n  );\n  bgStyle.addColorStop(0, &quot;#000B49&quot;);\n  bgStyle.addColorStop(1, &quot;#000B2A&quot;);\n\n  // Render the board overlay.\n  c.beginPath();\n  c.rect(0, 0, canvas.width, canvas.height);\n  c.closePath();\n  c.shadowBlur = 0;\n  for (let i = 0; i < board.length; i++) {\n    drawCellCircle(i);\n    c.closePath();\n  }\n  c.fillStyle = bgStyle;\n  c.fill(&quot;evenodd&quot;);\n\n  // Render the board overlay cell outlines.\n  for (let i = 0; i < board.length; i++) {\n    c.beginPath();\n    drawCellCircle(i);\n    c.strokeStyle = &quot;#0361B2&quot;;\n    c.lineWidth = 1;\n    c.stroke();\n    c.closePath();\n  }\n\n  const drawLine = (fromCell, toCell) => {\n    if (frame < 0.5) return;\n    const lineFrame = (frame - 0.5) / 0.5;\n    const x1 = xOffset + (fromCell % columns) * cellSize + cellSize / 2;\n    const x2 =\n      x1 +\n      lineFrame *\n        (xOffset + ((toCell % columns) * cellSize + cellSize / 2) - x1);\n    const y1 =\n      yOffset + Math.floor(fromCell / columns) * cellSize + cellSize / 2;\n    const y2 =\n      y1 +\n      lineFrame *\n        (yOffset + Math.floor(toCell / columns) * cellSize + cellSize / 2 - y1);\n    c.beginPath();\n    c.lineCap = &quot;round&quot;;\n    c.lineWidth = 4;\n    c.strokeStyle = getColor(board[fromCell]);\n    c.shadowBlur = 8;\n    c.shadowColor = getColor(board[fromCell]);\n    c.moveTo(x1, y1);\n    c.lineTo(x2, y2);\n    c.stroke();\n  };\n\n  // Generate a graph of the board.\n  const getCell = (cell, rowOffset, columnOffset) => {\n    const row = Math.floor(cell / columns) + rowOffset;\n    const col = (cell % columns) + columnOffset;\n    if (row < 0 || row >= rows || col < 0 || col >= columns) return -1;\n    return col + row * columns;\n  };\n  const makeNode = cell => {\n    const node = { cell, directions: [], value: board[cell] };\n    for (let r = -1; r <= 1; r++) {\n      for (let c = -1; c <= 1; c++) {\n        if (r === 0 && c === 0) continue;\n        node.directions.push(getCell(cell, r, c));\n      }\n    }\n    return node;\n  };\n  const graph = board.map((_, i) => makeNode(i));\n\n  // Check for any wins!\n  const getSequence = (node, direction) => {\n    const sequence = [node.cell];\n    while (sequence.length < inarow) {\n      const next = graph[node.directions[direction]];\n      if (!next || node.value !== next.value || next.value === 0) return;\n      node = next;\n      sequence.push(node.cell);\n    }\n    return sequence;\n  };\n\n  // Check all nodes.\n  for (let i = 0; i < board.length; i++) {\n    // Check all directions (not the most efficient).\n    for (let d = 0; d < 8; d++) {\n      const seq = getSequence(graph[i], d);\n      if (seq) {\n        drawLine(seq[0], seq[3]);\n        i = board.length;\n        break;\n      }\n    }\n  }\n\n  // Upgrade the legend.\n  if (agents.length && (!agents[0].color || !agents[0].image)) {\n    const getPieceImage = mark => {\n      const pieceCanvas = document.createElement(&quot;canvas&quot;);\n      parent.appendChild(pieceCanvas);\n      pieceCanvas.style.marginLeft = &quot;10000px&quot;;\n      pieceCanvas.width = 100;\n      pieceCanvas.height = 100;\n      c = pieceCanvas.getContext(&quot;2d&quot;);\n      c.translate(10, 10);\n      c.scale(0.8, 0.8);\n      drawPiece(mark);\n      const dataUrl = pieceCanvas.toDataURL();\n      parent.removeChild(pieceCanvas);\n      return dataUrl;\n    };\n\n    agents.forEach(agent => {\n      agent.color = getColor(agent.index + 1);\n      agent.image = getPieceImage(agent.index + 1);\n    });\n    update({ agents });\n  }\n};\n\n\n    \n    </script>\n    <script>\n      const h = htm.bind(preact.h);\n      const { useContext, useEffect, useRef, useState } = preactHooks;\n      const styled = window.styled.default;\n\n      const Context = preact.createContext({});\n\n      const Loading = styled.div`\n        animation: rotate360 1.1s infinite linear;\n        border: 8px solid rgba(255, 255, 255, 0.2);\n        border-left-color: #0cb1ed;\n        border-radius: 50%;\n        height: 40px;\n        position: relative;\n        transform: translateZ(0);\n        width: 40px;\n\n        @keyframes rotate360 {\n          0% {\n            transform: rotate(0deg);\n          }\n          100% {\n            transform: rotate(360deg);\n          }\n        }\n      `;\n\n      const Logo = styled(\n        props => h`\n        <a href=&quot;https://kaggle.com&quot; target=&quot;_blank&quot; className=${props.className}>\n          <svg width=&quot;62px&quot; height=&quot;20px&quot; viewBox=&quot;0 0 62 24&quot; version=&quot;1.1&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;>\n            <g fill=&quot;#1EBEFF&quot; fill-rule=&quot;nonzero&quot;>\n              <path d=&quot;M10.2,17.8c0,0.1-0.1,0.1-0.2,0.1H7.7c-0.1,0-0.3-0.1-0.4-0.2l-3.8-4.9l-1.1,1v3.8 c0,0.2-0.1,0.3-0.3,0.3H0.3c-0.2,0-0.3-0.1-0.3-0.3V0.3C0.1,0.1,0.2,0,0.3,0h1.8c0.2,0,0.3,0.1,0.3,0.3V11L7,6.3 c0.1-0.1,0.2-0.2,0.4-0.2h2.4c0.1,0,0.2,0,0.2,0.1c0,0.1,0,0.2,0,0.2l-4.9,4.7l5.1,6.3C10.2,17.6,10.2,17.7,10.2,17.8z&quot;/>\n              <path d=&quot;M19.6,17.9h-1.8c-0.2,0-0.3-0.1-0.3-0.3v-0.4c-0.8,0.6-1.8,0.9-3,0.9c-1.1,0-2-0.3-2.8-1 c-0.8-0.7-1.2-1.6-1.2-2.7c0-1.7,1.1-2.9,3.2-3.5c0.8-0.2,2.1-0.5,3.8-0.6c0.1-0.6-0.1-1.2-0.5-1.7c-0.4-0.5-1-0.7-1.7-0.7 c-1,0-2,0.4-3,1C12.2,9.1,12.1,9.1,12,9l-0.9-1.3C11,7.5,11,7.4,11.1,7.3c1.3-0.9,2.7-1.4,4.2-1.4c1.1,0,2.1,0.3,2.8,0.8 c1.1,0.8,1.7,2,1.7,3.7v7.3C19.9,17.8,19.8,17.9,19.6,17.9z M17.5,12.4c-1.7,0.2-2.9,0.4-3.5,0.7c-0.9,0.4-1.2,0.9-1.1,1.6 c0.1,0.4,0.2,0.7,0.6,0.9c0.3,0.2,0.7,0.4,1.1,0.4c1.2,0.1,2.2-0.2,2.9-1V12.4z&quot;/>\n              <path d=&quot;M30.6,22.5c-0.9,1-2.3,1.5-4,1.5c-1,0-2-0.3-2.9-0.8c-0.2-0.1-0.4-0.3-0.7-0.5 c-0.3-0.2-0.6-0.5-0.9-0.7c-0.1-0.1-0.1-0.2,0-0.4l1.2-1.2c0.1-0.1,0.1-0.1,0.2-0.1c0.1,0,0.1,0,0.2,0.1c1,1,1.9,1.5,2.8,1.5 c2.1,0,3.2-1.1,3.2-3.3v-1.4c-0.8,0.7-1.9,1-3.3,1c-1.7,0-3-0.6-4-1.9c-0.8-1.1-1.3-2.5-1.3-4.2c0-1.6,0.4-3,1.2-4.1 c0.9-1.3,2.3-2,4-2c1.3,0,2.4,0.3,3.3,1V6.4c0-0.2,0.1-0.3,0.3-0.3h1.8c0.2,0,0.3,0.1,0.3,0.3v11.7C32,20,31.5,21.5,30.6,22.5z M29.7,9.9c-0.4-1.1-1.4-1.7-3-1.7c-2,0-3.1,1.3-3.1,3.8c0,1.4,0.3,2.4,1,3.1c0.5,0.5,1.2,0.8,2,0.8c1.6,0,2.7-0.6,3.1-1.7V9.9z&quot;/>\n              <path d=&quot;M42.9,22.5c-0.9,1-2.3,1.5-4,1.5c-1,0-2-0.3-2.9-0.8c-0.2-0.1-0.4-0.3-0.7-0.5 c-0.3-0.2-0.6-0.5-0.9-0.7c-0.1-0.1-0.1-0.2,0-0.4l1.2-1.2c0.1-0.1,0.1-0.1,0.2-0.1c0.1,0,0.1,0,0.2,0.1c1,1,1.9,1.5,2.8,1.5 c2.1,0,3.2-1.1,3.2-3.3v-1.4c-0.8,0.7-1.9,1-3.3,1c-1.7,0-3-0.6-4-1.9c-0.8-1.1-1.3-2.5-1.3-4.2c0-1.6,0.4-3,1.2-4.1 c0.9-1.3,2.3-2,4-2c1.3,0,2.4,0.3,3.3,1V6.4c0-0.2,0.1-0.3,0.3-0.3H44c0.2,0,0.3,0.1,0.3,0.3v11.7C44.3,20,43.8,21.5,42.9,22.5z M42,9.9c-0.4-1.1-1.4-1.7-3-1.7c-2,0-3.1,1.3-3.1,3.8c0,1.4,0.3,2.4,1,3.1c0.5,0.5,1.2,0.8,2,0.8c1.6,0,2.7-0.6,3.1-1.7L42,9.9 L42,9.9z&quot;/>\n              <path d=&quot;M48.3,17.9h-1.8c-0.2,0-0.3-0.1-0.3-0.3V0.3c0-0.2,0.1-0.3,0.3-0.3h1.8c0.2,0,0.3,0.1,0.3,0.3 v17.3C48.5,17.8,48.5,17.9,48.3,17.9z&quot;/>\n              <path d=&quot;M61.4,12.6c0,0.2-0.1,0.3-0.3,0.3h-8.5c0.1,0.9,0.5,1.6,1.1,2.2c0.7,0.6,1.6,0.9,2.7,0.9 c1,0,1.8-0.3,2.6-0.8c0.2-0.1,0.3-0.1,0.4,0l1.2,1.3c0.1,0.1,0.1,0.3,0,0.4c-1.3,0.9-2.7,1.4-4.4,1.4c-1.8,0-3.3-0.6-4.4-1.8 c-1.1-1.2-1.7-2.7-1.7-4.5c0-1.7,0.6-3.2,1.7-4.4c1-1.1,2.4-1.6,4.1-1.6c1.6,0,2.9,0.6,4,1.7c1.1,1.2,1.6,2.6,1.5,4.4L61.4,12.6 z M58,8.7c-0.6-0.5-1.3-0.8-2.1-0.8c-0.8,0-1.5,0.3-2.1,0.8c-0.6,0.5-1,1.2-1.1,2H59C59,9.9,58.6,9.3,58,8.7z&quot;/>\n            </g>\n          </svg>\n        </a>\n      `\n      )`\n        display: inline-flex;\n      `;\n\n      const Header = styled(props => {\n        const { environment } = useContext(Context);\n\n        return h`<div className=${props.className} >\n          <${Logo} />\n          ${environment.title}\n        </div>`;\n      })`\n        align-items: center;\n        border-bottom: 4px solid #212121;\n        box-sizing: border-box;\n        color: #fff;\n        display: flex;\n        flex: 0 0 36px;\n        font-size: 14px;\n        justify-content: space-between;\n        padding: 0 8px;\n        width: 100%;\n      `;\n\n      const Renderer = styled(props => {\n        const context = useContext(Context);\n        const { animate, debug, playing, renderer, speed } = context;\n        const ref = preact.createRef();\n\n        useEffect(async () => {\n          if (!ref.current) return;\n\n          const renderFrame = async (start, step, lastFrame) => {\n            if (step !== context.step) return;\n            if (lastFrame === 1) {\n              if (!animate) return;\n              start = Date.now();\n            }\n            const frame =\n              playing || animate\n                ? Math.min((Date.now() - start) / speed, 1)\n                : 1;\n            try {\n              if (debug) console.time(&quot;render&quot;);\n              await renderer({\n                ...context,\n                frame,\n                height: ref.current.clientHeight,\n                hooks: preactHooks,\n                parent: ref.current,\n                preact,\n                styled,\n                width: ref.current.clientWidth,\n              });\n            } catch (error) {\n              console.log({ ...context, frame, error });\n            } finally {\n              if (debug) console.timeEnd(&quot;render&quot;);\n            }\n            window.requestAnimationFrame(() => renderFrame(start, step, frame));\n          };\n\n          await renderFrame(Date.now(), context.step);\n        }, [ref.current, context.step, context.renderer]);\n\n        return h`<div className=${props.className} ref=${ref} />`;\n      })`\n        align-items: center;\n        box-sizing: border-box;\n        display: flex;\n        height: 100%;\n        left: 0;\n        justify-content: center;\n        position: absolute;\n        top: 0;\n        width: 100%;\n      `;\n\n      const Processing = styled(props => {\n        const { processing } = useContext(Context);\n        return h`<div className=${props.className}>Processing...</div>`;\n      })`\n        bottom: 0;\n        color: #fff;\n        font-size: 12px;\n        left: 0;\n        line-height: 24px;\n        position: absolute;\n        text-align: center;\n        width: 100%;\n      `;\n\n      const Viewer = styled(props => {\n        const { processing } = useContext(Context);\n        return h`<div className=${props.className}>\n          <${Renderer} />\n          ${processing && h`<${Processing} />`}\n        </div>`;\n      })`\n        background-color: #000b2a;\n        background-image: radial-gradient(\n          circle closest-side,\n          #000b49,\n          #000b2a\n        );\n        display: flex;\n        flex: 1;\n        overflow: hidden;\n        position: relative;\n        width: 100%;\n      `;\n\n      const Legend = styled(props => {\n        const { agents, legend } = useContext(Context);\n\n        return h`<div className=${props.className}>\n          <ul>\n            ${agents\n              .sort((a, b) => a.index - b.index)\n              .map(a => {\n                const name =\n                  a.name.length > 15 ? a.name.substr(0, 14) + &quot;&quot; : a.name;\n                return h`<li key=${a.id} title=&quot;id: ${\n                  a.id\n                }&quot; style=&quot;color:${a.color || &quot;#FFF&quot;}&quot;>${a.image &&\n                  h`<img src=${a.image} />`}${name}</li>`;\n              })}\n          </ul>\n        </div>`;\n      })`\n        background-color: #000b2a;\n        font-family: sans-serif;\n        font-size: 14px;\n        width: 100%;\n\n        ul {\n          align-items: center;\n          display: flex;\n          flex-direction: row;\n          justify-content: center;\n        }\n\n        li {\n          align-items: center;\n          display: inline-flex;\n          padding: 8px;\n          transition: color 1s;\n        }\n\n        img {\n          height: 24px;\n          margin-right: 4px;\n          width: 24px;\n        }\n      `;\n\n      const StepInput = styled.input.attrs({\n        type: &quot;range&quot;,\n      })`\n        appearance: none;\n        background: rgba(255, 255, 255, 0.15);\n        border-radius: 2px;\n        display: block;\n        flex: 1;\n        height: 4px;\n        opacity: 0.8;\n        outline: none;\n        transition: opacity 0.2s;\n        width: 100%;\n\n        &:hover {\n          opacity: 1;\n        }\n\n        &::-webkit-slider-thumb {\n          appearance: none;\n          background: #1ebeff;\n          border-radius: 100%;\n          cursor: pointer;\n          height: 12px;\n          margin: 0;\n          position: relative;\n          width: 12px;\n\n          &::after {\n            content: &quot;&quot;;\n            position: absolute;\n            top: 0px;\n            left: 0px;\n            width: 200px;\n            height: 8px;\n            background: green;\n          }\n        }\n      `;\n\n      const PlayButton = styled.button`\n        align-items: center;\n        background: none;\n        border: none;\n        color: white;\n        cursor: pointer;\n        display: flex;\n        flex: 0 0 56px;\n        font-size: 20px;\n        height: 40px;\n        justify-content: center;\n        opacity: 0.8;\n        outline: none;\n        transition: opacity 0.2s;\n\n        &:hover {\n          opacity: 1;\n        }\n      `;\n\n      const StepCount = styled.span`\n        align-items: center;\n        color: white;\n        display: flex;\n        font-size: 14px;\n        justify-content: center;\n        opacity: 0.8;\n        padding: 0 16px;\n        pointer-events: none;\n      `;\n\n      const Controls = styled(props => {\n        const { environment, pause, play, playing, setStep, step } = useContext(\n          Context\n        );\n        const value = step + 1;\n        const onClick = () => (playing ? pause() : play());\n        const onInput = e => {\n          pause();\n          setStep(parseInt(e.target.value) - 1);\n        };\n\n        return h`\n          <div className=${props.className}>\n            <${PlayButton} onClick=${onClick}><svg xmlns=&quot;http://www.w3.org/2000/svg&quot; width=&quot;24px&quot; height=&quot;24px&quot; viewBox=&quot;0 0 24 24&quot; fill=&quot;#FFFFFF&quot;>${\n          playing\n            ? h`<path d=&quot;M6 19h4V5H6v14zm8-14v14h4V5h-4z&quot;/><path d=&quot;M0 0h24v24H0z&quot; fill=&quot;none&quot;/>`\n            : h`<path d=&quot;M8 5v14l11-7z&quot;/><path d=&quot;M0 0h24v24H0z&quot; fill=&quot;none&quot;/>`\n        }</svg><//>\n            <${StepInput} min=&quot;1&quot; max=${\n          environment.steps.length\n        } value=&quot;${value}&quot; onInput=${onInput} />\n            <${StepCount}>${value} / ${environment.steps.length}<//>\n          </div>\n        `;\n      })`\n        align-items: center;\n        border-top: 4px solid #212121;\n        display: flex;\n        flex: 0 0 44px;\n        width: 100%;\n      `;\n\n      const Info = styled(props => {\n        const {\n          environment,\n          playing,\n          step,\n          speed,\n          animate,\n          header,\n          controls,\n          settings,\n        } = useContext(Context);\n\n        return h`\n          <div className=${props.className}>\n            info:\n            step(${step}),\n            playing(${playing ? &quot;T&quot; : &quot;F&quot;}),\n            speed(${speed}),\n            animate(${animate ? &quot;T&quot; : &quot;F&quot;})\n          </div>`;\n      })`\n        color: #888;\n        font-family: monospace;\n        font-size: 12px;\n      `;\n\n      const Settings = styled(props => {\n        const { environment, pause, play, playing, setStep, step } = useContext(\n          Context\n        );\n\n        return h`\n          <div className=${props.className}>\n            <${Info} />\n          </div>\n        `;\n      })`\n        background: #fff;\n        border-top: 4px solid #212121;\n        box-sizing: border-box;\n        padding: 20px;\n        width: 100%;\n\n        h1 {\n          font-size: 20px;\n        }\n      `;\n\n      const Player = styled(props => {\n        const context = useContext(Context);\n        const { agents, controls, header, legend, loading, settings } = context;\n        return h`\n          <div className=${props.className}>\n            ${loading && h`<${Loading} />`}\n            ${!loading && header && h`<${Header} />`}\n            ${!loading && h`<${Viewer} />`}\n            ${!loading && agents.length > 0 && legend && h`<${Legend} />`}\n            ${!loading && controls && h`<${Controls} />`}\n            ${!loading && settings && h`<${Settings} />`}\n          </div>`;\n      })`\n        align-items: center;\n        background: #212121;\n        border: 4px solid #212121;\n        box-sizing: border-box;\n        display: flex;\n        flex-direction: column;\n        height: 100%;\n        justify-content: center;\n        position: relative;\n        width: 100%;\n      `;\n\n      const App = () => {\n        const renderCountRef = useRef(0);\n        const [_, setRenderCount] = useState(0);\n\n        const contextRef = useRef({\n          animate: false,\n          agents: [],\n          autoplay: false,\n          controls: false,\n          debug: false,\n          environment: { steps: [] },\n          header: window.innerHeight >= 600,\n          interactive: false,\n          legend: true,\n          loading: false,\n          playing: false,\n          processing: false,\n          renderer: () => &quot;DNE&quot;,\n          settings: false,\n          speed: 500,\n          step: 0,\n        });\n\n        // Context helpers.\n        const rerender = (contextRef.current.rerender = () =>\n          setRenderCount((renderCountRef.current += 1)));\n        const setStep = (contextRef.current.setStep = newStep => {\n          contextRef.current.step = newStep;\n          rerender();\n        });\n        const setPlaying = (contextRef.current.setPlaying = playing => {\n          contextRef.current.playing = playing;\n          rerender();\n        });\n        const pause = (contextRef.current.pause = () => setPlaying(false));\n\n        const playNext = () => {\n          const context = contextRef.current;\n\n          if (\n            context.playing &&\n            context.step < context.environment.steps.length - 1\n          ) {\n            setStep(context.step + 1);\n            play(true);\n          } else {\n            pause();\n          }\n        };\n\n        const play = (contextRef.current.play = continuing => {\n          const context = contextRef.current;\n          if (context.playing && !continuing) return;\n          if (!context.playing) setPlaying(true);\n          if (\n            !continuing &&\n            context.step === context.environment.steps.length - 1\n          ) {\n            setStep(0);\n          }\n          setTimeout(playNext, context.speed);\n        });\n\n        const updateContext = o => {\n          const context = contextRef.current;\n          Object.assign(context, o, {\n            environment: { ...context.environment, ...(o.environment || {}) },\n          });\n          rerender();\n\n          // If autoplay, toggle to playing.\n          if (context.autoplay) play();\n        };\n\n        // First time setup.\n        useEffect(() => {\n          // Timeout is used to ensure useEffect renders once.\n          setTimeout(() => {\n            // Initialize context with window.kaggle.\n            updateContext(window.kaggle || {});\n            // Listen for messages received to update the context.\n            window.addEventListener(\n              &quot;message&quot;,\n              event => {\n                // Ensure the environment names match before updating.\n                try {\n                  if (\n                    event.data.environment.name ==\n                    contextRef.current.environment.name\n                  ) {\n                    updateContext(event.data);\n                  }\n                } catch {}\n              },\n              false\n            );\n            // Listen for keyboard commands.\n            window.addEventListener(\n              &quot;keyup&quot;,\n              event => {\n                const { playing, step, environment } = contextRef.current;\n                const key = event.keyCode;\n                if (key !== 32 && key !== 37 && key !== 39) return;\n\n                if (key === 32) {\n                  playing ? pause() : play();\n                } else if (event.keyCode === 39) {\n                  contextRef.current.playing = false;\n                  if (step < environment.steps.length - 1) setStep(step + 1);\n                  rerender();\n                } else if (event.keyCode === 37) {\n                  contextRef.current.playing = false;\n                  if (step > 0) setStep(step - 1);\n                  rerender();\n                }\n                event.preventDefault();\n                return false;\n              },\n              false\n            );\n          }, 1);\n        }, []);\n\n        if (contextRef.current.debug) {\n          console.log(&quot;context&quot;, contextRef.current);\n        }\n\n        // Ability to update context.\n        contextRef.current.update = updateContext;\n\n        // Ability to communicate with ipython.\n        const execute = (contextRef.current.execute = source =>\n          new Promise((resolve, reject) => {\n            try {\n              window.parent.IPython.notebook.kernel.execute(source, {\n                iopub: {\n                  output: resp => {\n                    const type = resp.msg_type;\n                    if (type === &quot;stream&quot;) return resolve(resp.content.text);\n                    if (type === &quot;error&quot;) return reject(new Error(resp.evalue));\n                    return reject(new Error(&quot;Unknown message type: &quot; + type));\n                  },\n                },\n              });\n            } catch (e) {\n              reject(new Error(&quot;IPython Unavailable: &quot; + e));\n            }\n          }));\n\n        // Ability to return an action from an interactive session.\n        contextRef.current.act = action => {\n          const id = contextRef.current.environment.id;\n          updateContext({ processing: true });\n          execute(`\n            import json\n            from kaggle_environments import interactives\n            if &quot;${id}&quot; in interactives:\n                action = json.loads('${JSON.stringify(action)}')\n                env, trainer = interactives[&quot;${id}&quot;]\n                trainer.step(action)\n                print(json.dumps(env.steps))`)\n            .then(resp => {\n              try {\n                updateContext({\n                  processing: false,\n                  environment: { steps: JSON.parse(resp) },\n                });\n                play();\n              } catch (e) {\n                console.error(resp, e);\n              }\n            })\n            .catch(e => console.error(e));\n        };\n\n        // Check if currently interactive.\n        contextRef.current.isInteractive = () => {\n          const context = contextRef.current;\n          const steps = context.environment.steps;\n          return (\n            context.interactive &&\n            !context.processing &&\n            context.step === steps.length - 1 &&\n            steps[context.step].some(s => s.status === &quot;ACTIVE&quot;)\n          );\n        };\n\n        return h`\n          <${Context.Provider} value=${contextRef.current}>\n            <${Player} />\n          <//>`;\n      };\n\n      preact.render(h`<${App} />`, document.body);\n    </script>\n  </body>\n</html>\n\" width=\"500\" height=\"450\" frameborder=\"0\"></iframe> ",
      "text/plain": "<IPython.core.display.HTML object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "valid_env.reset()\n",
    "valid_env.run([my_agent, \"random\"])\n",
    "valid_env.render(mode=\"ipython\", width=500, height=450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_reward(rewards):\n",
    "    return sum(r[0] for r in rewards) / sum(r[0] + r[1] for r in rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "My Agent vs Random Agent: 0.7\nMy Agent vs Negamax Agent: 1.0\n"
    }
   ],
   "source": [
    "print(\"My Agent vs. Random Agent:\", mean_reward(evaluate(\"connectx\", [my_agent, \"random\"], num_episodes=10)))\n",
    "print(\"My Agent vs. Negamax Agent:\", mean_reward(evaluate(\"connectx\", [my_agent, \"negamax\"], num_episodes=10)))\n",
    "print(\"Random Agent vs. My Agent:\", mean_reward(evaluate(\"connectx\", [\"random\", my_agent], num_episodes=10)))\n",
    "print(\"Negamax Agent vs. My Agent:\", mean_reward(evaluate(\"connectx\", [\"negamax\", my_agent], num_episodes=10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "<function my_agent at 0x7f40cfea29d0> written to submission.py\n"
    }
   ],
   "source": [
    "import inspect\n",
    "import os\n",
    "\n",
    "def write_agent_to_file(function, file):\n",
    "    with open(file, \"a\" if os.path.exists(file) else \"w\") as f:\n",
    "        f.write(inspect.getsource(function))\n",
    "        print(function, \"written to\", file)\n",
    "\n",
    "write_agent_to_file(my_agent, \"submission.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgument",
     "evalue": "No callable found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSyntaxError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/kaggle_environments/utils.py\u001b[0m in \u001b[0;36mget_exec\u001b[0;34m(raw, fallback)\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0mcode_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"<string>\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"exec\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSyntaxError\u001b[0m: EOL while scanning string literal (<string>, line 5)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgument\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/kaggle_environments/utils.py\u001b[0m in \u001b[0;36mget_last_callable\u001b[0;34m(raw, fallback)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0mlocal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_exec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         \u001b[0mcallables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/kaggle_environments/utils.py\u001b[0m in \u001b[0;36mget_exec\u001b[0;34m(raw, fallback)\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfallback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mInvalidArgument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid raw Python: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgument\u001b[0m: Invalid raw Python: EOL while scanning string literal (<string>, line 5)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgument\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-166-b3c0389ba38a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msubmission\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./submission_test.py\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0magent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_last_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubmission\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/kaggle_environments/utils.py\u001b[0m in \u001b[0;36mget_last_callable\u001b[0;34m(raw, fallback)\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfallback\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfallback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mInvalidArgument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No callable found\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgument\u001b[0m: No callable found"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "out = sys.stdout\n",
    "submission = utils.read_file(\"./submission_test.py\")\n",
    "agent = utils.get_last_callable(submission)\n",
    "sys.stdout = out\n",
    "\n",
    "env = make(\"connectx\", debug=True)\n",
    "env.run([agent, agent])\n",
    "print(\"Success!\" if env.state[0].status == env.state[1].status == \"DONE\" else \"Failed...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}