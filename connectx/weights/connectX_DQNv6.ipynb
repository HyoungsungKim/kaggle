{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.8.1-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python38164bit66f7a8720ea44564891eb6b9b39e6c03",
   "display_name": "Python 3.8.1 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "import collections\n",
    "import time\n",
    "\n",
    "from random import choice\n",
    "from kaggle_environments import evaluate, make, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Experience = collections.namedtuple('Experience', field_names=['observation', 'action', 'reward', 'done', 'new_observation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExperienceBuffer:\n",
    "    def __init__(self, capacity):\n",
    "        self.buffer = collections.deque(maxlen=capacity)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.buffer)\n",
    "\n",
    "    def append(self, experience):\n",
    "        self.buffer.append(experience)\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        # * Get a number of batch_size experience in a range of len(self.buffer)\n",
    "        # * It does not replace\n",
    "        indices = np.random.choice(len(self.buffer), batch_size, replace=False)\n",
    "\n",
    "        observation, actions, rewards, dones, next_observation = zip(*[self.buffer[idx] for idx in indices])\n",
    "        return np.array(observation), np.array(actions), np.array(rewards, dtype=np.float32), np.array(dones, dtype=np.uint8), np.array(next_observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Flatten, self).__init__()\n",
    "\n",
    "    def forward(self, shape):\n",
    "        return shape.view(shape.size()[0], -1)\n",
    "\n",
    "\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, input_shape, n_actions):\n",
    "        super(DQN, self).__init__()\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(input_shape[0], 32, kernel_size=3, padding = 1, stride=4),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=4, padding = 1, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding = 1, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "\n",
    "        conv_out_size = self._get_conv_out(input_shape)\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(conv_out_size, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, n_actions)\n",
    "        )\n",
    "\n",
    "    def _get_conv_out(self, input_shape):\n",
    "        # * To make 3D shape, we have to put 1 in torch.zeros\n",
    "        # * torch.zeros(1, 1, 52, 52)\n",
    "        # * -> troch.zeros(batch_dimension, *shape)\n",
    "        out = self.conv(torch.zeros(1, *input_shape))\n",
    "        return int(np.prod(out.size()))\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv_out = self.conv(x)\n",
    "        fc_out = self.fc(conv_out)\n",
    "        return fc_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "DQN(\n  (conv): Sequential(\n    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(4, 4), padding=(1, 1))\n    (1): ReLU()\n    (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n    (3): ReLU()\n    (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (5): ReLU()\n    (6): Flatten()\n  )\n  (fc): Sequential(\n    (0): Linear(in_features=2304, out_features=512, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=512, out_features=10, bias=True)\n  )\n)\n"
    },
    {
     "data": {
      "text/plain": "tensor([[ 0.0325, -0.0008, -0.0268,  0.0226,  0.0545, -0.0367,  0.0186, -0.0036,\n          0.0258,  0.0242]], grad_fn=<AddmmBackward>)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = torch.rand(1, 1, 52, 52)\n",
    "dqn = DQN(image[0].shape, 10)\n",
    "print(dqn)\n",
    "dqn(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /kaggle_environments/envs/connectx.py\n",
    "def is_win(board, column, mark, config, has_played=True):\n",
    "    columns = config.columns\n",
    "    rows = config.rows\n",
    "    inarow = config.inarow - 1\n",
    "    row = (\n",
    "        min([r for r in range(rows) if board[column + (r * columns)] == mark])\n",
    "        if has_played\n",
    "        else max([r for r in range(rows) if board[column + (r * columns)] == 0])\n",
    "    )\n",
    "\n",
    "    def count(offset_row, offset_column):\n",
    "        for i in range(1, inarow + 1):\n",
    "            r = row + offset_row * i\n",
    "            c = column + offset_column * i\n",
    "            if (\n",
    "                r < 0\n",
    "                or r >= rows\n",
    "                or c < 0\n",
    "                or c >= columns\n",
    "                or board[c + (r * columns)] != mark\n",
    "            ):\n",
    "                return i - 1\n",
    "        return inarow\n",
    "\n",
    "    return (\n",
    "        count(1, 0) >= inarow  # vertical.\n",
    "        or (count(0, 1) + count(0, -1)) >= inarow  # horizontal.\n",
    "        or (count(-1, -1) + count(1, 1)) >= inarow  # top left diagonal.\n",
    "        or (count(-1, 1) + count(1, -1)) >= inarow  # top right diagonal.\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, env, exp_buffer):\n",
    "        configuration = env.configuration\n",
    "        self.env = env\n",
    "        self.columns = configuration['columns']\n",
    "        self.rows = configuration['rows']        \n",
    "        self.exp_buffer = exp_buffer\n",
    "        self._reset()\n",
    "\n",
    "    def _reset(self):        \n",
    "        if np.random.random() < 0.5:        \n",
    "            self.trainer = self.env.train([None, \"random\"])\n",
    "           # print(\"random mode\")\n",
    "            self.trainer.reset()\n",
    "        else:\n",
    "            self.trainer = self.env.train([None, \"negamax\"])\n",
    "           # print(\"negamax mode\")\n",
    "            self.trainer.reset()\n",
    "\n",
    "        env_observation = self.trainer.reset()\n",
    "        self.mark = env_observation['mark']\n",
    "        self.board = env_observation['board']\n",
    "        np_board = np.array(self.board)\n",
    "        np_board = np_board.reshape(1, self.rows, -1)\n",
    "        assert np_board.shape[2] == self.columns\n",
    "\n",
    "        self.env.reset()\n",
    "        self.observation = np_board\n",
    "        self.total_reward = 0.0       \n",
    "\n",
    "    def _select_random_action(self):        \n",
    "        while True:\n",
    "            action = choice([c for c in range (self.columns) if self.board[c] == 0]) \n",
    "            if self.board[action] == 0:\n",
    "                return action\n",
    "\n",
    "    def _select_network_action(self, q_vals_v):\n",
    "        actions = torch.argsort(q_vals_v, descending=True, dim=1)\n",
    "        actions = actions.view(-1)\n",
    "\n",
    "        for action in actions:            \n",
    "            if self.board[action] == 0:                \n",
    "                return action.item()\n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def play_step(self, net, epsilon=0.0, device=\"cpu\"):\n",
    "        done_reward = None\n",
    "\n",
    "        if np.random.random() < epsilon:\n",
    "            action = self._select_random_action()\n",
    "        else:            \n",
    "            observation_v = torch.from_numpy(self.observation).float().to(device)\n",
    "            # Unsqueeze for batch size\n",
    "            # [batch_size, channel, row, column]\n",
    "            q_vals_v = net(observation_v.unsqueeze(0))\n",
    "            action = self._select_network_action(q_vals_v)   \n",
    "       \n",
    "        new_observation, reward, done, _ = self.trainer.step(action)        \n",
    "        \n",
    "        # For debuging\n",
    "        if reward == None:\n",
    "            print(\"INVALID\")\n",
    "            assert False\n",
    "                        \n",
    "        if done == False:\n",
    "            reward = 1                              \n",
    "   \n",
    "        self.total_reward += reward\n",
    "        self.board = new_observation['board']\n",
    "        if done == True and is_win(self.board, action, self.mark, self.env.configuration, has_played=True) == False:\n",
    "            reward = -30\n",
    "            #print(\"lose!\")\n",
    "\n",
    "        # Do not need to consider lose case. If agent can get high reward when it doen win        \n",
    "        if done == True and is_win(self.board, action, self.mark, self.env.configuration, has_played=True):\n",
    "            reward = 30\n",
    "            #print(\"WIN!\")\n",
    "\n",
    "        new_observation = np.array(self.board)\n",
    "        new_observation = new_observation.reshape(1, self.rows, -1)\n",
    "        assert new_observation.shape[2] == self.columns\n",
    "        \n",
    "        exp = Experience(self.observation, action, reward, done, new_observation)\n",
    "\n",
    "        self.exp_buffer.append(exp)\n",
    "        self.observation = new_observation\n",
    "\n",
    "        if done:\n",
    "            done_reward = self.total_reward\n",
    "            self._reset()     \n",
    "\n",
    "        return done_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "+---+---+---+---+---+---+---+\n| 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n+---+---+---+---+---+---+---+\n| 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n+---+---+---+---+---+---+---+\n| 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n+---+---+---+---+---+---+---+\n| 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n+---+---+---+---+---+---+---+\n| 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n+---+---+---+---+---+---+---+\n| 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n+---+---+---+---+---+---+---+\n\n"
    }
   ],
   "source": [
    "test_env = make(\"connectx\", debug=True)\n",
    "test_env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = test_env.configuration['columns']\n",
    "rows = test_env.configuration['rows']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_buffer = ExperienceBuffer(30)\n",
    "agent = Agent(test_env, test_buffer)\n",
    "epsilon = 1\n",
    "input_shape = [1, rows, columns]\n",
    "n_actions = columns\n",
    "net = DQN(input_shape, n_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "+---+---+---+---+---+---+---+\n| 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n+---+---+---+---+---+---+---+\n| 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n+---+---+---+---+---+---+---+\n| 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n+---+---+---+---+---+---+---+\n| 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n+---+---+---+---+---+---+---+\n| 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n+---+---+---+---+---+---+---+\n| 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n+---+---+---+---+---+---+---+\n\n"
    }
   ],
   "source": [
    "test_env.render()\n",
    "agent.play_step(net, epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "+---+---+---+---+---+---+---+\n| 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n+---+---+---+---+---+---+---+\n| 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n+---+---+---+---+---+---+---+\n| 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n+---+---+---+---+---+---+---+\n| 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n+---+---+---+---+---+---+---+\n| 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n+---+---+---+---+---+---+---+\n| 0 | 0 | 0 | 2 | 1 | 0 | 0 |\n+---+---+---+---+---+---+---+\n\n"
    }
   ],
   "source": [
    "test_env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(500):    \n",
    "    agent.play_step(net, epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation, actions, rewards, dones, next_observation = test_buffer.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[[[2, 1, 0, 0, 1, 0, 2],\n         [1, 2, 2, 0, 1, 0, 1],\n         [2, 1, 2, 0, 1, 0, 2],\n         [2, 2, 1, 0, 2, 0, 2],\n         [1, 1, 2, 0, 2, 1, 1],\n         [1, 2, 1, 1, 2, 2, 1]]],\n\n\n       [[[2, 1, 0, 0, 0, 0, 0],\n         [1, 2, 0, 0, 1, 0, 0],\n         [2, 1, 2, 0, 1, 0, 0],\n         [2, 2, 1, 0, 2, 0, 2],\n         [1, 1, 2, 0, 2, 0, 1],\n         [1, 2, 1, 0, 2, 0, 1]]],\n\n\n       [[[0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0]]],\n\n\n       [[[0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0]]],\n\n\n       [[[0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0],\n         [2, 0, 0, 0, 0, 0, 0],\n         [1, 0, 0, 2, 0, 0, 0],\n         [1, 1, 2, 1, 2, 2, 1]]],\n\n\n       [[[2, 1, 0, 0, 1, 0, 0],\n         [1, 2, 0, 0, 1, 0, 0],\n         [2, 1, 2, 0, 1, 0, 0],\n         [2, 2, 1, 0, 2, 0, 2],\n         [1, 1, 2, 0, 2, 0, 1],\n         [1, 2, 1, 0, 2, 2, 1]]],\n\n\n       [[[0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 2, 0, 0, 0],\n         [0, 0, 0, 1, 0, 0, 0],\n         [1, 0, 0, 2, 0, 0, 0]]],\n\n\n       [[[0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0],\n         [2, 0, 0, 0, 0, 0, 0],\n         [1, 0, 1, 2, 0, 2, 0],\n         [1, 1, 2, 1, 2, 2, 1]]],\n\n\n       [[[0, 1, 0, 0, 0, 0, 0],\n         [0, 2, 0, 0, 0, 0, 0],\n         [0, 1, 0, 0, 0, 0, 0],\n         [2, 2, 0, 0, 2, 0, 0],\n         [1, 1, 2, 0, 2, 0, 1],\n         [1, 2, 1, 0, 2, 0, 1]]],\n\n\n       [[[0, 1, 0, 0, 0, 0, 0],\n         [0, 2, 0, 0, 0, 0, 0],\n         [2, 1, 0, 0, 0, 0, 0],\n         [2, 2, 1, 0, 2, 0, 0],\n         [1, 1, 2, 0, 2, 0, 1],\n         [1, 2, 1, 0, 2, 0, 1]]]])"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([2, 4, 0, 6, 2, 5, 6, 3, 2, 4])"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=uint8)"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[[[2, 1, 1, 0, 1, 0, 2],\n         [1, 2, 2, 0, 1, 0, 1],\n         [2, 1, 2, 0, 1, 0, 2],\n         [2, 2, 1, 0, 2, 2, 2],\n         [1, 1, 2, 0, 2, 1, 1],\n         [1, 2, 1, 1, 2, 2, 1]]],\n\n\n       [[[2, 1, 0, 0, 1, 0, 0],\n         [1, 2, 0, 0, 1, 0, 0],\n         [2, 1, 2, 0, 1, 0, 0],\n         [2, 2, 1, 0, 2, 0, 2],\n         [1, 1, 2, 0, 2, 0, 1],\n         [1, 2, 1, 0, 2, 2, 1]]],\n\n\n       [[[0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0],\n         [1, 0, 0, 0, 2, 0, 0]]],\n\n\n       [[[0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 2, 0, 1]]],\n\n\n       [[[0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0],\n         [2, 0, 0, 0, 0, 0, 0],\n         [1, 0, 1, 2, 0, 2, 0],\n         [1, 1, 2, 1, 2, 2, 1]]],\n\n\n       [[[2, 1, 0, 0, 1, 0, 0],\n         [1, 2, 0, 0, 1, 0, 0],\n         [2, 1, 2, 0, 1, 0, 2],\n         [2, 2, 1, 0, 2, 0, 2],\n         [1, 1, 2, 0, 2, 1, 1],\n         [1, 2, 1, 0, 2, 2, 1]]],\n\n\n       [[[0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 2, 0, 0, 0],\n         [2, 0, 0, 1, 0, 0, 0],\n         [1, 0, 0, 2, 0, 0, 1]]],\n\n\n       [[[0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 2, 0, 0, 0],\n         [2, 0, 0, 1, 0, 0, 0],\n         [1, 0, 1, 2, 0, 2, 0],\n         [1, 1, 2, 1, 2, 2, 1]]],\n\n\n       [[[0, 1, 0, 0, 0, 0, 0],\n         [0, 2, 0, 0, 0, 0, 0],\n         [2, 1, 0, 0, 0, 0, 0],\n         [2, 2, 1, 0, 2, 0, 0],\n         [1, 1, 2, 0, 2, 0, 1],\n         [1, 2, 1, 0, 2, 0, 1]]],\n\n\n       [[[0, 1, 0, 0, 0, 0, 0],\n         [0, 2, 0, 0, 0, 0, 0],\n         [2, 1, 2, 0, 1, 0, 0],\n         [2, 2, 1, 0, 2, 0, 0],\n         [1, 1, 2, 0, 2, 0, 1],\n         [1, 2, 1, 0, 2, 0, 1]]]])"
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([  1.,   1.,   1.,   1., -10.,   1.,   1.,   1.,   1.,   1.],\n      dtype=float32)"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "2\n+---+---+---+---+---+---+---+\n| 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n+---+---+---+---+---+---+---+\n| 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n+---+---+---+---+---+---+---+\n| 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n+---+---+---+---+---+---+---+\n| 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n+---+---+---+---+---+---+---+\n| 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n+---+---+---+---+---+---+---+\n| 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n+---+---+---+---+---+---+---+\n\n"
    }
   ],
   "source": [
    "agent.play_step(net, epsilon)\n",
    "test_env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss(batch, net, tgt_net, device='cpu'):\n",
    "    observation, actions, rewards, dones, next_observation = batch\n",
    "\n",
    "    observation_v = torch.from_numpy(observation).float().to(device)\n",
    "    next_observation_v = torch.from_numpy(next_observation).float().to(device)\n",
    "    action_v = torch.from_numpy(actions).to(device)\n",
    "    rewards_v = torch.from_numpy(rewards).to(device)\n",
    "    done_mask = torch.from_numpy(dones).to(device)\n",
    "\n",
    "    state_action_value = net(observation_v).gather(1, action_v.unsqueeze(-1)).squeeze(-1)\n",
    "    with torch.no_grad():\n",
    "        next_observation_values = tgt_net(next_observation_v).max(1)[0]\n",
    "        next_observation_values[done_mask] = 0.0\n",
    "        next_observation_values = next_observation_values.detach()\n",
    "\n",
    "    expected_state_action_values = next_observation_values * GAMMA + rewards_v\n",
    "\n",
    "    loss = nn.MSELoss()\n",
    "    return loss(state_action_value, expected_state_action_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAMMA = 0.99\n",
    "BATCH_SIZE = 4096\n",
    "REPLAY_SIZE = 1000000\n",
    "LEARNING_RATE = 1e-4\n",
    "SYNC_TARGET_FRAMES = 5000\n",
    "REPLAY_START_SIZE = 10000\n",
    "\n",
    "EPSILON_DECAY_LAST_FRAME = 300000\n",
    "EPSILON_START = 1.0\n",
    "EPSILON_FINAL = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Run using cuda\n"
    }
   ],
   "source": [
    "env = make(\"connectx\", debug=True)\n",
    "rows, columns = env.configuration['rows'], env.configuration['columns']\n",
    "input_shape = [1, rows, columns]\n",
    "n_actions = columns\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available else 'cpu')\n",
    "print(f\"Run using {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = DQN(input_shape, n_actions).to(device)    \n",
    "tgt_net = DQN(input_shape, n_actions).to(device)\n",
    "\n",
    "buffer = ExperienceBuffer(REPLAY_SIZE)\n",
    "agent = Agent(env, buffer)\n",
    "epsilon = EPSILON_START\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=LEARNING_RATE)\n",
    "total_rewards = []\n",
    "frame_idx = 0\n",
    "ts_frame = 0\n",
    "ts = time.time()\n",
    "best_m_reward = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_for_plot = []\n",
    "mean_reward_for_plot = []\n",
    "loss_for_plot = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "5 : done 2479 games, reward 11.000, eps 0.93, speed 31.97 f/s\n22250 : done 2480 games, reward 10.200, eps 0.93, speed 9.03 f/s\n22255 : done 2481 games, reward 8.600, eps 0.93, speed 9.75 f/s\n22263 : done 2482 games, reward 7.800, eps 0.93, speed 32.33 f/s\n22275 : done 2483 games, reward 8.000, eps 0.93, speed 31.46 f/s\n22281 : done 2484 games, reward 8.100, eps 0.93, speed 29.97 f/s\n22295 : done 2485 games, reward 9.100, eps 0.93, speed 31.34 f/s\n22309 : done 2486 games, reward 8.700, eps 0.93, speed 29.68 f/s\n22313 : done 2487 games, reward 8.000, eps 0.93, speed 8.85 f/s\n22322 : done 2488 games, reward 8.500, eps 0.93, speed 31.97 f/s\n22327 : done 2489 games, reward 7.700, eps 0.93, speed 7.87 f/s\n22331 : done 2490 games, reward 7.600, eps 0.93, speed 9.02 f/s\n22339 : done 2491 games, reward 8.000, eps 0.93, speed 28.72 f/s\n22350 : done 2492 games, reward 8.200, eps 0.93, speed 10.14 f/s\n22367 : done 2493 games, reward 8.600, eps 0.93, speed 13.02 f/s\n22371 : done 2494 games, reward 8.300, eps 0.93, speed 8.13 f/s\n22384 : done 2495 games, reward 8.300, eps 0.93, speed 30.34 f/s\n22397 : done 2496 games, reward 8.100, eps 0.93, speed 12.70 f/s\n22410 : done 2497 games, reward 9.000, eps 0.93, speed 12.35 f/s\n22420 : done 2498 games, reward 9.000, eps 0.93, speed 10.10 f/s\n22430 : done 2499 games, reward 9.500, eps 0.93, speed 28.98 f/s\n22437 : done 2500 games, reward 9.800, eps 0.93, speed 9.26 f/s\n22450 : done 2501 games, reward 10.300, eps 0.93, speed 31.54 f/s\n22464 : done 2502 games, reward 10.700, eps 0.93, speed 30.19 f/s\n22468 : done 2503 games, reward 9.400, eps 0.93, speed 8.20 f/s\n22483 : done 2504 games, reward 10.500, eps 0.93, speed 30.55 f/s\n22495 : done 2505 games, reward 10.400, eps 0.93, speed 29.37 f/s\n22505 : done 2506 games, reward 10.100, eps 0.92, speed 9.23 f/s\n22509 : done 2507 games, reward 9.200, eps 0.92, speed 8.86 f/s\n22517 : done 2508 games, reward 9.000, eps 0.92, speed 32.09 f/s\n22524 : done 2509 games, reward 8.700, eps 0.92, speed 8.51 f/s\n22545 : done 2510 games, reward 10.100, eps 0.92, speed 16.19 f/s\n22551 : done 2511 games, reward 9.300, eps 0.92, speed 32.34 f/s\n22555 : done 2512 games, reward 8.200, eps 0.92, speed 9.43 f/s\n22564 : done 2513 games, reward 8.700, eps 0.92, speed 9.86 f/s\n22568 : done 2514 games, reward 7.600, eps 0.92, speed 8.41 f/s\n22572 : done 2515 games, reward 6.700, eps 0.92, speed 8.07 f/s\n22582 : done 2516 games, reward 6.700, eps 0.92, speed 31.54 f/s\n22586 : done 2517 games, reward 6.700, eps 0.92, speed 8.40 f/s\n22590 : done 2518 games, reward 6.300, eps 0.92, speed 8.20 f/s\n22594 : done 2519 games, reward 6.000, eps 0.92, speed 9.10 f/s\n22602 : done 2520 games, reward 4.800, eps 0.92, speed 32.07 f/s\n22614 : done 2521 games, reward 5.400, eps 0.92, speed 11.92 f/s\n22624 : done 2522 games, reward 6.100, eps 0.92, speed 30.02 f/s\n22638 : done 2523 games, reward 6.700, eps 0.92, speed 32.32 f/s\n22648 : done 2524 games, reward 7.300, eps 0.92, speed 29.14 f/s\n22659 : done 2525 games, reward 8.000, eps 0.92, speed 12.06 f/s\n22669 : done 2526 games, reward 8.100, eps 0.92, speed 30.61 f/s\n22673 : done 2527 games, reward 8.100, eps 0.92, speed 8.38 f/s\n22677 : done 2528 games, reward 8.100, eps 0.92, speed 8.58 f/s\n22685 : done 2529 games, reward 8.500, eps 0.92, speed 8.27 f/s\n22702 : done 2530 games, reward 9.400, eps 0.92, speed 12.80 f/s\n22709 : done 2531 games, reward 9.000, eps 0.92, speed 29.13 f/s\n22722 : done 2532 games, reward 9.200, eps 0.92, speed 13.16 f/s\n22729 : done 2533 games, reward 8.500, eps 0.92, speed 30.86 f/s\n22733 : done 2534 games, reward 7.900, eps 0.92, speed 8.74 f/s\n22741 : done 2535 games, reward 7.600, eps 0.92, speed 27.74 f/s\n22746 : done 2536 games, reward 7.000, eps 0.92, speed 8.02 f/s\n22755 : done 2537 games, reward 7.600, eps 0.92, speed 31.83 f/s\n22761 : done 2538 games, reward 7.900, eps 0.92, speed 29.78 f/s\n22776 : done 2539 games, reward 8.700, eps 0.92, speed 31.11 f/s\n22788 : done 2540 games, reward 8.100, eps 0.92, speed 11.27 f/s\n22798 : done 2541 games, reward 8.400, eps 0.92, speed 29.01 f/s\n22810 : done 2542 games, reward 8.300, eps 0.92, speed 10.68 f/s\n22814 : done 2543 games, reward 7.900, eps 0.92, speed 8.59 f/s\n22819 : done 2544 games, reward 8.100, eps 0.92, speed 30.64 f/s\n22833 : done 2545 games, reward 8.700, eps 0.92, speed 32.38 f/s\n22846 : done 2546 games, reward 9.500, eps 0.92, speed 11.35 f/s\n22851 : done 2547 games, reward 9.000, eps 0.92, speed 8.07 f/s\n22857 : done 2548 games, reward 8.900, eps 0.92, speed 8.00 f/s\n22864 : done 2549 games, reward 8.000, eps 0.92, speed 32.17 f/s\n22875 : done 2550 games, reward 7.900, eps 0.92, speed 29.89 f/s\n22880 : done 2551 games, reward 7.300, eps 0.92, speed 9.25 f/s\n22894 : done 2552 games, reward 7.500, eps 0.92, speed 32.54 f/s\n22905 : done 2553 games, reward 8.200, eps 0.92, speed 29.98 f/s\n22918 : done 2554 games, reward 9.000, eps 0.92, speed 31.80 f/s\n22931 : done 2555 games, reward 8.900, eps 0.92, speed 29.89 f/s\n22935 : done 2556 games, reward 8.000, eps 0.92, speed 8.56 f/s\n22940 : done 2557 games, reward 8.000, eps 0.92, speed 8.78 f/s\n22947 : done 2558 games, reward 8.100, eps 0.92, speed 31.23 f/s\n22956 : done 2559 games, reward 8.400, eps 0.92, speed 30.88 f/s\n22970 : done 2560 games, reward 8.800, eps 0.92, speed 29.82 f/s\n22980 : done 2561 games, reward 9.300, eps 0.92, speed 30.64 f/s\n22985 : done 2562 games, reward 8.500, eps 0.92, speed 32.38 f/s\n22998 : done 2563 games, reward 8.700, eps 0.92, speed 29.71 f/s\n23014 : done 2564 games, reward 8.900, eps 0.92, speed 12.54 f/s\n23018 : done 2565 games, reward 8.000, eps 0.92, speed 8.42 f/s\n23026 : done 2566 games, reward 8.500, eps 0.92, speed 31.61 f/s\n23031 : done 2567 games, reward 8.500, eps 0.92, speed 7.82 f/s\n23042 : done 2568 games, reward 9.000, eps 0.92, speed 32.08 f/s\n23046 : done 2569 games, reward 8.400, eps 0.92, speed 8.32 f/s\n23056 : done 2570 games, reward 7.900, eps 0.92, speed 11.34 f/s\n23068 : done 2571 games, reward 8.100, eps 0.92, speed 30.38 f/s\n23073 : done 2572 games, reward 8.000, eps 0.92, speed 7.77 f/s\n23082 : done 2573 games, reward 7.600, eps 0.92, speed 9.92 f/s\n23087 : done 2574 games, reward 6.500, eps 0.92, speed 9.88 f/s\n23091 : done 2575 games, reward 6.500, eps 0.92, speed 9.05 f/s\n23095 : done 2576 games, reward 6.000, eps 0.92, speed 8.55 f/s\n23105 : done 2577 games, reward 6.500, eps 0.92, speed 30.94 f/s\n23115 : done 2578 games, reward 6.300, eps 0.92, speed 32.63 f/s\n23126 : done 2579 games, reward 7.100, eps 0.92, speed 32.68 f/s\n23134 : done 2580 games, reward 6.900, eps 0.92, speed 26.97 f/s\n23149 : done 2581 games, reward 7.300, eps 0.92, speed 31.08 f/s\n23160 : done 2582 games, reward 8.000, eps 0.92, speed 29.99 f/s\n23165 : done 2583 games, reward 7.600, eps 0.92, speed 25.35 f/s\n23179 : done 2584 games, reward 8.500, eps 0.92, speed 10.78 f/s\n23188 : done 2585 games, reward 9.100, eps 0.92, speed 32.42 f/s\n23205 : done 2586 games, reward 10.400, eps 0.92, speed 12.74 f/s\n23219 : done 2587 games, reward 10.800, eps 0.92, speed 29.80 f/s\n23223 : done 2588 games, reward 10.200, eps 0.92, speed 9.28 f/s\n23239 : done 2589 games, reward 10.600, eps 0.92, speed 29.52 f/s\n23243 : done 2590 games, reward 10.200, eps 0.92, speed 8.09 f/s\n23252 : done 2591 games, reward 9.600, eps 0.92, speed 31.95 f/s\n23259 : done 2592 games, reward 9.100, eps 0.92, speed 8.07 f/s\n23270 : done 2593 games, reward 9.800, eps 0.92, speed 30.71 f/s\n23275 : done 2594 games, reward 8.900, eps 0.92, speed 9.71 f/s\n23280 : done 2595 games, reward 8.400, eps 0.92, speed 7.76 f/s\n23288 : done 2596 games, reward 7.500, eps 0.92, speed 32.70 f/s\n23308 : done 2597 games, reward 8.100, eps 0.92, speed 15.10 f/s\n23315 : done 2598 games, reward 8.500, eps 0.92, speed 31.00 f/s\n23329 : done 2599 games, reward 8.400, eps 0.92, speed 30.86 f/s\n23339 : done 2600 games, reward 9.100, eps 0.92, speed 29.08 f/s\n23352 : done 2601 games, reward 9.500, eps 0.92, speed 31.79 f/s\n23364 : done 2602 games, reward 10.000, eps 0.92, speed 30.97 f/s\n23373 : done 2603 games, reward 9.700, eps 0.92, speed 9.08 f/s\n23385 : done 2604 games, reward 10.400, eps 0.92, speed 9.28 f/s\n23402 : done 2605 games, reward 11.600, eps 0.92, speed 10.55 f/s\n23409 : done 2606 games, reward 11.600, eps 0.92, speed 28.29 f/s\n23421 : done 2607 games, reward 10.800, eps 0.92, speed 29.07 f/s\n23436 : done 2608 games, reward 11.500, eps 0.92, speed 12.28 f/s\n23449 : done 2609 games, reward 11.400, eps 0.92, speed 31.47 f/s\n23453 : done 2610 games, reward 10.700, eps 0.92, speed 7.99 f/s\n23458 : done 2611 games, reward 9.800, eps 0.92, speed 28.84 f/s\n23462 : done 2612 games, reward 9.000, eps 0.92, speed 8.82 f/s\n23472 : done 2613 games, reward 9.100, eps 0.92, speed 30.58 f/s\n23485 : done 2614 games, reward 9.300, eps 0.92, speed 28.15 f/s\n23501 : done 2615 games, reward 9.200, eps 0.92, speed 29.83 f/s\n23505 : done 2616 games, reward 8.800, eps 0.92, speed 8.77 f/s\n23510 : done 2617 games, reward 8.100, eps 0.92, speed 7.72 f/s\n23515 : done 2618 games, reward 7.100, eps 0.92, speed 8.11 f/s\n23526 : done 2619 games, reward 6.800, eps 0.92, speed 29.71 f/s\n23530 : done 2620 games, reward 6.800, eps 0.92, speed 8.06 f/s\n23547 : done 2621 games, reward 8.100, eps 0.92, speed 30.51 f/s\n23552 : done 2622 games, reward 8.200, eps 0.92, speed 8.03 f/s\n23573 : done 2623 games, reward 9.400, eps 0.92, speed 29.59 f/s\n23586 : done 2624 games, reward 9.300, eps 0.92, speed 28.63 f/s\n23590 : done 2625 games, reward 8.100, eps 0.92, speed 8.25 f/s\n23594 : done 2626 games, reward 8.100, eps 0.92, speed 8.75 f/s\n23608 : done 2627 games, reward 9.000, eps 0.92, speed 11.16 f/s\n23613 : done 2628 games, reward 9.000, eps 0.92, speed 8.17 f/s\n23617 : done 2629 games, reward 8.300, eps 0.92, speed 8.38 f/s\n23621 : done 2630 games, reward 8.300, eps 0.92, speed 8.80 f/s\n23632 : done 2631 games, reward 7.700, eps 0.92, speed 31.38 f/s\n23646 : done 2632 games, reward 8.700, eps 0.92, speed 29.48 f/s\n23660 : done 2633 games, reward 7.900, eps 0.92, speed 11.65 f/s\n23665 : done 2634 games, reward 7.100, eps 0.92, speed 7.83 f/s\n23680 : done 2635 games, reward 8.200, eps 0.92, speed 31.11 f/s\n23692 : done 2636 games, reward 9.000, eps 0.92, speed 29.73 f/s\n23697 : done 2637 games, reward 8.100, eps 0.92, speed 9.65 f/s\n23708 : done 2638 games, reward 8.700, eps 0.92, speed 30.19 f/s\n23712 : done 2639 games, reward 8.700, eps 0.92, speed 8.11 f/s\n23716 : done 2640 games, reward 8.700, eps 0.92, speed 8.57 f/s\n23725 : done 2641 games, reward 8.400, eps 0.92, speed 29.86 f/s\n23730 : done 2642 games, reward 7.400, eps 0.92, speed 9.10 f/s\n23742 : done 2643 games, reward 7.300, eps 0.92, speed 30.00 f/s\n23755 : done 2644 games, reward 8.200, eps 0.92, speed 29.85 f/s\n23766 : done 2645 games, reward 7.800, eps 0.92, speed 11.22 f/s\n23782 : done 2646 games, reward 8.200, eps 0.92, speed 12.92 f/s\n23798 : done 2647 games, reward 9.300, eps 0.92, speed 13.39 f/s\n23813 : done 2648 games, reward 9.800, eps 0.92, speed 30.83 f/s\n23817 : done 2649 games, reward 9.800, eps 0.92, speed 8.86 f/s\n23821 : done 2650 games, reward 9.800, eps 0.92, speed 8.18 f/s\n23837 : done 2651 games, reward 10.500, eps 0.92, speed 11.76 f/s\n23844 : done 2652 games, reward 10.800, eps 0.92, speed 31.96 f/s\n23856 : done 2653 games, reward 10.700, eps 0.92, speed 9.78 f/s\n23861 : done 2654 games, reward 9.900, eps 0.92, speed 26.82 f/s\n23868 : done 2655 games, reward 9.500, eps 0.92, speed 30.46 f/s\n23879 : done 2656 games, reward 9.100, eps 0.92, speed 31.18 f/s\n23884 : done 2657 games, reward 8.000, eps 0.92, speed 8.24 f/s\n23889 : done 2658 games, reward 6.900, eps 0.92, speed 8.51 f/s\n23901 : done 2659 games, reward 7.700, eps 0.92, speed 11.53 f/s\n23913 : done 2660 games, reward 8.500, eps 0.92, speed 29.81 f/s\n23917 : done 2661 games, reward 7.300, eps 0.92, speed 8.62 f/s\n23924 : done 2662 games, reward 7.200, eps 0.92, speed 31.70 f/s\n23928 : done 2663 games, reward 6.400, eps 0.92, speed 8.45 f/s\n23937 : done 2664 games, reward 6.700, eps 0.92, speed 11.04 f/s\n23955 : done 2665 games, reward 7.800, eps 0.92, speed 30.02 f/s\n23964 : done 2666 games, reward 7.600, eps 0.92, speed 28.91 f/s\n23976 : done 2667 games, reward 8.300, eps 0.92, speed 32.27 f/s\n23992 : done 2668 games, reward 9.500, eps 0.92, speed 30.32 f/s\n24000 : done 2669 games, reward 9.100, eps 0.92, speed 30.93 f/s\n24017 : done 2670 games, reward 9.600, eps 0.92, speed 11.82 f/s\n24028 : done 2671 games, reward 10.400, eps 0.92, speed 30.10 f/s\n24032 : done 2672 games, reward 10.100, eps 0.92, speed 8.40 f/s\n24037 : done 2673 games, reward 10.200, eps 0.92, speed 9.52 f/s\n24050 : done 2674 games, reward 10.700, eps 0.92, speed 29.33 f/s\n24059 : done 2675 games, reward 9.900, eps 0.92, speed 32.47 f/s\n24072 : done 2676 games, reward 10.200, eps 0.92, speed 12.39 f/s\n24085 : done 2677 games, reward 10.300, eps 0.92, speed 11.08 f/s\n24095 : done 2678 games, reward 9.700, eps 0.92, speed 31.07 f/s\n24104 : done 2679 games, reward 9.800, eps 0.92, speed 27.89 f/s\n24114 : done 2680 games, reward 9.100, eps 0.92, speed 11.37 f/s\n24120 : done 2681 games, reward 8.500, eps 0.92, speed 8.18 f/s\n24130 : done 2682 games, reward 9.100, eps 0.92, speed 32.05 f/s\n24140 : done 2683 games, reward 9.700, eps 0.92, speed 29.69 f/s\n24145 : done 2684 games, reward 8.800, eps 0.92, speed 9.67 f/s\n24153 : done 2685 games, reward 8.700, eps 0.92, speed 32.32 f/s\n24168 : done 2686 games, reward 8.900, eps 0.92, speed 29.30 f/s\n24172 : done 2687 games, reward 8.000, eps 0.92, speed 8.40 f/s\n24186 : done 2688 games, reward 8.300, eps 0.92, speed 30.51 f/s\n24190 : done 2689 games, reward 7.800, eps 0.92, speed 8.25 f/s\n24198 : done 2690 games, reward 7.700, eps 0.92, speed 31.17 f/s\n24203 : done 2691 games, reward 7.600, eps 0.92, speed 10.13 f/s\n24219 : done 2692 games, reward 8.200, eps 0.92, speed 31.18 f/s\n24231 : done 2693 games, reward 8.300, eps 0.92, speed 10.17 f/s\n24240 : done 2694 games, reward 8.700, eps 0.92, speed 29.31 f/s\n24245 : done 2695 games, reward 8.300, eps 0.92, speed 8.51 f/s\n24251 : done 2696 games, reward 7.500, eps 0.92, speed 28.91 f/s\n24260 : done 2697 games, reward 8.000, eps 0.92, speed 9.91 f/s\n24264 : done 2698 games, reward 7.000, eps 0.92, speed 9.27 f/s\n24269 : done 2699 games, reward 7.100, eps 0.92, speed 8.18 f/s\n24273 : done 2700 games, reward 6.600, eps 0.92, speed 8.61 f/s\n24277 : done 2701 games, reward 6.500, eps 0.92, speed 9.17 f/s\n24289 : done 2702 games, reward 6.100, eps 0.92, speed 29.46 f/s\n24295 : done 2703 games, reward 5.600, eps 0.92, speed 32.48 f/s\n24307 : done 2704 games, reward 5.900, eps 0.92, speed 32.32 f/s\n24318 : done 2705 games, reward 6.600, eps 0.92, speed 29.22 f/s\n24323 : done 2706 games, reward 6.400, eps 0.92, speed 8.42 f/s\n24337 : done 2707 games, reward 7.000, eps 0.92, speed 32.02 f/s\n24342 : done 2708 games, reward 7.100, eps 0.92, speed 7.32 f/s\n24361 : done 2709 games, reward 8.500, eps 0.92, speed 15.01 f/s\n24369 : done 2710 games, reward 9.000, eps 0.92, speed 29.68 f/s\n24374 : done 2711 games, reward 9.100, eps 0.92, speed 8.51 f/s\n24390 : done 2712 games, reward 9.600, eps 0.92, speed 31.65 f/s\n24394 : done 2713 games, reward 9.300, eps 0.92, speed 9.06 f/s\n24398 : done 2714 games, reward 8.500, eps 0.92, speed 8.61 f/s\n24405 : done 2715 games, reward 8.100, eps 0.92, speed 29.20 f/s\n24419 : done 2716 games, reward 9.000, eps 0.92, speed 31.51 f/s\n24439 : done 2717 games, reward 9.600, eps 0.92, speed 28.96 f/s\n24458 : done 2718 games, reward 11.000, eps 0.92, speed 30.95 f/s\n24464 : done 2719 games, reward 9.700, eps 0.92, speed 30.48 f/s\n24473 : done 2720 games, reward 9.700, eps 0.92, speed 8.52 f/s\n24486 : done 2721 games, reward 10.500, eps 0.92, speed 30.63 f/s\n24500 : done 2722 games, reward 10.200, eps 0.92, speed 31.42 f/s\n24506 : done 2723 games, reward 10.400, eps 0.92, speed 8.23 f/s\n24518 : done 2724 games, reward 11.300, eps 0.92, speed 32.30 f/s\n24528 : done 2725 games, reward 11.600, eps 0.92, speed 32.12 f/s\n24542 : done 2726 games, reward 11.700, eps 0.92, speed 29.80 f/s\n24546 : done 2727 games, reward 10.000, eps 0.92, speed 8.15 f/s\n24557 : done 2728 games, reward 9.200, eps 0.92, speed 10.45 f/s\n24567 : done 2729 games, reward 9.600, eps 0.92, speed 27.93 f/s\n24581 : done 2730 games, reward 10.200, eps 0.92, speed 30.71 f/s\n24593 : done 2731 games, reward 10.100, eps 0.92, speed 31.78 f/s\n24609 : done 2732 games, reward 10.300, eps 0.92, speed 10.99 f/s\n24624 : done 2733 games, reward 11.300, eps 0.92, speed 12.57 f/s\n24631 : done 2734 games, reward 10.800, eps 0.92, speed 25.36 f/s\n24640 : done 2735 games, reward 10.600, eps 0.92, speed 9.60 f/s\n24644 : done 2736 games, reward 9.500, eps 0.92, speed 9.08 f/s\n24661 : done 2737 games, reward 10.800, eps 0.92, speed 11.87 f/s\n24673 : done 2738 games, reward 10.900, eps 0.92, speed 10.97 f/s\n24679 : done 2739 games, reward 10.500, eps 0.92, speed 7.50 f/s\n24698 : done 2740 games, reward 11.000, eps 0.92, speed 30.19 f/s\n24705 : done 2741 games, reward 10.500, eps 0.92, speed 31.59 f/s\n24718 : done 2742 games, reward 10.200, eps 0.92, speed 29.58 f/s\n24725 : done 2743 games, reward 9.400, eps 0.92, speed 30.17 f/s\n24730 : done 2744 games, reward 9.100, eps 0.92, speed 7.86 f/s\n24741 : done 2745 games, reward 9.300, eps 0.92, speed 10.94 f/s\n24749 : done 2746 games, reward 9.800, eps 0.92, speed 28.96 f/s\n24753 : done 2747 games, reward 8.500, eps 0.92, speed 8.75 f/s\n24765 : done 2748 games, reward 8.600, eps 0.92, speed 27.93 f/s\n24777 : done 2749 games, reward 9.200, eps 0.92, speed 10.29 f/s\n24793 : done 2750 games, reward 8.900, eps 0.92, speed 30.33 f/s\n24812 : done 2751 games, reward 10.200, eps 0.92, speed 28.30 f/s\n24824 : done 2752 games, reward 10.100, eps 0.92, speed 11.03 f/s\n24833 : done 2753 games, reward 10.200, eps 0.92, speed 29.60 f/s\n24839 : done 2754 games, reward 10.300, eps 0.92, speed 9.13 f/s\n24850 : done 2755 games, reward 10.300, eps 0.92, speed 11.49 f/s\n24856 : done 2756 games, reward 10.000, eps 0.92, speed 32.62 f/s\n24867 : done 2757 games, reward 10.700, eps 0.92, speed 8.86 f/s\n24881 : done 2758 games, reward 10.800, eps 0.92, speed 28.53 f/s\n24893 : done 2759 games, reward 10.800, eps 0.92, speed 31.28 f/s\n24904 : done 2760 games, reward 10.200, eps 0.92, speed 9.52 f/s\n24925 : done 2761 games, reward 10.350, eps 0.92, speed 14.75 f/s\n24930 : done 2762 games, reward 9.650, eps 0.92, speed 8.89 f/s\n24936 : done 2763 games, reward 9.450, eps 0.92, speed 27.30 f/s\n24948 : done 2764 games, reward 10.150, eps 0.92, speed 30.46 f/s\n24960 : done 2765 games, reward 10.350, eps 0.92, speed 32.13 f/s\n24973 : done 2766 games, reward 11.150, eps 0.92, speed 27.91 f/s\n24981 : done 2767 games, reward 10.950, eps 0.92, speed 30.73 f/s\n24996 : done 2768 games, reward 11.050, eps 0.92, speed 29.03 f/s\nSync\nAppend data\n25001 : done 2769 games, reward 10.450, eps 0.92, speed 28.00 f/s\n25008 : done 2770 games, reward 10.150, eps 0.92, speed 30.20 f/s\n25022 : done 2771 games, reward 9.400, eps 0.92, speed 12.76 f/s\n25026 : done 2772 games, reward 9.300, eps 0.92, speed 8.89 f/s\n25034 : done 2773 games, reward 9.400, eps 0.92, speed 26.78 f/s\n25043 : done 2774 games, reward 9.100, eps 0.92, speed 31.98 f/s\n25058 : done 2775 games, reward 9.400, eps 0.92, speed 31.41 f/s\n25064 : done 2776 games, reward 8.700, eps 0.92, speed 29.27 f/s\n25079 : done 2777 games, reward 9.400, eps 0.92, speed 31.07 f/s\n25096 : done 2778 games, reward 9.600, eps 0.92, speed 15.24 f/s\n25101 : done 2779 games, reward 9.500, eps 0.92, speed 9.24 f/s\n25106 : done 2780 games, reward 9.200, eps 0.92, speed 28.40 f/s\n25111 : done 2781 games, reward 8.300, eps 0.92, speed 8.27 f/s\n25120 : done 2782 games, reward 8.800, eps 0.92, speed 8.73 f/s\n25137 : done 2783 games, reward 9.700, eps 0.92, speed 13.24 f/s\n25149 : done 2784 games, reward 10.000, eps 0.92, speed 27.64 f/s\n25153 : done 2785 games, reward 8.800, eps 0.92, speed 8.55 f/s\n25157 : done 2786 games, reward 8.600, eps 0.92, speed 29.43 f/s\n"
    }
   ],
   "source": [
    "while True:\n",
    "    frame_idx += 1\n",
    "    epsilon = max(EPSILON_FINAL, EPSILON_START - frame_idx / EPSILON_DECAY_LAST_FRAME)   \n",
    "    reward = agent.play_step(net, epsilon, device=device)\n",
    "    if reward is not None:\n",
    "        total_rewards.append(reward)\n",
    "        speed = (frame_idx - ts_frame) / (time.time() - ts)\n",
    "        ts_frame = frame_idx\n",
    "        ts = time.time()\n",
    "        m_reward = np.mean(total_rewards[-10:])\n",
    "        print(\"%d : done %d games, reward %.3f, eps %.2f, speed %.2f f/s\" % (frame_idx, len(total_rewards), m_reward, epsilon, speed))\n",
    "\n",
    "        if best_m_reward is None or best_m_reward < m_reward:\n",
    "            torch.save(net.state_dict(), \"best_%.0f.pth\" % m_reward)\n",
    "            if best_m_reward is not None:\n",
    "                print(\"Best reward updated %.3f -> %.3f\" % (best_m_reward, m_reward))\n",
    "            best_m_reward = m_reward\n",
    "\n",
    "    if len(buffer) < REPLAY_START_SIZE:\n",
    "        continue\n",
    "  \n",
    "    if frame_idx % SYNC_TARGET_FRAMES == 0:\n",
    "        tgt_net.load_state_dict(net.state_dict())\n",
    "        print(\"Sync\")\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    batch = buffer.sample(BATCH_SIZE)\n",
    "    loss_t = calc_loss(batch, net, tgt_net, device=device)\n",
    "    loss_t.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "    if frame_idx is not 0 and frame_idx % 5000 == 0:\n",
    "        reward_for_plot.append(reward)\n",
    "        mean_reward_for_plot.append(m_reward)\n",
    "        loss_for_plot.append(loss_t)\n",
    "        print(\"Append data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_env = make(\"connectx\")\n",
    "valid_env.reset()\n",
    "valid_trainer = valid_env.train([None, \"negamax\"])\n",
    "valid_observation = valid_trainer.reset()\n",
    "path = \"./weights/best_18.pth\"\n",
    "path2 = \"./win_best_17.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_network_action(q_vals_v, observation):\n",
    "    actions = torch.argsort(q_vals_v, descending=True, dim=1)\n",
    "    actions = actions.view(-1)\n",
    "\n",
    "    for action in actions:            \n",
    "        action = action.item()\n",
    "        if observation.board[action] == 0:                \n",
    "            return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_agent(observation, configuration):\n",
    "    rows, columns = configuration['rows'], configuration['columns']\n",
    "    input_shape = [1, rows, columns]\n",
    "    n_actions = columns\n",
    "\n",
    "    board = observation['board']\n",
    "    np_board = np.array(board)\n",
    "    np_board = np_board.reshape(1, rows, -1)\n",
    "    assert np_board.shape[2] == columns\n",
    "    \n",
    "    net = DQN(input_shape, n_actions)\n",
    "    net.load_state_dict(torch.load(path))\n",
    "    net.eval()\n",
    "\n",
    "    observation_v = torch.from_numpy(np_board).float()\n",
    "    q_vals_v = net(observation_v.unsqueeze(0))\n",
    "    action = select_network_action(q_vals_v, observation)\n",
    "\n",
    "    return int(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "action = my_agent(valid_observation, valid_env.configuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<iframe srcdoc=\"<!--\n  Copyright 2020 Kaggle Inc\n\n  Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);\n  you may not use this file except in compliance with the License.\n  You may obtain a copy of the License at\n\n      http://www.apache.org/licenses/LICENSE-2.0\n\n  Unless required by applicable law or agreed to in writing, software\n  distributed under the License is distributed on an &quot;AS IS&quot; BASIS,\n  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n  See the License for the specific language governing permissions and\n  limitations under the License.\n-->\n<!DOCTYPE html>\n<html lang=&quot;en&quot;>\n  <head>\n    <title>Kaggle Simulation Player</title>\n    <meta name=&quot;viewport&quot; content=&quot;width=device-width,initial-scale=1&quot; />\n    <link\n      rel=&quot;stylesheet&quot;\n      href=&quot;https://cdnjs.cloudflare.com/ajax/libs/meyer-reset/2.0/reset.css&quot;\n      crossorigin=&quot;anonymous&quot;\n    />\n    <style type=&quot;text/css&quot;>\n      html,\n      body {\n        height: 100%;\n        font-family: sans-serif;\n      }\n      canvas {\n        /* image-rendering: -moz-crisp-edges;\n        image-rendering: -webkit-crisp-edges;\n        image-rendering: pixelated;\n        image-rendering: crisp-edges; */\n      }\n    </style>\n    <script src=&quot;https://unpkg.com/preact@10.0.1/dist/preact.umd.js&quot;></script>\n    <script src=&quot;https://unpkg.com/preact@10.0.1/hooks/dist/hooks.umd.js&quot;></script>\n    <script src=&quot;https://unpkg.com/htm@2.2.1/dist/htm.umd.js&quot;></script>\n    <script>\n      // Polyfill for Styled Components\n      window.React = {\n        ...preact,\n        createElement: preact.h,\n        PropTypes: { func: {} },\n      };\n    </script>\n    <script src=&quot;https://unpkg.com/styled-components@3.5.0-0/dist/styled-components.min.js&quot;></script>\n  </head>\n  <body>\n    <script>\n      \nwindow.kaggle = {\n  &quot;debug&quot;: false,\n  &quot;autoplay&quot;: true,\n  &quot;step&quot;: 0,\n  &quot;controls&quot;: true,\n  &quot;environment&quot;: {\n    &quot;id&quot;: &quot;b521cc20-5bf4-11ea-b551-38d547ad5d4a&quot;,\n    &quot;name&quot;: &quot;connectx&quot;,\n    &quot;title&quot;: &quot;ConnectX&quot;,\n    &quot;description&quot;: &quot;Classic Connect in a row but configurable.&quot;,\n    &quot;version&quot;: &quot;1.0.0&quot;,\n    &quot;configuration&quot;: {\n      &quot;timeout&quot;: 5,\n      &quot;columns&quot;: 7,\n      &quot;rows&quot;: 6,\n      &quot;inarow&quot;: 4,\n      &quot;steps&quot;: 1000\n    },\n    &quot;specification&quot;: {\n      &quot;action&quot;: {\n        &quot;description&quot;: &quot;Column to drop a checker onto the board.&quot;,\n        &quot;type&quot;: &quot;integer&quot;,\n        &quot;minimum&quot;: 0,\n        &quot;default&quot;: 0\n      },\n      &quot;agents&quot;: [\n        2\n      ],\n      &quot;configuration&quot;: {\n        &quot;timeout&quot;: {\n          &quot;description&quot;: &quot;Seconds an agent can run before timing out.&quot;,\n          &quot;type&quot;: &quot;integer&quot;,\n          &quot;minimum&quot;: 1,\n          &quot;default&quot;: 5\n        },\n        &quot;columns&quot;: {\n          &quot;description&quot;: &quot;The number of columns on the board&quot;,\n          &quot;type&quot;: &quot;integer&quot;,\n          &quot;default&quot;: 7,\n          &quot;minimum&quot;: 1\n        },\n        &quot;rows&quot;: {\n          &quot;description&quot;: &quot;The number of rows on the board&quot;,\n          &quot;type&quot;: &quot;integer&quot;,\n          &quot;default&quot;: 6,\n          &quot;minimum&quot;: 1\n        },\n        &quot;inarow&quot;: {\n          &quot;description&quot;: &quot;The number of checkers in a row required to win.&quot;,\n          &quot;type&quot;: &quot;integer&quot;,\n          &quot;default&quot;: 4,\n          &quot;minimum&quot;: 1\n        },\n        &quot;steps&quot;: {\n          &quot;description&quot;: &quot;Maximum number of steps the environment can run.&quot;,\n          &quot;type&quot;: &quot;integer&quot;,\n          &quot;minimum&quot;: 1,\n          &quot;default&quot;: 1000\n        }\n      },\n      &quot;info&quot;: {},\n      &quot;observation&quot;: {\n        &quot;board&quot;: {\n          &quot;description&quot;: &quot;Serialized grid (rows x columns). 0 = Empty, 1 = P1, 2 = P2&quot;,\n          &quot;type&quot;: &quot;array&quot;,\n          &quot;default&quot;: []\n        },\n        &quot;mark&quot;: {\n          &quot;default&quot;: 0,\n          &quot;description&quot;: &quot;Which checkers are the agents.&quot;,\n          &quot;enum&quot;: [\n            1,\n            2\n          ]\n        }\n      },\n      &quot;reward&quot;: {\n        &quot;description&quot;: &quot;0 = Lost, 0.5 = Draw, 1 = Won&quot;,\n        &quot;enum&quot;: [\n          0,\n          0.5,\n          1\n        ],\n        &quot;default&quot;: 0.5,\n        &quot;type&quot;: [\n          &quot;number&quot;,\n          &quot;null&quot;\n        ]\n      },\n      &quot;reset&quot;: {\n        &quot;status&quot;: [\n          &quot;ACTIVE&quot;,\n          &quot;INACTIVE&quot;\n        ],\n        &quot;observation&quot;: [\n          {\n            &quot;mark&quot;: 1\n          },\n          {\n            &quot;mark&quot;: 2\n          }\n        ]\n      }\n    },\n    &quot;steps&quot;: [\n      [\n        {\n          &quot;action&quot;: 0,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0\n            ],\n            &quot;mark&quot;: 1\n          },\n          &quot;status&quot;: &quot;ACTIVE&quot;\n        },\n        {\n          &quot;action&quot;: 0,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0\n            ],\n            &quot;mark&quot;: 2\n          },\n          &quot;status&quot;: &quot;INACTIVE&quot;\n        }\n      ],\n      [\n        {\n          &quot;action&quot;: 6,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              1\n            ],\n            &quot;mark&quot;: 1\n          },\n          &quot;status&quot;: &quot;INACTIVE&quot;\n        },\n        {\n          &quot;action&quot;: 0,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              1\n            ],\n            &quot;mark&quot;: 2\n          },\n          &quot;status&quot;: &quot;ACTIVE&quot;\n        }\n      ],\n      [\n        {\n          &quot;action&quot;: 0,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              2,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              1\n            ],\n            &quot;mark&quot;: 1\n          },\n          &quot;status&quot;: &quot;ACTIVE&quot;\n        },\n        {\n          &quot;action&quot;: 6,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              2,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              1\n            ],\n            &quot;mark&quot;: 2\n          },\n          &quot;status&quot;: &quot;INACTIVE&quot;\n        }\n      ],\n      [\n        {\n          &quot;action&quot;: 6,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              1,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              2,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              1\n            ],\n            &quot;mark&quot;: 1\n          },\n          &quot;status&quot;: &quot;INACTIVE&quot;\n        },\n        {\n          &quot;action&quot;: 0,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              1,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              2,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              1\n            ],\n            &quot;mark&quot;: 2\n          },\n          &quot;status&quot;: &quot;ACTIVE&quot;\n        }\n      ],\n      [\n        {\n          &quot;action&quot;: 0,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              1,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              2,\n              0,\n              2,\n              0,\n              0,\n              0,\n              0,\n              1\n            ],\n            &quot;mark&quot;: 1\n          },\n          &quot;status&quot;: &quot;ACTIVE&quot;\n        },\n        {\n          &quot;action&quot;: 1,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              1,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              2,\n              0,\n              2,\n              0,\n              0,\n              0,\n              0,\n              1\n            ],\n            &quot;mark&quot;: 2\n          },\n          &quot;status&quot;: &quot;INACTIVE&quot;\n        }\n      ],\n      [\n        {\n          &quot;action&quot;: 0,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              1,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              2,\n              1,\n              2,\n              0,\n              0,\n              0,\n              0,\n              1\n            ],\n            &quot;mark&quot;: 1\n          },\n          &quot;status&quot;: &quot;INACTIVE&quot;\n        },\n        {\n          &quot;action&quot;: 0,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              1,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              2,\n              1,\n              2,\n              0,\n              0,\n              0,\n              0,\n              1\n            ],\n            &quot;mark&quot;: 2\n          },\n          &quot;status&quot;: &quot;ACTIVE&quot;\n        }\n      ],\n      [\n        {\n          &quot;action&quot;: 0,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              1,\n              0,\n              2,\n              0,\n              0,\n              0,\n              0,\n              2,\n              1,\n              2,\n              0,\n              0,\n              0,\n              0,\n              1\n            ],\n            &quot;mark&quot;: 1\n          },\n          &quot;status&quot;: &quot;ACTIVE&quot;\n        },\n        {\n          &quot;action&quot;: 1,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              1,\n              0,\n              2,\n              0,\n              0,\n              0,\n              0,\n              2,\n              1,\n              2,\n              0,\n              0,\n              0,\n              0,\n              1\n            ],\n            &quot;mark&quot;: 2\n          },\n          &quot;status&quot;: &quot;INACTIVE&quot;\n        }\n      ],\n      [\n        {\n          &quot;action&quot;: 3,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              1,\n              0,\n              2,\n              0,\n              0,\n              0,\n              0,\n              2,\n              1,\n              2,\n              0,\n              1,\n              0,\n              0,\n              1\n            ],\n            &quot;mark&quot;: 1\n          },\n          &quot;status&quot;: &quot;INACTIVE&quot;\n        },\n        {\n          &quot;action&quot;: 0,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              1,\n              0,\n              2,\n              0,\n              0,\n              0,\n              0,\n              2,\n              1,\n              2,\n              0,\n              1,\n              0,\n              0,\n              1\n            ],\n            &quot;mark&quot;: 2\n          },\n          &quot;status&quot;: &quot;ACTIVE&quot;\n        }\n      ],\n      [\n        {\n          &quot;action&quot;: 0,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              1,\n              0,\n              2,\n              0,\n              0,\n              0,\n              0,\n              2,\n              1,\n              2,\n              0,\n              1,\n              0,\n              2,\n              1\n            ],\n            &quot;mark&quot;: 1\n          },\n          &quot;status&quot;: &quot;ACTIVE&quot;\n        },\n        {\n          &quot;action&quot;: 5,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              1,\n              0,\n              2,\n              0,\n              0,\n              0,\n              0,\n              2,\n              1,\n              2,\n              0,\n              1,\n              0,\n              2,\n              1\n            ],\n            &quot;mark&quot;: 2\n          },\n          &quot;status&quot;: &quot;INACTIVE&quot;\n        }\n      ],\n      [\n        {\n          &quot;action&quot;: 2,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              1,\n              0,\n              2,\n              0,\n              0,\n              0,\n              0,\n              2,\n              1,\n              2,\n              1,\n              1,\n              0,\n              2,\n              1\n            ],\n            &quot;mark&quot;: 1\n          },\n          &quot;status&quot;: &quot;INACTIVE&quot;\n        },\n        {\n          &quot;action&quot;: 0,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              1,\n              0,\n              2,\n              0,\n              0,\n              0,\n              0,\n              2,\n              1,\n              2,\n              1,\n              1,\n              0,\n              2,\n              1\n            ],\n            &quot;mark&quot;: 2\n          },\n          &quot;status&quot;: &quot;ACTIVE&quot;\n        }\n      ],\n      [\n        {\n          &quot;action&quot;: 0,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              1,\n              0,\n              2,\n              0,\n              0,\n              0,\n              2,\n              2,\n              1,\n              2,\n              1,\n              1,\n              0,\n              2,\n              1\n            ],\n            &quot;mark&quot;: 1\n          },\n          &quot;status&quot;: &quot;ACTIVE&quot;\n        },\n        {\n          &quot;action&quot;: 5,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              1,\n              0,\n              2,\n              0,\n              0,\n              0,\n              2,\n              2,\n              1,\n              2,\n              1,\n              1,\n              0,\n              2,\n              1\n            ],\n            &quot;mark&quot;: 2\n          },\n          &quot;status&quot;: &quot;INACTIVE&quot;\n        }\n      ],\n      [\n        {\n          &quot;action&quot;: 5,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              1,\n              1,\n              0,\n              2,\n              0,\n              0,\n              0,\n              2,\n              2,\n              1,\n              2,\n              1,\n              1,\n              0,\n              2,\n              1\n            ],\n            &quot;mark&quot;: 1\n          },\n          &quot;status&quot;: &quot;INACTIVE&quot;\n        },\n        {\n          &quot;action&quot;: 0,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              1,\n              1,\n              0,\n              2,\n              0,\n              0,\n              0,\n              2,\n              2,\n              1,\n              2,\n              1,\n              1,\n              0,\n              2,\n              1\n            ],\n            &quot;mark&quot;: 2\n          },\n          &quot;status&quot;: &quot;ACTIVE&quot;\n        }\n      ],\n      [\n        {\n          &quot;action&quot;: 0,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              2,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              1,\n              1,\n              0,\n              2,\n              0,\n              0,\n              0,\n              2,\n              2,\n              1,\n              2,\n              1,\n              1,\n              0,\n              2,\n              1\n            ],\n            &quot;mark&quot;: 1\n          },\n          &quot;status&quot;: &quot;ACTIVE&quot;\n        },\n        {\n          &quot;action&quot;: 5,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              2,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              1,\n              1,\n              0,\n              2,\n              0,\n              0,\n              0,\n              2,\n              2,\n              1,\n              2,\n              1,\n              1,\n              0,\n              2,\n              1\n            ],\n            &quot;mark&quot;: 2\n          },\n          &quot;status&quot;: &quot;INACTIVE&quot;\n        }\n      ],\n      [\n        {\n          &quot;action&quot;: 5,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              1,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              2,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              1,\n              1,\n              0,\n              2,\n              0,\n              0,\n              0,\n              2,\n              2,\n              1,\n              2,\n              1,\n              1,\n              0,\n              2,\n              1\n            ],\n            &quot;mark&quot;: 1\n          },\n          &quot;status&quot;: &quot;INACTIVE&quot;\n        },\n        {\n          &quot;action&quot;: 0,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              1,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              2,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              1,\n              1,\n              0,\n              2,\n              0,\n              0,\n              0,\n              2,\n              2,\n              1,\n              2,\n              1,\n              1,\n              0,\n              2,\n              1\n            ],\n            &quot;mark&quot;: 2\n          },\n          &quot;status&quot;: &quot;ACTIVE&quot;\n        }\n      ],\n      [\n        {\n          &quot;action&quot;: 0,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              1,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              2,\n              0,\n              0,\n              2,\n              0,\n              0,\n              0,\n              1,\n              1,\n              0,\n              2,\n              0,\n              0,\n              0,\n              2,\n              2,\n              1,\n              2,\n              1,\n              1,\n              0,\n              2,\n              1\n            ],\n            &quot;mark&quot;: 1\n          },\n          &quot;status&quot;: &quot;ACTIVE&quot;\n        },\n        {\n          &quot;action&quot;: 1,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              1,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              2,\n              0,\n              0,\n              2,\n              0,\n              0,\n              0,\n              1,\n              1,\n              0,\n              2,\n              0,\n              0,\n              0,\n              2,\n              2,\n              1,\n              2,\n              1,\n              1,\n              0,\n              2,\n              1\n            ],\n            &quot;mark&quot;: 2\n          },\n          &quot;status&quot;: &quot;INACTIVE&quot;\n        }\n      ],\n      [\n        {\n          &quot;action&quot;: 1,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              1,\n              0,\n              0,\n              1,\n              0,\n              0,\n              0,\n              2,\n              0,\n              0,\n              2,\n              0,\n              0,\n              0,\n              1,\n              1,\n              0,\n              2,\n              0,\n              0,\n              0,\n              2,\n              2,\n              1,\n              2,\n              1,\n              1,\n              0,\n              2,\n              1\n            ],\n            &quot;mark&quot;: 1\n          },\n          &quot;status&quot;: &quot;INACTIVE&quot;\n        },\n        {\n          &quot;action&quot;: 0,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              1,\n              0,\n              0,\n              1,\n              0,\n              0,\n              0,\n              2,\n              0,\n              0,\n              2,\n              0,\n              0,\n              0,\n              1,\n              1,\n              0,\n              2,\n              0,\n              0,\n              0,\n              2,\n              2,\n              1,\n              2,\n              1,\n              1,\n              0,\n              2,\n              1\n            ],\n            &quot;mark&quot;: 2\n          },\n          &quot;status&quot;: &quot;ACTIVE&quot;\n        }\n      ],\n      [\n        {\n          &quot;action&quot;: 0,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              2,\n              0,\n              0,\n              0,\n              1,\n              0,\n              0,\n              1,\n              0,\n              0,\n              0,\n              2,\n              0,\n              0,\n              2,\n              0,\n              0,\n              0,\n              1,\n              1,\n              0,\n              2,\n              0,\n              0,\n              0,\n              2,\n              2,\n              1,\n              2,\n              1,\n              1,\n              0,\n              2,\n              1\n            ],\n            &quot;mark&quot;: 1\n          },\n          &quot;status&quot;: &quot;ACTIVE&quot;\n        },\n        {\n          &quot;action&quot;: 1,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              2,\n              0,\n              0,\n              0,\n              1,\n              0,\n              0,\n              1,\n              0,\n              0,\n              0,\n              2,\n              0,\n              0,\n              2,\n              0,\n              0,\n              0,\n              1,\n              1,\n              0,\n              2,\n              0,\n              0,\n              0,\n              2,\n              2,\n              1,\n              2,\n              1,\n              1,\n              0,\n              2,\n              1\n            ],\n            &quot;mark&quot;: 2\n          },\n          &quot;status&quot;: &quot;INACTIVE&quot;\n        }\n      ],\n      [\n        {\n          &quot;action&quot;: 4,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              2,\n              0,\n              0,\n              0,\n              1,\n              0,\n              0,\n              1,\n              0,\n              0,\n              0,\n              2,\n              0,\n              0,\n              2,\n              0,\n              0,\n              0,\n              1,\n              1,\n              0,\n              2,\n              0,\n              0,\n              0,\n              2,\n              2,\n              1,\n              2,\n              1,\n              1,\n              1,\n              2,\n              1\n            ],\n            &quot;mark&quot;: 1\n          },\n          &quot;status&quot;: &quot;INACTIVE&quot;\n        },\n        {\n          &quot;action&quot;: 0,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              2,\n              0,\n              0,\n              0,\n              1,\n              0,\n              0,\n              1,\n              0,\n              0,\n              0,\n              2,\n              0,\n              0,\n              2,\n              0,\n              0,\n              0,\n              1,\n              1,\n              0,\n              2,\n              0,\n              0,\n              0,\n              2,\n              2,\n              1,\n              2,\n              1,\n              1,\n              1,\n              2,\n              1\n            ],\n            &quot;mark&quot;: 2\n          },\n          &quot;status&quot;: &quot;ACTIVE&quot;\n        }\n      ],\n      [\n        {\n          &quot;action&quot;: 0,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              2,\n              0,\n              0,\n              0,\n              1,\n              0,\n              0,\n              1,\n              0,\n              0,\n              0,\n              2,\n              0,\n              0,\n              2,\n              0,\n              0,\n              0,\n              1,\n              1,\n              2,\n              2,\n              0,\n              0,\n              0,\n              2,\n              2,\n              1,\n              2,\n              1,\n              1,\n              1,\n              2,\n              1\n            ],\n            &quot;mark&quot;: 1\n          },\n          &quot;status&quot;: &quot;ACTIVE&quot;\n        },\n        {\n          &quot;action&quot;: 0,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              2,\n              0,\n              0,\n              0,\n              1,\n              0,\n              0,\n              1,\n              0,\n              0,\n              0,\n              2,\n              0,\n              0,\n              2,\n              0,\n              0,\n              0,\n              1,\n              1,\n              2,\n              2,\n              0,\n              0,\n              0,\n              2,\n              2,\n              1,\n              2,\n              1,\n              1,\n              1,\n              2,\n              1\n            ],\n            &quot;mark&quot;: 2\n          },\n          &quot;status&quot;: &quot;INACTIVE&quot;\n        }\n      ],\n      [\n        {\n          &quot;action&quot;: 0,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              2,\n              0,\n              0,\n              0,\n              1,\n              0,\n              0,\n              1,\n              0,\n              0,\n              0,\n              2,\n              0,\n              1,\n              2,\n              0,\n              0,\n              0,\n              1,\n              1,\n              2,\n              2,\n              0,\n              0,\n              0,\n              2,\n              2,\n              1,\n              2,\n              1,\n              1,\n              1,\n              2,\n              1\n            ],\n            &quot;mark&quot;: 1\n          },\n          &quot;status&quot;: &quot;INACTIVE&quot;\n        },\n        {\n          &quot;action&quot;: 0,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              2,\n              0,\n              0,\n              0,\n              1,\n              0,\n              0,\n              1,\n              0,\n              0,\n              0,\n              2,\n              0,\n              1,\n              2,\n              0,\n              0,\n              0,\n              1,\n              1,\n              2,\n              2,\n              0,\n              0,\n              0,\n              2,\n              2,\n              1,\n              2,\n              1,\n              1,\n              1,\n              2,\n              1\n            ],\n            &quot;mark&quot;: 2\n          },\n          &quot;status&quot;: &quot;ACTIVE&quot;\n        }\n      ],\n      [\n        {\n          &quot;action&quot;: 0,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              2,\n              0,\n              0,\n              0,\n              1,\n              0,\n              0,\n              1,\n              0,\n              0,\n              0,\n              2,\n              2,\n              1,\n              2,\n              0,\n              0,\n              0,\n              1,\n              1,\n              2,\n              2,\n              0,\n              0,\n              0,\n              2,\n              2,\n              1,\n              2,\n              1,\n              1,\n              1,\n              2,\n              1\n            ],\n            &quot;mark&quot;: 1\n          },\n          &quot;status&quot;: &quot;ACTIVE&quot;\n        },\n        {\n          &quot;action&quot;: 6,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              2,\n              0,\n              0,\n              0,\n              1,\n              0,\n              0,\n              1,\n              0,\n              0,\n              0,\n              2,\n              2,\n              1,\n              2,\n              0,\n              0,\n              0,\n              1,\n              1,\n              2,\n              2,\n              0,\n              0,\n              0,\n              2,\n              2,\n              1,\n              2,\n              1,\n              1,\n              1,\n              2,\n              1\n            ],\n            &quot;mark&quot;: 2\n          },\n          &quot;status&quot;: &quot;INACTIVE&quot;\n        }\n      ],\n      [\n        {\n          &quot;action&quot;: 4,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              2,\n              0,\n              0,\n              0,\n              1,\n              0,\n              0,\n              1,\n              0,\n              0,\n              0,\n              2,\n              2,\n              1,\n              2,\n              0,\n              0,\n              0,\n              1,\n              1,\n              2,\n              2,\n              0,\n              0,\n              1,\n              2,\n              2,\n              1,\n              2,\n              1,\n              1,\n              1,\n              2,\n              1\n            ],\n            &quot;mark&quot;: 1\n          },\n          &quot;status&quot;: &quot;INACTIVE&quot;\n        },\n        {\n          &quot;action&quot;: 0,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              2,\n              0,\n              0,\n              0,\n              1,\n              0,\n              0,\n              1,\n              0,\n              0,\n              0,\n              2,\n              2,\n              1,\n              2,\n              0,\n              0,\n              0,\n              1,\n              1,\n              2,\n              2,\n              0,\n              0,\n              1,\n              2,\n              2,\n              1,\n              2,\n              1,\n              1,\n              1,\n              2,\n              1\n            ],\n            &quot;mark&quot;: 2\n          },\n          &quot;status&quot;: &quot;ACTIVE&quot;\n        }\n      ],\n      [\n        {\n          &quot;action&quot;: 0,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              2,\n              0,\n              0,\n              0,\n              1,\n              0,\n              0,\n              1,\n              0,\n              0,\n              0,\n              2,\n              2,\n              1,\n              2,\n              0,\n              0,\n              0,\n              1,\n              1,\n              2,\n              2,\n              0,\n              2,\n              1,\n              2,\n              2,\n              1,\n              2,\n              1,\n              1,\n              1,\n              2,\n              1\n            ],\n            &quot;mark&quot;: 1\n          },\n          &quot;status&quot;: &quot;ACTIVE&quot;\n        },\n        {\n          &quot;action&quot;: 3,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              2,\n              0,\n              0,\n              0,\n              1,\n              0,\n              0,\n              1,\n              0,\n              0,\n              0,\n              2,\n              2,\n              1,\n              2,\n              0,\n              0,\n              0,\n              1,\n              1,\n              2,\n              2,\n              0,\n              2,\n              1,\n              2,\n              2,\n              1,\n              2,\n              1,\n              1,\n              1,\n              2,\n              1\n            ],\n            &quot;mark&quot;: 2\n          },\n          &quot;status&quot;: &quot;INACTIVE&quot;\n        }\n      ],\n      [\n        {\n          &quot;action&quot;: 5,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              1,\n              0,\n              0,\n              2,\n              0,\n              0,\n              0,\n              1,\n              0,\n              0,\n              1,\n              0,\n              0,\n              0,\n              2,\n              2,\n              1,\n              2,\n              0,\n              0,\n              0,\n              1,\n              1,\n              2,\n              2,\n              0,\n              2,\n              1,\n              2,\n              2,\n              1,\n              2,\n              1,\n              1,\n              1,\n              2,\n              1\n            ],\n            &quot;mark&quot;: 1\n          },\n          &quot;status&quot;: &quot;INACTIVE&quot;\n        },\n        {\n          &quot;action&quot;: 0,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              1,\n              0,\n              0,\n              2,\n              0,\n              0,\n              0,\n              1,\n              0,\n              0,\n              1,\n              0,\n              0,\n              0,\n              2,\n              2,\n              1,\n              2,\n              0,\n              0,\n              0,\n              1,\n              1,\n              2,\n              2,\n              0,\n              2,\n              1,\n              2,\n              2,\n              1,\n              2,\n              1,\n              1,\n              1,\n              2,\n              1\n            ],\n            &quot;mark&quot;: 2\n          },\n          &quot;status&quot;: &quot;ACTIVE&quot;\n        }\n      ],\n      [\n        {\n          &quot;action&quot;: 0,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              1,\n              0,\n              0,\n              2,\n              0,\n              0,\n              0,\n              1,\n              0,\n              0,\n              1,\n              0,\n              0,\n              0,\n              2,\n              2,\n              1,\n              2,\n              0,\n              2,\n              0,\n              1,\n              1,\n              2,\n              2,\n              0,\n              2,\n              1,\n              2,\n              2,\n              1,\n              2,\n              1,\n              1,\n              1,\n              2,\n              1\n            ],\n            &quot;mark&quot;: 1\n          },\n          &quot;status&quot;: &quot;ACTIVE&quot;\n        },\n        {\n          &quot;action&quot;: 3,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              1,\n              0,\n              0,\n              2,\n              0,\n              0,\n              0,\n              1,\n              0,\n              0,\n              1,\n              0,\n              0,\n              0,\n              2,\n              2,\n              1,\n              2,\n              0,\n              2,\n              0,\n              1,\n              1,\n              2,\n              2,\n              0,\n              2,\n              1,\n              2,\n              2,\n              1,\n              2,\n              1,\n              1,\n              1,\n              2,\n              1\n            ],\n            &quot;mark&quot;: 2\n          },\n          &quot;status&quot;: &quot;INACTIVE&quot;\n        }\n      ],\n      [\n        {\n          &quot;action&quot;: 1,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              1,\n              0,\n              0,\n              0,\n              1,\n              0,\n              0,\n              2,\n              0,\n              0,\n              0,\n              1,\n              0,\n              0,\n              1,\n              0,\n              0,\n              0,\n              2,\n              2,\n              1,\n              2,\n              0,\n              2,\n              0,\n              1,\n              1,\n              2,\n              2,\n              0,\n              2,\n              1,\n              2,\n              2,\n              1,\n              2,\n              1,\n              1,\n              1,\n              2,\n              1\n            ],\n            &quot;mark&quot;: 1\n          },\n          &quot;status&quot;: &quot;INACTIVE&quot;\n        },\n        {\n          &quot;action&quot;: 0,\n          &quot;reward&quot;: 0.5,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              1,\n              0,\n              0,\n              0,\n              1,\n              0,\n              0,\n              2,\n              0,\n              0,\n              0,\n              1,\n              0,\n              0,\n              1,\n              0,\n              0,\n              0,\n              2,\n              2,\n              1,\n              2,\n              0,\n              2,\n              0,\n              1,\n              1,\n              2,\n              2,\n              0,\n              2,\n              1,\n              2,\n              2,\n              1,\n              2,\n              1,\n              1,\n              1,\n              2,\n              1\n            ],\n            &quot;mark&quot;: 2\n          },\n          &quot;status&quot;: &quot;ACTIVE&quot;\n        }\n      ],\n      [\n        {\n          &quot;action&quot;: 0,\n          &quot;reward&quot;: 0,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              1,\n              0,\n              0,\n              0,\n              1,\n              0,\n              0,\n              2,\n              0,\n              0,\n              0,\n              1,\n              0,\n              0,\n              1,\n              0,\n              0,\n              0,\n              2,\n              2,\n              1,\n              2,\n              0,\n              2,\n              0,\n              1,\n              1,\n              2,\n              2,\n              2,\n              2,\n              1,\n              2,\n              2,\n              1,\n              2,\n              1,\n              1,\n              1,\n              2,\n              1\n            ],\n            &quot;mark&quot;: 1\n          },\n          &quot;status&quot;: &quot;DONE&quot;\n        },\n        {\n          &quot;action&quot;: 2,\n          &quot;reward&quot;: 1,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;board&quot;: [\n              0,\n              1,\n              0,\n              0,\n              0,\n              1,\n              0,\n              0,\n              2,\n              0,\n              0,\n              0,\n              1,\n              0,\n              0,\n              1,\n              0,\n              0,\n              0,\n              2,\n              2,\n              1,\n              2,\n              0,\n              2,\n              0,\n              1,\n              1,\n              2,\n              2,\n              2,\n              2,\n              1,\n              2,\n              2,\n              1,\n              2,\n              1,\n              1,\n              1,\n              2,\n              1\n            ],\n            &quot;mark&quot;: 2\n          },\n          &quot;status&quot;: &quot;DONE&quot;\n        }\n      ]\n    ],\n    &quot;rewards&quot;: [\n      0,\n      1\n    ],\n    &quot;statuses&quot;: [\n      &quot;DONE&quot;,\n      &quot;DONE&quot;\n    ],\n    &quot;schema_version&quot;: 1\n  },\n  &quot;mode&quot;: &quot;ipython&quot;,\n  &quot;width&quot;: 500,\n  &quot;height&quot;: 450\n};\n\n\nwindow.kaggle.renderer = // Copyright 2020 Kaggle Inc\n//\n// Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//      http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an &quot;AS IS&quot; BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\nfunction renderer({\n  act,\n  agents,\n  environment,\n  frame,\n  height = 400,\n  interactive,\n  isInteractive,\n  parent,\n  step,\n  update,\n  width = 400,\n}) {\n  // Configuration.\n  const { rows, columns, inarow } = environment.configuration;\n\n  // Common Dimensions.\n  const unit = 8;\n  const minCanvasSize = Math.min(height, width);\n  const minOffset = minCanvasSize > 400 ? 30 : unit / 2;\n  const cellSize = Math.min(\n    (width - minOffset * 2) / columns,\n    (height - minOffset * 2) / rows\n  );\n  const cellInset = 0.8;\n  const pieceScale = cellSize / 100;\n  const xOffset = Math.max(0, (width - cellSize * columns) / 2);\n  const yOffset = Math.max(0, (height - cellSize * rows) / 2);\n\n  // Canvas Setup.\n  let canvas = parent.querySelector(&quot;canvas&quot;);\n  if (!canvas) {\n    canvas = document.createElement(&quot;canvas&quot;);\n    parent.appendChild(canvas);\n\n    if (interactive) {\n      canvas.addEventListener(&quot;click&quot;, evt => {\n        if (!isInteractive()) return;\n        const rect = evt.target.getBoundingClientRect();\n        const col = Math.floor((evt.clientX - rect.left - xOffset) / cellSize);\n        if (col >= 0 && col < columns) act(col);\n      });\n    }\n  }\n  canvas.style.cursor = isInteractive() ? &quot;pointer&quot; : &quot;default&quot;;\n\n  // Character Paths (based on 100x100 tiles).\n  const kPath = new Path2D(\n    `M78.3,96.5c-0.1,0.4-0.5,0.6-1.1,0.6H64.9c-0.7,0-1.4-0.3-1.9-1l-20.3-26L37,75.5v20.1 c0,0.9-0.5,1.4-1.4,1.4H26c-0.9,0-1.4-0.5-1.4-1.4V3.9c0-0.9,0.5-1.4,1.4-1.4h9.5C36.5,2.5,37,3,37,3.9v56.5l24.3-24.7 c0.6-0.6,1.3-1,1.9-1H76c0.6,0,0.9,0.2,1.1,0.7c0.2,0.6,0.1,1-0.1,1.2l-25.7,25L78,95.1C78.4,95.5,78.5,95.9,78.3,96.5z`\n  );\n  const goose1Path = new Path2D(\n    `M8.8,92.7c-4-18.5,4.7-37.2,20.7-46.2c0,0,2.7-1.4,3.4-1.9c2.2-1.6,3-2.1,3-5c0-5-2.1-7.2-2.1-7.2 c-3.9-3.3-6.3-8.2-6.3-13.7c0-10,8.1-18.1,18.1-18.1s18.1,8.1,18.1,18.1c0,6-1.5,32.7-2.3,38.8l-0.1,1`\n  );\n  const goose2Path = new Path2D(\n    `M27.4,19L8.2,27.6c0,0-7.3,2.9,2.6,5c6.1,1.3,24,5.9,24,5.9l1,0.3`\n  );\n  const goose3Path = new Path2D(\n    `M63.7,99.6C52.3,99.6,43,90.3,43,78.9s9.3-20.7,20.7-20.7c10.6,0,34.4,0.1,35.8,9`\n  );\n\n  // Canvas setup and reset.\n  let c = canvas.getContext(&quot;2d&quot;);\n  canvas.width = width;\n  canvas.height = height;\n  c.fillStyle = &quot;#000B2A&quot;;\n  c.fillRect(0, 0, canvas.width, canvas.height);\n\n  const getRowCol = cell => [Math.floor(cell / columns), cell % columns];\n\n  const getColor = (mark, opacity = 1) => {\n    if (mark === 1) return `rgba(0,255,255,${opacity})`;\n    if (mark === 2) return `rgba(255,255,255,${opacity})`;\n    return &quot;#fff&quot;;\n  };\n\n  const drawCellCircle = (cell, xFrame = 1, yFrame = 1, radiusOffset = 0) => {\n    const [row, col] = getRowCol(cell);\n    c.arc(\n      xOffset + xFrame * (col * cellSize + cellSize / 2),\n      yOffset + yFrame * (row * cellSize + cellSize / 2),\n      (cellInset * cellSize) / 2 - radiusOffset,\n      2 * Math.PI,\n      false\n    );\n  };\n\n  // Render the pieces.\n  const board = environment.steps[step][0].observation.board;\n\n  const drawPiece = mark => {\n    // Base Styles.\n    const opacity = minCanvasSize < 300 ? 0.6 - minCanvasSize / 1000 : 0.1;\n    c.fillStyle = getColor(mark, opacity);\n    c.strokeStyle = getColor(mark);\n    c.shadowColor = getColor(mark);\n    c.shadowBlur = 8 / cellInset;\n    c.lineWidth = 1 / cellInset;\n\n    // Outer circle.\n    c.save();\n    c.beginPath();\n    c.arc(50, 50, 50, 2 * Math.PI, false);\n    c.closePath();\n    c.lineWidth *= 4;\n    c.stroke();\n    c.fill();\n    c.restore();\n\n    // Inner circle.\n    c.beginPath();\n    c.arc(50, 50, 40, 2 * Math.PI, false);\n    c.closePath();\n    c.stroke();\n\n    // Kaggle &quot;K&quot;.\n    if (mark === 1) {\n      const scale = 0.54;\n      c.save();\n      c.translate(23, 23);\n      c.scale(scale, scale);\n      c.lineWidth /= scale;\n      c.shadowBlur /= scale;\n      c.stroke(kPath);\n      c.restore();\n    }\n\n    // Kaggle &quot;Goose&quot;.\n    if (mark === 2) {\n      const scale = 0.6;\n      c.save();\n      c.translate(24, 28);\n      c.scale(scale, scale);\n      c.lineWidth /= scale;\n      c.shadowBlur /= scale;\n      c.stroke(goose1Path);\n      c.stroke(goose2Path);\n      c.stroke(goose3Path);\n      c.beginPath();\n      c.arc(38.5, 18.6, 2.7, 0, Math.PI * 2, false);\n      c.closePath();\n      c.fill();\n      c.restore();\n    }\n  };\n\n  for (let i = 0; i < board.length; i++) {\n    const [row, col] = getRowCol(i);\n    if (board[i] === 0) continue;\n    // Easing In.\n    let yFrame = Math.min(\n      (columns * Math.pow(frame, 3)) / Math.floor(i / columns),\n      1\n    );\n\n    if (\n      step > 1 &&\n      environment.steps[step - 1][0].observation.board[i] === board[i]\n    ) {\n      yFrame = 1;\n    }\n\n    c.save();\n    c.translate(\n      xOffset + cellSize * col + (cellSize - cellSize * cellInset) / 2,\n      yOffset +\n        yFrame * (cellSize * row) +\n        (cellSize - cellSize * cellInset) / 2\n    );\n    c.scale(pieceScale * cellInset, pieceScale * cellInset);\n    drawPiece(board[i]);\n    c.restore();\n  }\n\n  // Background Gradient.\n  const bgRadius = (Math.min(rows, columns) * cellSize) / 2;\n  const bgStyle = c.createRadialGradient(\n    xOffset + (cellSize * columns) / 2,\n    yOffset + (cellSize * rows) / 2,\n    0,\n    xOffset + (cellSize * columns) / 2,\n    yOffset + (cellSize * rows) / 2,\n    bgRadius\n  );\n  bgStyle.addColorStop(0, &quot;#000B49&quot;);\n  bgStyle.addColorStop(1, &quot;#000B2A&quot;);\n\n  // Render the board overlay.\n  c.beginPath();\n  c.rect(0, 0, canvas.width, canvas.height);\n  c.closePath();\n  c.shadowBlur = 0;\n  for (let i = 0; i < board.length; i++) {\n    drawCellCircle(i);\n    c.closePath();\n  }\n  c.fillStyle = bgStyle;\n  c.fill(&quot;evenodd&quot;);\n\n  // Render the board overlay cell outlines.\n  for (let i = 0; i < board.length; i++) {\n    c.beginPath();\n    drawCellCircle(i);\n    c.strokeStyle = &quot;#0361B2&quot;;\n    c.lineWidth = 1;\n    c.stroke();\n    c.closePath();\n  }\n\n  const drawLine = (fromCell, toCell) => {\n    if (frame < 0.5) return;\n    const lineFrame = (frame - 0.5) / 0.5;\n    const x1 = xOffset + (fromCell % columns) * cellSize + cellSize / 2;\n    const x2 =\n      x1 +\n      lineFrame *\n        (xOffset + ((toCell % columns) * cellSize + cellSize / 2) - x1);\n    const y1 =\n      yOffset + Math.floor(fromCell / columns) * cellSize + cellSize / 2;\n    const y2 =\n      y1 +\n      lineFrame *\n        (yOffset + Math.floor(toCell / columns) * cellSize + cellSize / 2 - y1);\n    c.beginPath();\n    c.lineCap = &quot;round&quot;;\n    c.lineWidth = 4;\n    c.strokeStyle = getColor(board[fromCell]);\n    c.shadowBlur = 8;\n    c.shadowColor = getColor(board[fromCell]);\n    c.moveTo(x1, y1);\n    c.lineTo(x2, y2);\n    c.stroke();\n  };\n\n  // Generate a graph of the board.\n  const getCell = (cell, rowOffset, columnOffset) => {\n    const row = Math.floor(cell / columns) + rowOffset;\n    const col = (cell % columns) + columnOffset;\n    if (row < 0 || row >= rows || col < 0 || col >= columns) return -1;\n    return col + row * columns;\n  };\n  const makeNode = cell => {\n    const node = { cell, directions: [], value: board[cell] };\n    for (let r = -1; r <= 1; r++) {\n      for (let c = -1; c <= 1; c++) {\n        if (r === 0 && c === 0) continue;\n        node.directions.push(getCell(cell, r, c));\n      }\n    }\n    return node;\n  };\n  const graph = board.map((_, i) => makeNode(i));\n\n  // Check for any wins!\n  const getSequence = (node, direction) => {\n    const sequence = [node.cell];\n    while (sequence.length < inarow) {\n      const next = graph[node.directions[direction]];\n      if (!next || node.value !== next.value || next.value === 0) return;\n      node = next;\n      sequence.push(node.cell);\n    }\n    return sequence;\n  };\n\n  // Check all nodes.\n  for (let i = 0; i < board.length; i++) {\n    // Check all directions (not the most efficient).\n    for (let d = 0; d < 8; d++) {\n      const seq = getSequence(graph[i], d);\n      if (seq) {\n        drawLine(seq[0], seq[3]);\n        i = board.length;\n        break;\n      }\n    }\n  }\n\n  // Upgrade the legend.\n  if (agents.length && (!agents[0].color || !agents[0].image)) {\n    const getPieceImage = mark => {\n      const pieceCanvas = document.createElement(&quot;canvas&quot;);\n      parent.appendChild(pieceCanvas);\n      pieceCanvas.style.marginLeft = &quot;10000px&quot;;\n      pieceCanvas.width = 100;\n      pieceCanvas.height = 100;\n      c = pieceCanvas.getContext(&quot;2d&quot;);\n      c.translate(10, 10);\n      c.scale(0.8, 0.8);\n      drawPiece(mark);\n      const dataUrl = pieceCanvas.toDataURL();\n      parent.removeChild(pieceCanvas);\n      return dataUrl;\n    };\n\n    agents.forEach(agent => {\n      agent.color = getColor(agent.index + 1);\n      agent.image = getPieceImage(agent.index + 1);\n    });\n    update({ agents });\n  }\n};\n\n\n    \n    </script>\n    <script>\n      const h = htm.bind(preact.h);\n      const { useContext, useEffect, useRef, useState } = preactHooks;\n      const styled = window.styled.default;\n\n      const Context = preact.createContext({});\n\n      const Loading = styled.div`\n        animation: rotate360 1.1s infinite linear;\n        border: 8px solid rgba(255, 255, 255, 0.2);\n        border-left-color: #0cb1ed;\n        border-radius: 50%;\n        height: 40px;\n        position: relative;\n        transform: translateZ(0);\n        width: 40px;\n\n        @keyframes rotate360 {\n          0% {\n            transform: rotate(0deg);\n          }\n          100% {\n            transform: rotate(360deg);\n          }\n        }\n      `;\n\n      const Logo = styled(\n        props => h`\n        <a href=&quot;https://kaggle.com&quot; target=&quot;_blank&quot; className=${props.className}>\n          <svg width=&quot;62px&quot; height=&quot;20px&quot; viewBox=&quot;0 0 62 24&quot; version=&quot;1.1&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;>\n            <g fill=&quot;#1EBEFF&quot; fill-rule=&quot;nonzero&quot;>\n              <path d=&quot;M10.2,17.8c0,0.1-0.1,0.1-0.2,0.1H7.7c-0.1,0-0.3-0.1-0.4-0.2l-3.8-4.9l-1.1,1v3.8 c0,0.2-0.1,0.3-0.3,0.3H0.3c-0.2,0-0.3-0.1-0.3-0.3V0.3C0.1,0.1,0.2,0,0.3,0h1.8c0.2,0,0.3,0.1,0.3,0.3V11L7,6.3 c0.1-0.1,0.2-0.2,0.4-0.2h2.4c0.1,0,0.2,0,0.2,0.1c0,0.1,0,0.2,0,0.2l-4.9,4.7l5.1,6.3C10.2,17.6,10.2,17.7,10.2,17.8z&quot;/>\n              <path d=&quot;M19.6,17.9h-1.8c-0.2,0-0.3-0.1-0.3-0.3v-0.4c-0.8,0.6-1.8,0.9-3,0.9c-1.1,0-2-0.3-2.8-1 c-0.8-0.7-1.2-1.6-1.2-2.7c0-1.7,1.1-2.9,3.2-3.5c0.8-0.2,2.1-0.5,3.8-0.6c0.1-0.6-0.1-1.2-0.5-1.7c-0.4-0.5-1-0.7-1.7-0.7 c-1,0-2,0.4-3,1C12.2,9.1,12.1,9.1,12,9l-0.9-1.3C11,7.5,11,7.4,11.1,7.3c1.3-0.9,2.7-1.4,4.2-1.4c1.1,0,2.1,0.3,2.8,0.8 c1.1,0.8,1.7,2,1.7,3.7v7.3C19.9,17.8,19.8,17.9,19.6,17.9z M17.5,12.4c-1.7,0.2-2.9,0.4-3.5,0.7c-0.9,0.4-1.2,0.9-1.1,1.6 c0.1,0.4,0.2,0.7,0.6,0.9c0.3,0.2,0.7,0.4,1.1,0.4c1.2,0.1,2.2-0.2,2.9-1V12.4z&quot;/>\n              <path d=&quot;M30.6,22.5c-0.9,1-2.3,1.5-4,1.5c-1,0-2-0.3-2.9-0.8c-0.2-0.1-0.4-0.3-0.7-0.5 c-0.3-0.2-0.6-0.5-0.9-0.7c-0.1-0.1-0.1-0.2,0-0.4l1.2-1.2c0.1-0.1,0.1-0.1,0.2-0.1c0.1,0,0.1,0,0.2,0.1c1,1,1.9,1.5,2.8,1.5 c2.1,0,3.2-1.1,3.2-3.3v-1.4c-0.8,0.7-1.9,1-3.3,1c-1.7,0-3-0.6-4-1.9c-0.8-1.1-1.3-2.5-1.3-4.2c0-1.6,0.4-3,1.2-4.1 c0.9-1.3,2.3-2,4-2c1.3,0,2.4,0.3,3.3,1V6.4c0-0.2,0.1-0.3,0.3-0.3h1.8c0.2,0,0.3,0.1,0.3,0.3v11.7C32,20,31.5,21.5,30.6,22.5z M29.7,9.9c-0.4-1.1-1.4-1.7-3-1.7c-2,0-3.1,1.3-3.1,3.8c0,1.4,0.3,2.4,1,3.1c0.5,0.5,1.2,0.8,2,0.8c1.6,0,2.7-0.6,3.1-1.7V9.9z&quot;/>\n              <path d=&quot;M42.9,22.5c-0.9,1-2.3,1.5-4,1.5c-1,0-2-0.3-2.9-0.8c-0.2-0.1-0.4-0.3-0.7-0.5 c-0.3-0.2-0.6-0.5-0.9-0.7c-0.1-0.1-0.1-0.2,0-0.4l1.2-1.2c0.1-0.1,0.1-0.1,0.2-0.1c0.1,0,0.1,0,0.2,0.1c1,1,1.9,1.5,2.8,1.5 c2.1,0,3.2-1.1,3.2-3.3v-1.4c-0.8,0.7-1.9,1-3.3,1c-1.7,0-3-0.6-4-1.9c-0.8-1.1-1.3-2.5-1.3-4.2c0-1.6,0.4-3,1.2-4.1 c0.9-1.3,2.3-2,4-2c1.3,0,2.4,0.3,3.3,1V6.4c0-0.2,0.1-0.3,0.3-0.3H44c0.2,0,0.3,0.1,0.3,0.3v11.7C44.3,20,43.8,21.5,42.9,22.5z M42,9.9c-0.4-1.1-1.4-1.7-3-1.7c-2,0-3.1,1.3-3.1,3.8c0,1.4,0.3,2.4,1,3.1c0.5,0.5,1.2,0.8,2,0.8c1.6,0,2.7-0.6,3.1-1.7L42,9.9 L42,9.9z&quot;/>\n              <path d=&quot;M48.3,17.9h-1.8c-0.2,0-0.3-0.1-0.3-0.3V0.3c0-0.2,0.1-0.3,0.3-0.3h1.8c0.2,0,0.3,0.1,0.3,0.3 v17.3C48.5,17.8,48.5,17.9,48.3,17.9z&quot;/>\n              <path d=&quot;M61.4,12.6c0,0.2-0.1,0.3-0.3,0.3h-8.5c0.1,0.9,0.5,1.6,1.1,2.2c0.7,0.6,1.6,0.9,2.7,0.9 c1,0,1.8-0.3,2.6-0.8c0.2-0.1,0.3-0.1,0.4,0l1.2,1.3c0.1,0.1,0.1,0.3,0,0.4c-1.3,0.9-2.7,1.4-4.4,1.4c-1.8,0-3.3-0.6-4.4-1.8 c-1.1-1.2-1.7-2.7-1.7-4.5c0-1.7,0.6-3.2,1.7-4.4c1-1.1,2.4-1.6,4.1-1.6c1.6,0,2.9,0.6,4,1.7c1.1,1.2,1.6,2.6,1.5,4.4L61.4,12.6 z M58,8.7c-0.6-0.5-1.3-0.8-2.1-0.8c-0.8,0-1.5,0.3-2.1,0.8c-0.6,0.5-1,1.2-1.1,2H59C59,9.9,58.6,9.3,58,8.7z&quot;/>\n            </g>\n          </svg>\n        </a>\n      `\n      )`\n        display: inline-flex;\n      `;\n\n      const Header = styled(props => {\n        const { environment } = useContext(Context);\n\n        return h`<div className=${props.className} >\n          <${Logo} />\n          ${environment.title}\n        </div>`;\n      })`\n        align-items: center;\n        border-bottom: 4px solid #212121;\n        box-sizing: border-box;\n        color: #fff;\n        display: flex;\n        flex: 0 0 36px;\n        font-size: 14px;\n        justify-content: space-between;\n        padding: 0 8px;\n        width: 100%;\n      `;\n\n      const Renderer = styled(props => {\n        const context = useContext(Context);\n        const { animate, debug, playing, renderer, speed } = context;\n        const ref = preact.createRef();\n\n        useEffect(async () => {\n          if (!ref.current) return;\n\n          const renderFrame = async (start, step, lastFrame) => {\n            if (step !== context.step) return;\n            if (lastFrame === 1) {\n              if (!animate) return;\n              start = Date.now();\n            }\n            const frame =\n              playing || animate\n                ? Math.min((Date.now() - start) / speed, 1)\n                : 1;\n            try {\n              if (debug) console.time(&quot;render&quot;);\n              await renderer({\n                ...context,\n                frame,\n                height: ref.current.clientHeight,\n                hooks: preactHooks,\n                parent: ref.current,\n                preact,\n                styled,\n                width: ref.current.clientWidth,\n              });\n            } catch (error) {\n              console.log({ ...context, frame, error });\n            } finally {\n              if (debug) console.timeEnd(&quot;render&quot;);\n            }\n            window.requestAnimationFrame(() => renderFrame(start, step, frame));\n          };\n\n          await renderFrame(Date.now(), context.step);\n        }, [ref.current, context.step, context.renderer]);\n\n        return h`<div className=${props.className} ref=${ref} />`;\n      })`\n        align-items: center;\n        box-sizing: border-box;\n        display: flex;\n        height: 100%;\n        left: 0;\n        justify-content: center;\n        position: absolute;\n        top: 0;\n        width: 100%;\n      `;\n\n      const Processing = styled(props => {\n        const { processing } = useContext(Context);\n        return h`<div className=${props.className}>Processing...</div>`;\n      })`\n        bottom: 0;\n        color: #fff;\n        font-size: 12px;\n        left: 0;\n        line-height: 24px;\n        position: absolute;\n        text-align: center;\n        width: 100%;\n      `;\n\n      const Viewer = styled(props => {\n        const { processing } = useContext(Context);\n        return h`<div className=${props.className}>\n          <${Renderer} />\n          ${processing && h`<${Processing} />`}\n        </div>`;\n      })`\n        background-color: #000b2a;\n        background-image: radial-gradient(\n          circle closest-side,\n          #000b49,\n          #000b2a\n        );\n        display: flex;\n        flex: 1;\n        overflow: hidden;\n        position: relative;\n        width: 100%;\n      `;\n\n      const Legend = styled(props => {\n        const { agents, legend } = useContext(Context);\n\n        return h`<div className=${props.className}>\n          <ul>\n            ${agents\n              .sort((a, b) => a.index - b.index)\n              .map(a => {\n                const name =\n                  a.name.length > 15 ? a.name.substr(0, 14) + &quot;&quot; : a.name;\n                return h`<li key=${a.id} title=&quot;id: ${\n                  a.id\n                }&quot; style=&quot;color:${a.color || &quot;#FFF&quot;}&quot;>${a.image &&\n                  h`<img src=${a.image} />`}${name}</li>`;\n              })}\n          </ul>\n        </div>`;\n      })`\n        background-color: #000b2a;\n        font-family: sans-serif;\n        font-size: 14px;\n        width: 100%;\n\n        ul {\n          align-items: center;\n          display: flex;\n          flex-direction: row;\n          justify-content: center;\n        }\n\n        li {\n          align-items: center;\n          display: inline-flex;\n          padding: 8px;\n          transition: color 1s;\n        }\n\n        img {\n          height: 24px;\n          margin-right: 4px;\n          width: 24px;\n        }\n      `;\n\n      const StepInput = styled.input.attrs({\n        type: &quot;range&quot;,\n      })`\n        appearance: none;\n        background: rgba(255, 255, 255, 0.15);\n        border-radius: 2px;\n        display: block;\n        flex: 1;\n        height: 4px;\n        opacity: 0.8;\n        outline: none;\n        transition: opacity 0.2s;\n        width: 100%;\n\n        &:hover {\n          opacity: 1;\n        }\n\n        &::-webkit-slider-thumb {\n          appearance: none;\n          background: #1ebeff;\n          border-radius: 100%;\n          cursor: pointer;\n          height: 12px;\n          margin: 0;\n          position: relative;\n          width: 12px;\n\n          &::after {\n            content: &quot;&quot;;\n            position: absolute;\n            top: 0px;\n            left: 0px;\n            width: 200px;\n            height: 8px;\n            background: green;\n          }\n        }\n      `;\n\n      const PlayButton = styled.button`\n        align-items: center;\n        background: none;\n        border: none;\n        color: white;\n        cursor: pointer;\n        display: flex;\n        flex: 0 0 56px;\n        font-size: 20px;\n        height: 40px;\n        justify-content: center;\n        opacity: 0.8;\n        outline: none;\n        transition: opacity 0.2s;\n\n        &:hover {\n          opacity: 1;\n        }\n      `;\n\n      const StepCount = styled.span`\n        align-items: center;\n        color: white;\n        display: flex;\n        font-size: 14px;\n        justify-content: center;\n        opacity: 0.8;\n        padding: 0 16px;\n        pointer-events: none;\n      `;\n\n      const Controls = styled(props => {\n        const { environment, pause, play, playing, setStep, step } = useContext(\n          Context\n        );\n        const value = step + 1;\n        const onClick = () => (playing ? pause() : play());\n        const onInput = e => {\n          pause();\n          setStep(parseInt(e.target.value) - 1);\n        };\n\n        return h`\n          <div className=${props.className}>\n            <${PlayButton} onClick=${onClick}><svg xmlns=&quot;http://www.w3.org/2000/svg&quot; width=&quot;24px&quot; height=&quot;24px&quot; viewBox=&quot;0 0 24 24&quot; fill=&quot;#FFFFFF&quot;>${\n          playing\n            ? h`<path d=&quot;M6 19h4V5H6v14zm8-14v14h4V5h-4z&quot;/><path d=&quot;M0 0h24v24H0z&quot; fill=&quot;none&quot;/>`\n            : h`<path d=&quot;M8 5v14l11-7z&quot;/><path d=&quot;M0 0h24v24H0z&quot; fill=&quot;none&quot;/>`\n        }</svg><//>\n            <${StepInput} min=&quot;1&quot; max=${\n          environment.steps.length\n        } value=&quot;${value}&quot; onInput=${onInput} />\n            <${StepCount}>${value} / ${environment.steps.length}<//>\n          </div>\n        `;\n      })`\n        align-items: center;\n        border-top: 4px solid #212121;\n        display: flex;\n        flex: 0 0 44px;\n        width: 100%;\n      `;\n\n      const Info = styled(props => {\n        const {\n          environment,\n          playing,\n          step,\n          speed,\n          animate,\n          header,\n          controls,\n          settings,\n        } = useContext(Context);\n\n        return h`\n          <div className=${props.className}>\n            info:\n            step(${step}),\n            playing(${playing ? &quot;T&quot; : &quot;F&quot;}),\n            speed(${speed}),\n            animate(${animate ? &quot;T&quot; : &quot;F&quot;})\n          </div>`;\n      })`\n        color: #888;\n        font-family: monospace;\n        font-size: 12px;\n      `;\n\n      const Settings = styled(props => {\n        const { environment, pause, play, playing, setStep, step } = useContext(\n          Context\n        );\n\n        return h`\n          <div className=${props.className}>\n            <${Info} />\n          </div>\n        `;\n      })`\n        background: #fff;\n        border-top: 4px solid #212121;\n        box-sizing: border-box;\n        padding: 20px;\n        width: 100%;\n\n        h1 {\n          font-size: 20px;\n        }\n      `;\n\n      const Player = styled(props => {\n        const context = useContext(Context);\n        const { agents, controls, header, legend, loading, settings } = context;\n        return h`\n          <div className=${props.className}>\n            ${loading && h`<${Loading} />`}\n            ${!loading && header && h`<${Header} />`}\n            ${!loading && h`<${Viewer} />`}\n            ${!loading && agents.length > 0 && legend && h`<${Legend} />`}\n            ${!loading && controls && h`<${Controls} />`}\n            ${!loading && settings && h`<${Settings} />`}\n          </div>`;\n      })`\n        align-items: center;\n        background: #212121;\n        border: 4px solid #212121;\n        box-sizing: border-box;\n        display: flex;\n        flex-direction: column;\n        height: 100%;\n        justify-content: center;\n        position: relative;\n        width: 100%;\n      `;\n\n      const App = () => {\n        const renderCountRef = useRef(0);\n        const [_, setRenderCount] = useState(0);\n\n        const contextRef = useRef({\n          animate: false,\n          agents: [],\n          autoplay: false,\n          controls: false,\n          debug: false,\n          environment: { steps: [] },\n          header: window.innerHeight >= 600,\n          interactive: false,\n          legend: true,\n          loading: false,\n          playing: false,\n          processing: false,\n          renderer: () => &quot;DNE&quot;,\n          settings: false,\n          speed: 500,\n          step: 0,\n        });\n\n        // Context helpers.\n        const rerender = (contextRef.current.rerender = () =>\n          setRenderCount((renderCountRef.current += 1)));\n        const setStep = (contextRef.current.setStep = newStep => {\n          contextRef.current.step = newStep;\n          rerender();\n        });\n        const setPlaying = (contextRef.current.setPlaying = playing => {\n          contextRef.current.playing = playing;\n          rerender();\n        });\n        const pause = (contextRef.current.pause = () => setPlaying(false));\n\n        const playNext = () => {\n          const context = contextRef.current;\n\n          if (\n            context.playing &&\n            context.step < context.environment.steps.length - 1\n          ) {\n            setStep(context.step + 1);\n            play(true);\n          } else {\n            pause();\n          }\n        };\n\n        const play = (contextRef.current.play = continuing => {\n          const context = contextRef.current;\n          if (context.playing && !continuing) return;\n          if (!context.playing) setPlaying(true);\n          if (\n            !continuing &&\n            context.step === context.environment.steps.length - 1\n          ) {\n            setStep(0);\n          }\n          setTimeout(playNext, context.speed);\n        });\n\n        const updateContext = o => {\n          const context = contextRef.current;\n          Object.assign(context, o, {\n            environment: { ...context.environment, ...(o.environment || {}) },\n          });\n          rerender();\n\n          // If autoplay, toggle to playing.\n          if (context.autoplay) play();\n        };\n\n        // First time setup.\n        useEffect(() => {\n          // Timeout is used to ensure useEffect renders once.\n          setTimeout(() => {\n            // Initialize context with window.kaggle.\n            updateContext(window.kaggle || {});\n            // Listen for messages received to update the context.\n            window.addEventListener(\n              &quot;message&quot;,\n              event => {\n                // Ensure the environment names match before updating.\n                try {\n                  if (\n                    event.data.environment.name ==\n                    contextRef.current.environment.name\n                  ) {\n                    updateContext(event.data);\n                  }\n                } catch {}\n              },\n              false\n            );\n            // Listen for keyboard commands.\n            window.addEventListener(\n              &quot;keyup&quot;,\n              event => {\n                const { playing, step, environment } = contextRef.current;\n                const key = event.keyCode;\n                if (key !== 32 && key !== 37 && key !== 39) return;\n\n                if (key === 32) {\n                  playing ? pause() : play();\n                } else if (event.keyCode === 39) {\n                  contextRef.current.playing = false;\n                  if (step < environment.steps.length - 1) setStep(step + 1);\n                  rerender();\n                } else if (event.keyCode === 37) {\n                  contextRef.current.playing = false;\n                  if (step > 0) setStep(step - 1);\n                  rerender();\n                }\n                event.preventDefault();\n                return false;\n              },\n              false\n            );\n          }, 1);\n        }, []);\n\n        if (contextRef.current.debug) {\n          console.log(&quot;context&quot;, contextRef.current);\n        }\n\n        // Ability to update context.\n        contextRef.current.update = updateContext;\n\n        // Ability to communicate with ipython.\n        const execute = (contextRef.current.execute = source =>\n          new Promise((resolve, reject) => {\n            try {\n              window.parent.IPython.notebook.kernel.execute(source, {\n                iopub: {\n                  output: resp => {\n                    const type = resp.msg_type;\n                    if (type === &quot;stream&quot;) return resolve(resp.content.text);\n                    if (type === &quot;error&quot;) return reject(new Error(resp.evalue));\n                    return reject(new Error(&quot;Unknown message type: &quot; + type));\n                  },\n                },\n              });\n            } catch (e) {\n              reject(new Error(&quot;IPython Unavailable: &quot; + e));\n            }\n          }));\n\n        // Ability to return an action from an interactive session.\n        contextRef.current.act = action => {\n          const id = contextRef.current.environment.id;\n          updateContext({ processing: true });\n          execute(`\n            import json\n            from kaggle_environments import interactives\n            if &quot;${id}&quot; in interactives:\n                action = json.loads('${JSON.stringify(action)}')\n                env, trainer = interactives[&quot;${id}&quot;]\n                trainer.step(action)\n                print(json.dumps(env.steps))`)\n            .then(resp => {\n              try {\n                updateContext({\n                  processing: false,\n                  environment: { steps: JSON.parse(resp) },\n                });\n                play();\n              } catch (e) {\n                console.error(resp, e);\n              }\n            })\n            .catch(e => console.error(e));\n        };\n\n        // Check if currently interactive.\n        contextRef.current.isInteractive = () => {\n          const context = contextRef.current;\n          const steps = context.environment.steps;\n          return (\n            context.interactive &&\n            !context.processing &&\n            context.step === steps.length - 1 &&\n            steps[context.step].some(s => s.status === &quot;ACTIVE&quot;)\n          );\n        };\n\n        return h`\n          <${Context.Provider} value=${contextRef.current}>\n            <${Player} />\n          <//>`;\n      };\n\n      preact.render(h`<${App} />`, document.body);\n    </script>\n  </body>\n</html>\n\" width=\"500\" height=\"450\" frameborder=\"0\"></iframe> ",
      "text/plain": "<IPython.core.display.HTML object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "valid_env.reset()\n",
    "valid_env.run([my_agent, \"random\"])\n",
    "valid_env.render(mode=\"ipython\", width=500, height=450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_reward(rewards):\n",
    "    return sum(r[0] for r in rewards) / sum(r[0] + r[1] for r in rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "My Agent vs Random Agent: 0.7\nMy Agent vs Negamax Agent: 1.0\n"
    }
   ],
   "source": [
    "# Run multiple episodes to estimate its performance.\n",
    "print(\"My Agent vs Random Agent:\", mean_reward(evaluate(\"connectx\", [my_agent, \"random\"], num_episodes=10)))\n",
    "print(\"My Agent vs Negamax Agent:\", mean_reward(evaluate(\"connectx\", [my_agent, \"negamax\"], num_episodes=10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "<function my_agent at 0x7f40cfea29d0> written to submission.py\n"
    }
   ],
   "source": [
    "import inspect\n",
    "import os\n",
    "\n",
    "def write_agent_to_file(function, file):\n",
    "    with open(file, \"a\" if os.path.exists(file) else \"w\") as f:\n",
    "        f.write(inspect.getsource(function))\n",
    "        print(function, \"written to\", file)\n",
    "\n",
    "write_agent_to_file(my_agent, \"submission.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgument",
     "evalue": "No callable found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSyntaxError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/kaggle_environments/utils.py\u001b[0m in \u001b[0;36mget_exec\u001b[0;34m(raw, fallback)\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0mcode_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"<string>\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"exec\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSyntaxError\u001b[0m: EOL while scanning string literal (<string>, line 5)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgument\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/kaggle_environments/utils.py\u001b[0m in \u001b[0;36mget_last_callable\u001b[0;34m(raw, fallback)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0mlocal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_exec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         \u001b[0mcallables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/kaggle_environments/utils.py\u001b[0m in \u001b[0;36mget_exec\u001b[0;34m(raw, fallback)\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfallback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mInvalidArgument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid raw Python: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgument\u001b[0m: Invalid raw Python: EOL while scanning string literal (<string>, line 5)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgument\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-166-b3c0389ba38a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msubmission\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./submission_test.py\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0magent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_last_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubmission\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/kaggle_environments/utils.py\u001b[0m in \u001b[0;36mget_last_callable\u001b[0;34m(raw, fallback)\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfallback\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfallback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mInvalidArgument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No callable found\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgument\u001b[0m: No callable found"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "out = sys.stdout\n",
    "submission = utils.read_file(\"./submission_test.py\")\n",
    "agent = utils.get_last_callable(submission)\n",
    "sys.stdout = out\n",
    "\n",
    "env = make(\"connectx\", debug=True)\n",
    "env.run([agent, agent])\n",
    "print(\"Success!\" if env.state[0].status == env.state[1].status == \"DONE\" else \"Failed...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}